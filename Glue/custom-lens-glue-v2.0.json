{
    "schemaVersion": "2021-11-01",
    "name": "Glue Best Practice Lens",
    "description": "Best practices for configuring Glue",
    "_version":"2.0",
    "_release_date":"2023-08-12",
    "_release_note":"",
    "_teams":{
       "_authors":[
          {
            "name":"Noritaka Sekiyama, Principal Big Data Architect, AWS"
          },
          {
            "name":"Ray Wang, Analytics SME, GCR, AWS",
            "email":"hsiawang@amazon.com"
          },
          {
            "name":"Hsu, Chia-Wei, Glue SME"
          }
       ],
       "_tech_reviewers":[
          {
            "name":"Bob Yeh, Geo Solutions Architect, Well-Architected APAC, AWS"
          }
       ]
    },
    "pillars": [
        {
            "id": "PERF",
            "name": "Performance Efficiency",
            "questions": [
                {
                    "id": "PERF1",
                    "title": "Do konw how file formats, file size, file layout and compression effect your job performance?",
                    "description": "To reduce the amount of data loaded into your job when reading from Amazon S3, you need to consider FileSize, Compression, FileFormat and FileLayout (Partitions) for your dataset.",
                    "choices": [
                        {
                            "id": "PERF1_1",
                            "title": "Choice the suitable file format for you Glue ETL Job",
                            "helpfulResource": {
                                "displayText": "Have you use a columnar format. Apache Parquet and Apache ORC are popular columnar data formats?\n\nWhen using columnar formats, you can skip blocks of data that correspond to columns you do not plan to use.",
                                "url": "https://aws.amazon.com/blogs/big-data/top-10-performance-tuning-tips-for-amazon-athena/"
                            },
                            "improvementPlan": {
                                "displayText": "Use input/output parquet, orc dataformat",
                                "url": "https://aws.amazon.com/blogs/big-data/top-10-performance-tuning-tips-for-amazon-athena/"
                            }
                        },
                        {
                            "id": "PERF1_2",
                            "title": "Choice the suitable file size for you Glue ETL Job",
                            "helpfulResource": {
                                "displayText": "Large number of small file will impact perfomrnace a lot. We will need to keep Inputs and Outputs within a moderate range of sizes (ex. 128MB)",
                                "url": "https://aws.amazon.com/blogs/big-data/top-10-performance-tuning-tips-for-amazon-athena/"
                            },
                            "improvementPlan": {
                                "displayText": "If you would like to use Apache Spark frame work to control file size, you will need repartition to control file number insteads.",
                                "url": "https://aws.amazon.com/blogs/big-data/top-10-performance-tuning-tips-for-amazon-athena/"
                            }
                        },
                        {
                            "id": "PERF1_3",
                            "title": "Choice the suitable compression for you Glue ETL Job",
                            "helpfulResource": {
                                "displayText": "Have you notice the difference between splittable and non splittable compression?",
                                "url": "https://aws.amazon.com/blogs/big-data/best-practices-to-scale-apache-spark-jobs-and-partition-data-with-aws-glue/"
                            },
                            "improvementPlan": {
                                "displayText": "File splitting also benefits block-based compression formats such as bzip2. You can read each compression block on a file split boundary and process them independently. Unsplittable compression formats such as gzip do not benefit from file splitting.",
                                "url": "https://aws.amazon.com/blogs/big-data/best-practices-to-scale-apache-spark-jobs-and-partition-data-with-aws-glue/"
                            }
                        },
                        {
                            "id": "PERF1_4",
                            "title": "Choice the suitable file layout for you Glue ETL Job",
                            "helpfulResource": {
                                "displayText": "File layout can help AWS Glue partition your data",
                                "url": "https://docs.aws.amazon.com/glue/latest/dg/aws-glue-programming-etl-partitions.html#aws-glue-programming-etl-partitions-pushdowns."
                            },
                            "improvementPlan": {
                                "displayText": "Consider store data in hive style naming convetion such as s3://bucket/column1=value2/column2=value2.",
                                "url": "https://docs.aws.amazon.com/glue/latest/dg/aws-glue-programming-etl-partitions.html#aws-glue-programming-etl-partitions-pushdowns."
                            }
                        },
                        {
                            "id": "PERF1_5",
                            "title": "Parameters used to interact with data formats and compression in AWS Glue",
                            "helpfulResource": {
                                "displayText": "AWS Glue Jobs can be configured with the arguments listed in this document. Compression is also recommended approach.",
                                "url": "https://docs.aws.amazon.com/glue/latest/dg/aws-glue-programming-etl-glue-arguments.html"
                            },
                            "improvementPlan": {
                                "displayText": "AWS Glue recognizes several argument names that you can use to set up the script environment for your jobs and job runs",
                                "url": "https://docs.aws.amazon.com/glue/latest/dg/aws-glue-programming-etl-glue-arguments.html"
                            }
                        }
                    ],
                    "riskRules": [
                        {
                            "condition": "PERF1_1 && PERF1_2 && PERF1_3 && PERF1_4 && PERF1_5",
                            "risk": "NO_RISK"
                        },
                        {
                            "condition": "(!PERF1_1) || (!PERF1_2) || (!PERF1_3) || (!PERF1_4)",
                            "risk": "HIGH_RISK"
                        },
                        {
                            "condition": "default",
                            "risk": "MEDIUM_RISK"
                        }
                    ]
                },
                {
                    "id": "PERF2",
                    "title": "How do you determine compute unit for your Glue Job?",
                    "description": "How do you determine compute unit for your Glue Job?",
                    "choices": [
                        {
                            "id": "PERF2_1",
                            "title": "Benchmarking using Glue TPC-DS Connector or custom dataset",
                            "helpfulResource": {
                                "displayText": "Generate the TPC-DS compliant datasets from AWS Glue or generate your custom dataset to conduct benchmark and evaluation performance of different DPU.",
                                "url": "https://aws.amazon.com/marketplace/pp/prodview-xtty6azr4xgey"
                            },
                            "improvementPlan": {
                                "displayText": "The TPC-DS Glue connector enables Glue ETL Jobs to generate TPC-DS compliant datasets with your preferred scale. The generated datasets can be used for any benchmarking purpose in AWS Glue jobs, Amazon Athena, Amazon EMR, Amazon Redshift Spectrum, etc.",
                                "url": "https://aws.amazon.com/marketplace/pp/prodview-xtty6azr4xgey"
                            }
                        },
                        {
                            "id": "PERF2_2",
                            "title": "Debugging demanding stages and straggler tasks",
                            "helpfulResource": {
                                "displayText": "A straggler task takes much longer than the rest of the tasks in a stage of an AWS Glue job. As a result, the stage takes longer to complete, which also delays the total execution time of the job.",
                                "url": "https://docs.aws.amazon.com/glue/latest/dg/monitor-profile-debug-straggler.html"
                            },
                            "improvementPlan": {
                                "displayText": "You can use AWS Glue job profiling to identify demanding stages and straggler tasks in your extract, transform, and load (ETL) jobs.",
                                "url": "https://docs.aws.amazon.com/glue/latest/dg/monitor-profile-debug-straggler.html"
                            }
                        },
                        {
                            "id": "PERF2_3",
                            "title": "Visualize the profiled metrics on the AWS Glue console",
                            "helpfulResource": {
                                "displayText": "This is a common workflow pattern, and requires monitoring for individual job progress, data processing backlog, data reprocessing, and job bookmarks.",
                                "url": "https://docs.aws.amazon.com/glue/latest/dg/monitor-debug-multiple.html"
                            },
                            "improvementPlan": {
                                "displayText": "You can profile multiple AWS Glue jobs together and monitor the flow of data between them.",
                                "url": "https://docs.aws.amazon.com/glue/latest/dg/monitor-debug-multiple.html"
                            }
                        },
                        {
                            "id": "PERF2_4",
                            "title": "Calculating and Monitoring for DPU capacity planning",
                            "helpfulResource": {
                                "displayText": "Applicable to AWS Glue versions 0.9 and 1.0. Later versions of AWS Glue contain cost-saving features that introduce additional considerations when capacity planning.",
                                "url": "https://docs.aws.amazon.com/glue/latest/dg/monitor-debug-capacity.html"
                            },
                            "improvementPlan": {
                                "displayText": "You can use job metrics in AWS Glue to estimate the number of data processing units (DPUs) that can be used to scale out an AWS Glue job.",
                                "url": "https://docs.aws.amazon.com/glue/latest/dg/monitor-debug-capacity.html"
                            }
                        },
                        {
                            "id": "PERF2_5",
                            "title": "Have you enable Auto Scaling in Glue?",
                            "helpfulResource": {
                                "displayText": "Applicable to AWS Glue 3.0 and 4.0. AWS Glue automatically adds and removes workers from the cluster depending on the parallelism at each stage or microbatch of the job run.",
                                "url": "https://docs.aws.amazon.com/glue/latest/dg/auto-scaling.html"
                            },
                            "improvementPlan": {
                                "displayText": "You can enable AWS Glue auto scaling in Glue job console",
                                "url": "https://docs.aws.amazon.com/glue/latest/dg/auto-scaling.html"
                            }
                        }
                    ],
                    "riskRules": [
                        {
                            "condition": "PERF2_1 && PERF2_2 && PERF2_3 && PERF2_4 && PERF2_5",
                            "risk": "NO_RISK"
                        },
                        {
                            "condition": "(!PERF2_2) || (!PERF2_3) || (!PERF2_4) || (!PERF2_5)",
                            "risk": "HIGH_RISK"
                        },
                        {
                            "condition": "default",
                            "risk": "MEDIUM_RISK"
                        }
                    ]
                },
                {
                    "id": "PERF3",
                    "title": "How do you organize or partition your data in your data lake for Glue Jobs friendly?",
                    "description": "How do you organize or partition your data in your data lake for Glue Jobs friendly?",
                    "choices": [
                        {
                            "id": "PERF3_1",
                            "title": "Structure your data to build high performant of Glue Job",
                            "helpfulResource": {
                                "displayText": "You can identify your ETL job query pattern and structure your data so that you can get better performance and reduce cost through target the partitioned data.",
                                "url": "https://aws.amazon.com/blogs/big-data/top-10-performance-tuning-tips-for-amazon-athena/"
                            },
                            "improvementPlan": {
                                "displayText": "You can apply the same practices to Amazon EMR data processing applications such as Spark, Presto, and Hive when your data is stored in Amazon S3.",
                                "url": "https://aws.amazon.com/blogs/big-data/top-10-performance-tuning-tips-for-amazon-athena/"
                            }
                        },
                        {
                            "id": "PERF3_2",
                            "title": "Awareness of performance degration in Glue partition",
                            "helpfulResource": {
                                "displayText": "Over time, hundreds of thousands of partitions get added to a table. The GetPartitions API is used to fetch the partitions in the table. The API returns partitions which match the expression provided in the request.",
                                "url": "https://docs.aws.amazon.com/glue/latest/dg/partition-indexes.html"
                            },
                            "improvementPlan": {
                                "displayText": "When you create a partition index, you specify a list of partition keys that already exist on a given table. Partition index is sub list of partition keys defined in the table. A partition index can be created on any permutation of partition keys defined on the table.",
                                "url": "https://docs.aws.amazon.com/glue/latest/dg/partition-indexes.html"
                            }
                        },
                        {
                            "id": "PERF3_3",
                            "title": "Avoid too many S3 partitions",
                            "helpfulResource": {
                                "displayText": "Too many partitions may cause: Increased latency for retrieving partition metadata from Glue Data Catalog; Increased number of small files which requires more Amazon S3 API requests (List/Get/Head)",
                                "url": "https://aws.amazon.com/blogs/big-data/get-started-managing-partitions-for-amazon-s3-tables-backed-by-the-aws-glue-data-catalog/"
                            },
                            "improvementPlan": {
                                "displayText": "You should not partition your S3 data on columns that contain a wide range of values, such as an ID column with thousands of values. This can substantially increase the number of partitions in your bucket, since the number of possible partitions is the product of all of the fields you have partitioned by.",
                                "url": "https://aws.amazon.com/blogs/big-data/get-started-managing-partitions-for-amazon-s3-tables-backed-by-the-aws-glue-data-catalog/"
                            }
                        },
                        {
                            "id": "PERF3_4",
                            "title": "For database and JDBC, Specify a where predicate in a SQL query to reduce data scan",
                            "helpfulResource": {
                                "displayText": "Glue pushdown predicate sql can help to reduce data scan when using JDBC datasource",
                                "url": "https://docs.aws.amazon.com/glue/latest/dg/aws-glue-programming-etl-connect.html#aws-glue-programming-etl-connect-jdbc"
                            },
                            "improvementPlan": {
                                "displayText": "set enablePartitioningForSampleQuery and sampleQuery in create_dynamic_frame.from_catalog or create_dynamic_frame.from_options",
                                "url": "https://docs.aws.amazon.com/glue/latest/dg/aws-glue-programming-etl-connect.html#aws-glue-programming-etl-connect-jdbc"
                            }
                        }
                    ],
                    "riskRules": [
                        {
                            "condition": "PERF3_1 && PERF3_2 && PERF3_3 && PERF3_4",
                            "risk": "NO_RISK"
                        },
                        {
                            "condition": "(!PERF3_1) || (!PERF3_2) || (!PERF3_3) || (!PERF3_4)",
                            "risk": "HIGH_RISK"
                        },
                        {
                            "condition": "default",
                            "risk": "MEDIUM_RISK"
                        }
                    ]
                },
                {
                    "id": "PERF4",
                    "title": "Do you know how to parallelize tasks based on your parition?",
                    "description": "It is important to parallelize tasks for data loads and transformations",
                    "choices": [
                        {
                            "id": "PERF4_1",
                            "title": "Monitor parallelize tasks",
                            "helpfulResource": {
                                "displayText": "Do you know how to monitor your job's parallelism?",
                                "url": "https://docs.aws.amazon.com/glue/latest/dg/monitoring-awsglue-with-cloudwatch-metrics.html"
                            },
                            "improvementPlan": {
                                "displayText": "You can use spark ui and glue metrics  numberMaxNeededExecutors to see thee reosurce you provsioned can fully parallelism your job ",
                                "url": "https://docs.aws.amazon.com/glue/latest/dg/monitoring-awsglue-with-cloudwatch-metrics.html"
                            }
                        },
                        {
                            "id": "PERF4_2",
                            "title": "Parallelize data load from S3",
                            "helpfulResource": {
                                "displayText": "Do you know the parallelism you will have when reading data on s3?",
                                "url": "https://spark.apache.org/docs/3.1.3/api/python/reference/api/pyspark.sql.DataFrame.repartition.html"
                            },
                            "improvementPlan": {
                                "displayText": "The RDD partition (parallelism) will base on data format and datasize. You can use repartition df.repartition(N) to control the rdd partition to control the task (job parallelism)",
                                "url": "https://spark.apache.org/docs/3.1.3/api/python/reference/api/pyspark.sql.DataFrame.repartition.html"
                            }
                        },
                        {
                            "id": "PERF4_3",
                            "title": "Parallelize data load from JDBC",
                            "helpfulResource": {
                                "displayText": "Do you know how to control the parallelism when reading data from jdbc source?",
                                "url": "https://docs.aws.amazon.com/glue/latest/dg/run-jdbc-parallel-read-job.html"
                            },
                            "improvementPlan": {
                                "displayText": "Using hashexpression and hashpartitions to control the parallelis",
                                "url": "https://docs.aws.amazon.com/glue/latest/dg/run-jdbc-parallel-read-job.html"
                            }
                        },
                        {
                            "id": "PERF4_4",
                            "title": "Parallelize data load from DynamoDB using traditional ETL connector",
                            "helpfulResource": {
                                "displayText": "Do you know how to control the parallelism when reading data from Dynamodb source?",
                                "url": "https://docs.aws.amazon.com/glue/latest/dg/aws-glue-programming-etl-connect.html"
                            },
                            "improvementPlan": {
                                "displayText": "set dynamodb.splits when using connection_type=\"dynamodb\" to scan dynamodb resource",
                                "url": "https://docs.aws.amazon.com/glue/latest/dg/aws-glue-programming-etl-connect.html"
                            }
                        },
                        {
                            "id": "PERF4_5",
                            "title": "Parallelize data load from Kinesis Data Streams",
                            "helpfulResource": {
                                "displayText": "Do you know the parallelism you will have when reading data from kniesis source?",
                                "url": "https://aws.amazon.com/blogs/big-data/best-practices-to-optimize-cost-and-performance-for-aws-glue-streaming-etl-jobs/"
                            },
                            "improvementPlan": {
                                "displayText": "parallelism will be the same as kinesis shard",
                                "url": "https://aws.amazon.com/blogs/big-data/best-practices-to-optimize-cost-and-performance-for-aws-glue-streaming-etl-jobs/"
                            }
                        },
                        {
                            "id": "PERF4_6",
                            "title": "Parallelize tasks after data load",
                            "helpfulResource": {
                                "displayText": "Do you know how to control the parallelism after loading data into spark dataframe/Glue Dynamicframe?",
                                "url": "https://spark.apache.org/docs/3.1.3/api/python/reference/api/pyspark.sql.DataFrame.repartition.html"
                            },
                            "improvementPlan": {
                                "displayText": "by maunlly invoke repartition() or set parameter spark.sql.shuffle.partitions. spark.sql.shuffle.partitions will affect the partitions when shuffle",
                                "url": "https://spark.apache.org/docs/3.1.3/api/python/reference/api/pyspark.sql.DataFrame.repartition.html"
                            }
                        },
                        {
                            "id": "PERF4_7",
                            "title": "Monitor data scan",
                            "helpfulResource": {
                                "displayText": "Do you know how to monitor data scan size in AWS Glue?",
                                "url": "https://docs.aws.amazon.com/glue/latest/ug/monitoring-chapter.html#monitoring-job-run-metrics"
                            },
                            "improvementPlan": {
                                "displayText": "You can use AWS Cloudwatch metrics or spark UI to monitor your job data scan size ",
                                "url": "https://docs.aws.amazon.com/glue/latest/ug/monitoring-chapter.html#monitoring-job-run-metrics"
                            }
                        }
                    ],
                    "riskRules": [
                        {
                            "condition": "PERF4_1 && PERF4_2 && PERF4_3 && PERF4_4 && PERF4_5 && PERF4_6 && PERF4_7",
                            "risk": "NO_RISK"
                        },
                        {
                            "condition": "(!PERF4_1) || (!PERF4_2) || (!PERF4_3) || (!PERF4_4) || (!PERF4_5) || (!PERF4_6) || (!PERF4_7)",
                            "risk": "HIGH_RISK"
                        },
                        {
                            "condition": "default",
                            "risk": "MEDIUM_RISK"
                        }
                    ]
                },
                {
                    "id": "PERF5",
                    "title": "How do you identified and improve your slow running job?",
                    "description": "How do you identified and improve your slow running job?",
                    "choices": [
                        {
                            "id": "PERF5_1",
                            "title": "Identify your slow stage in spark history",
                            "helpfulResource": {
                                "displayText": "You can compare the slow and the fast runs. For this you can even use your local pyspark and calculate a ratio between slow and fast run for each stage metrics.",
                                "url": "https://holdenk.github.io/spark-flowchart/details/slow-stage/"
                            },
                            "improvementPlan": {
                                "displayText": "Once you identify the slow stage, check the fields \"Input\", \"Output\", \"Shuffle Read\", \"Shuffle Write\" of the slow stage and use below grid to identify the stage type and the corresponding ETL action.",
                                "url": "https://holdenk.github.io/spark-flowchart/details/slow-stage/"
                            }
                        },
                        {
                            "id": "PERF5_2",
                            "title": "Identify too big DAG in spark history and log",
                            "helpfulResource": {
                                "displayText": "Spark uses lazy evaluation and creates a DAG (directed acyclic graph) of the operations needed to compute a peice of data. Even if the data is persisted or cached, Spark will keep this DAG in memory on the driver so that if an executor fails it can re-create this data later.",
                                "url": "https://holdenk.github.io/spark-flowchart/details/toobigdag/"
                            },
                            "improvementPlan": {
                                "displayText": "This is more likely to cause problems with iterative algorithms that create RDDs or DataFrames on each iteration based on the previous iteration, like ALS. Some signs of a DAG getting too big are:Iterative algorithm becoming slower on each iterationDriver OOMExecutor out-of-disk-error",
                                "url": "https://holdenk.github.io/spark-flowchart/details/toobigdag/"
                            }
                        },
                        {
                            "id": "PERF5_3",
                            "title": "Identify your job is waiting for cluster resources",
                            "helpfulResource": {
                                "displayText": "Sometimes the cluster manager may choke or otherwise not be able to allocate resources and we don't have a good way of detecting this situation making it difficult for the user to debug and tell apart from Spark not scaling up correctly.",
                                "url": "https://holdenk.github.io/spark-flowchart/details/slow-job-slow-cluster/"
                            },
                            "improvementPlan": {
                                "displayText": "As of Spark3.4, an executor will note when and for how long it waits for cluster resources. Check the JVM metrics for this information.",
                                "url": "https://holdenk.github.io/spark-flowchart/details/slow-job-slow-cluster/"
                            }
                        },
                        {
                            "id": "PERF5_4",
                            "title": "Know the difference between AWS Glue Dynamic frame, Apache Spark Dataframe, Apache Spark RDD",
                            "helpfulResource": {
                                "displayText": "Spark Dataframe has Catalyst Optimizer which will help you optmize the DAG workflow",
                                "url": "https://www.databricks.com/glossary/catalyst-optimizer"
                            },
                            "improvementPlan": {
                                "displayText": "Consider to use Spark Dataframe if you enconter performance issue. It will use cataluyst optimizer automatically.",
                                "url": "https://www.databricks.com/glossary/catalyst-optimizer"
                            }
                        },
                        {
                            "id": "PERF5_5",
                            "title": "Identify and optimize data skew",
                            "helpfulResource": {
                                "displayText": "When enable both spark.sql.adaptive.enabled and  spark.sql.adaptive.skewJoin.enabled config, spark sql will use sort-merge join algorithm to handle skew data.",
                                "url": "https://www.hadoopinrealworld.com/how-does-shuffle-sort-merge-join-work-in-spark/"
                            },
                            "improvementPlan": {
                                "displayText": "We can set it configuration  such as spark.conf.set(\"spark.sql.adaptive.enabled\", \"true\")",
                                "url": "https://spark.apache.org/docs/latest/sql-performance-tuning.html"
                            }
                        },
                        {
                            "id": "PERF5_6",
                            "title": "Optimze shuffles and related action",
                            "helpfulResource": {
                                "displayText": "Do you know shuffle is one of the most substantial factors in degraded performance of your Spark application",
                                "url": "https://spark.apache.org/docs/latest/sql-performance-tuning.html"
                            },
                            "improvementPlan": {
                                "displayText": "Consider to optimze join,Use Bucket Table,Repartition DataFrames on Join keys before the Join, Use cache, remove unnesscary action(such as collect) on your job",
                                "url": "https://spark.apache.org/docs/latest/sql-performance-tuning.html"
                            }
                        },
                        {
                            "id": "PERF5_7",
                            "title": "Minimize planning overhead",
                            "helpfulResource": {
                                "displayText": "Do you know how to monitor the bottleneck on plaing phase?",
                                "url": "https://spark.apache.org/docs/latest/sql-performance-tuning.html"
                            },
                            "improvementPlan": {
                                "displayText": "Monitor cloudwatch glue cpu and memory usage and spark ui submitted time.",
                                "url": "https://spark.apache.org/docs/latest/sql-performance-tuning.html"
                            }
                        },
                        {
                            "id": "PERF5_8",
                            "title": "Optimize User Defined Functions",
                            "helpfulResource": {
                                "displayText": "Do you know Python udf may degrade your job performance?",
                                "url": "https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-functions.html"
                            },
                            "improvementPlan": {
                                "displayText": "Consider to use UDFs written in Java/Scala than Python UDFs.",
                                "url": "https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-catalog-functions.html"
                            }
                        },
                        {
                            "id": "PERF5_9",
                            "title": "Updage your spark and Glue version to lasest version",
                            "helpfulResource": {
                                "displayText": "We recommend using the latest Glue version. For example, Glue 4.0 \nuse new optimized Apache Spark 3.3.0 runtime",
                                "url": "https://spark.apache.org/releases/spark-release-3-3-0.html"
                            },
                            "improvementPlan": {
                                "displayText": "The AWS Glue version determines the versions of Apache Spark and Python that AWS Glue supports.",
                                "url": "https://docs.aws.amazon.com/glue/latest/dg/release-notes.html"
                            }
                        }
                    ],
                    "riskRules": [
                        {
                            "condition": "PERF5_1 && PERF5_2 && PERF5_3 && PERF5_4 && PERF5_5 && PERF5_6 && PERF5_7 && PERF5_8 && PERF5_9",
                            "risk": "NO_RISK"
                        },
                        {
                            "condition": "(!PERF5_1) || (!PERF5_2) || (!PERF5_3) || (!PERF5_5) || (!PERF5_6) || (!PERF5_7) || (!PERF5_8) || (!PERF5_9)",
                            "risk": "HIGH_RISK"
                        },
                        {
                            "condition": "default",
                            "risk": "MEDIUM_RISK"
                        }
                    ]
                }
            ]
        },
        {
            "id": "OPS",
            "name": "Operational Excellence",
            "questions": [
                {
                    "id": "OPS1",
                    "title": "How do you monitor ETL jobs in AWS Glue?",
                    "description": "How do you monitor ETL jobs in AWS Glue?",
                    "choices": [
                        {
                            "id": "OPS1_1",
                            "title": "Enable AWS tags in AWS Glue",
                            "helpfulResource": {
                                "displayText": "To help you manage your AWS Glue resources, you can optionally assign your own tags to some AWS Glue resource types. A tag is a label that you assign to an AWS resource. Each tag consists of a key and an optional value, both of which you define.",
                                "url": "https://docs.aws.amazon.com/glue/latest/dg/monitor-tags.html"
                            },
                            "improvementPlan": {
                                "displayText": "You can use tags in AWS Glue to organize and identify your resources. Tags can be used to create cost accounting reports and restrict access to resources. If you're using AWS Identity and Access Management, you can control which users in your AWS account have permission to create, edit, or delete tags.",
                                "url": "https://docs.aws.amazon.com/glue/latest/dg/monitor-tags.html"
                            }
                        },
                        {
                            "id": "OPS1_2",
                            "title": "Automating AWS Glue with CloudWatch Events",
                            "helpfulResource": {
                                "displayText": "You can use Amazon CloudWatch Events to automate your AWS services and respond automatically to system events such as application availability issues or resource changes.",
                                "url": "https://docs.aws.amazon.com/glue/latest/dg/automating-awsglue-with-cloudwatch-events.html"
                            },
                            "improvementPlan": {
                                "displayText": "Events from AWS services are delivered to CloudWatch Events in near real time. You can write simple rules to indicate which events are of interest to you, and what automated actions to take when an event matches a rule.",
                                "url": "https://docs.aws.amazon.com/glue/latest/dg/automating-awsglue-with-cloudwatch-events.html"
                            }
                        },
                        {
                            "id": "OPS1_3",
                            "title": "Logging AWS Glue API calls with AWS CloudTrail",
                            "helpfulResource": {
                                "displayText": "AWS Glue is integrated with AWS CloudTrail, a service that provides a record of actions taken by a user, role, or an AWS service in AWS Glue.",
                                "url": "https://docs.aws.amazon.com/glue/latest/dg/monitor-cloudtrail.html"
                            },
                            "improvementPlan": {
                                "displayText": "CloudTrail captures all API calls for AWS Glue as events. The calls captured include calls from the AWS Glue console and code calls to the AWS Glue API operations.",
                                "url": "https://docs.aws.amazon.com/glue/latest/dg/monitor-cloudtrail.html"
                            }
                        }
                    ],
                    "riskRules": [
                        {
                            "condition": "OPS1_1 && OPS1_2 && OPS1_3",
                            "risk": "NO_RISK"
                        },
                        {
                            "condition": "(!OPS1_2)",
                            "risk": "HIGH_RISK"
                        },
                        {
                            "condition": "default",
                            "risk": "MEDIUM_RISK"
                        }
                    ]
                },
                {
                    "id": "OPS2",
                    "title": "How do you monitor your Spark Job on AWS Glue",
                    "description": "How do you monitor your Spark Job on AWS Glue",
                    "choices": [
                        {
                            "id": "OPS2_1",
                            "title": "Monitoring jobs using the Apache Spark web UI",
                            "helpfulResource": {
                                "displayText": "You can use the Apache Spark web UI to monitor and debug AWS Glue ETL jobs running on the AWS Glue job system, and also Spark applications running on AWS Glue development endpoints.",
                                "url": "https://docs.aws.amazon.com/glue/latest/dg/monitor-spark-ui.html"
                            },
                            "improvementPlan": {
                                "displayText": "You can enable the Spark UI using the AWS Glue console or the AWS Command Line Interface (AWS CLI). When you enable the Spark UI, AWS Glue ETL jobs and Spark applications on AWS Glue development endpoints can persist Spark event logs to a location that you specify in Amazon Simple Storage Service (Amazon S3).",
                                "url": "https://docs.aws.amazon.com/glue/latest/dg/monitor-spark-ui.html"
                            }
                        },
                        {
                            "id": "OPS2_2",
                            "title": "Monitoring with AWS Glue job run insights",
                            "helpfulResource": {
                                "displayText": "AWS Glue job run insights is a feature in AWS Glue that simplifies job debugging and optimization for your AWS Glue jobs.",
                                "url": "https://docs.aws.amazon.com/glue/latest/dg/monitor-job-insights.html"
                            },
                            "improvementPlan": {
                                "displayText": "AWS Glue provides Spark UI, and CloudWatch logs and metrics for monitoring your AWS Glue jobs.",
                                "url": "https://docs.aws.amazon.com/glue/latest/dg/monitor-job-insights.html"
                            }
                        },
                        {
                            "id": "OPS2_3",
                            "title": "Monitoring with Amazon CloudWatch",
                            "helpfulResource": {
                                "displayText": "You can monitor AWS Glue using Amazon CloudWatch, which collects and processes raw data from AWS Glue into readable, near-real-time metrics.",
                                "url": "https://docs.aws.amazon.com/glue/latest/dg/monitor-cloudwatch.html"
                            },
                            "improvementPlan": {
                                "displayText": "By default, AWS Glue metrics data is sent to CloudWatch automatically. For more information, see What Is Amazon CloudWatch? in the Amazon CloudWatch User Guide, and AWS Glue metrics.",
                                "url": "https://docs.aws.amazon.com/glue/latest/dg/monitor-cloudwatch.html"
                            }
                        },
                        {
                            "id": "OPS2_4",
                            "title": "Job monitoring and debugging",
                            "helpfulResource": {
                                "displayText": "Most of the errors should fall into below 4 categories, which includes: SQL Analysis Exception, Memory Error, Shuffle Error, Other Error",
                                "url": "https://holdenk.github.io/spark-flowchart/flowchart/error/"
                            },
                            "improvementPlan": {
                                "displayText": "You can collect metrics about AWS Glue jobs and visualize them on the AWS Glue and Amazon CloudWatch consoles to identify and fix issues.",
                                "url": "https://docs.aws.amazon.com/glue/latest/dg/monitor-profile-glue-job-cloudwatch-metrics.html"
                            }
                        }
                    ],
                    "riskRules": [
                        {
                            "condition": "OPS2_1 && OPS2_2 && OPS2_3 && OPS2_4",
                            "risk": "NO_RISK"
                        },
                        {
                            "condition": "(!OPS2_2) || (!OPS2_3) || (!OPS2_4)",
                            "risk": "HIGH_RISK"
                        },
                        {
                            "condition": "default",
                            "risk": "MEDIUM_RISK"
                        }
                    ]
                },
                {
                    "id": "OPS3",
                    "title": "How do you troubleshooting AWS Glue",
                    "description": "How do you troubleshooting AWS Glue",
                    "choices": [
                        {
                            "id": "OPS3_1",
                            "title": "Gathering AWS Glue troubleshooting information",
                            "helpfulResource": {
                                "displayText": "If you encounter errors or unexpected behavior in AWS Glue and need to contact AWS Support, you should first gather information about names, IDs, and logs that are associated with the failed action.",
                                "url": "https://docs.aws.amazon.com/glue/latest/dg/troubleshooting-contact-support.html"
                            },
                            "improvementPlan": {
                                "displayText": "Along with your account ID, gather the following information for each of these types of failures: Glue Crawler, Glue Connection, and Glue ETL Job.",
                                "url": "https://docs.aws.amazon.com/glue/latest/dg/troubleshooting-contact-support.html"
                            }
                        },
                        {
                            "id": "OPS3_2",
                            "title": "Troubleshooting errors in AWS Glue",
                            "helpfulResource": {
                                "displayText": "If you encounter errors in AWS Glue, use the following solutions to help you find the source of the problems and fix them.",
                                "url": "https://docs.aws.amazon.com/glue/latest/dg/glue-troubleshooting-errors.html"
                            },
                            "improvementPlan": {
                                "displayText": "The AWS Glue GitHub repository contains additional troubleshooting guidance in AWS Glue Frequently Asked Questions",
                                "url": "https://github.com/aws-samples/aws-glue-samples/blob/master/FAQ_and_How_to.md"
                            }
                        },
                        {
                            "id": "OPS3_3",
                            "title": "AWS Glue machine learning exceptions",
                            "helpfulResource": {
                                "displayText": "The error codes and error strings are provided for each machine learning activity that may occur when you perform an operation.",
                                "url": "https://docs.aws.amazon.com/glue/latest/dg/exceptions-machine-learning.html"
                            },
                            "improvementPlan": {
                                "displayText": "Also, you can see whether it is possible to retry the operation that resulted in the error.",
                                "url": "https://docs.aws.amazon.com/glue/latest/dg/exceptions-machine-learning.html"
                            }
                        },
                        {
                            "id": "OPS3_4",
                            "title": "Build data lineage for data lakes using AWS Glue",
                            "helpfulResource": {
                                "displayText": "Data lineage is one of the most critical components of a data governance strategy for data lakes. Data lineage helps ensure that accurate, complete and trustworthy data is being used to drive business decisions.",
                                "url": "https://aws.amazon.com/blogs/big-data/build-data-lineage-for-data-lakes-using-aws-glue-amazon-neptune-and-spline/"
                            },
                            "improvementPlan": {
                                "displayText": "Our solution uses the Spline agent to capture runtime lineage information from Spark jobs, powered by AWS Glue.",
                                "url": "https://aws.amazon.com/blogs/big-data/build-data-lineage-for-data-lakes-using-aws-glue-amazon-neptune-and-spline/"
                            }
                        },
                        {
                            "id": "OPS3_5",
                            "title": "AWS Glue quotas",
                            "helpfulResource": {
                                "displayText": "Unless otherwise noted, each quota is Region-specific. For more information, see AWS Glue Endpoints and Quotas.",
                                "url": "https://docs.aws.amazon.com/general/latest/gr/glue.html"
                            },
                            "improvementPlan": {
                                "displayText": "You can contact AWS Support to request a quota increase for the service quotas listed in the AWS General Reference.",
                                "url": "https://docs.aws.amazon.com/glue/latest/dg/troubleshooting-service-limits.html"
                            }
                        }
                    ],
                    "riskRules": [
                        {
                            "condition": "OPS3_1 && OPS3_2 && OPS3_3 && OPS3_4 && OPS3_5",
                            "risk": "NO_RISK"
                        },
                        {
                            "condition": "(!OPS3_1) || (!OPS3_2) || (!OPS3_4) || (!OPS3_5)",
                            "risk": "HIGH_RISK"
                        },
                        {
                            "condition": "default",
                            "risk": "MEDIUM_RISK"
                        }
                    ]
                },
                {
                    "id": "OPS4",
                    "title": "How do you support variable data source and schema evolve if the Glue Job?",
                    "description": "How do you support variable data source and schema evolve if the Glue Job?",
                    "choices": [
                        {
                            "id": "OPS4_1",
                            "title": "Defining connections in the AWS Glue Data Catalog",
                            "helpfulResource": {
                                "displayText": "An AWS Glue connection is a Data Catalog object that stores login credentials, URI strings, virtual private cloud (VPC) information, and more for a particular data store.",
                                "url": "https://docs.aws.amazon.com/glue/latest/dg/glue-connections.html"
                            },
                            "improvementPlan": {
                                "displayText": "You can use connections for both sources and targets, and reuse the same connection across multiple crawler or extract, transform, and load (ETL) jobs.",
                                "url": "https://docs.aws.amazon.com/glue/latest/dg/glue-connections.html"
                            }
                        },
                        {
                            "id": "OPS4_2",
                            "title": "Evolving and adding new partitions in the Data Catalog from AWS Glue ETL jobs",
                            "helpfulResource": {
                                "displayText": "Your extract, transform, and load (ETL) job might create new table partitions in the target data store. Your dataset schema can evolve and diverge from the AWS Glue Data Catalog schema over time.",
                                "url": "https://docs.aws.amazon.com/glue/latest/dg/update-from-job.html"
                            },
                            "improvementPlan": {
                                "displayText": "AWS Glue ETL jobs now provide several features that you can use within your ETL script to update your schema and partitions in the Data Catalog.",
                                "url": "https://docs.aws.amazon.com/glue/latest/dg/update-from-job.html"
                            }
                        },
                        {
                            "id": "OPS4_3",
                            "title": "Adding classifiers to a crawler to support Custom datasets in AWS Glue",
                            "helpfulResource": {
                                "displayText": "A classifier reads the data in a data store. If it recognizes the format of the data, it generates a schema. The classifier also returns a certainty number to indicate how certain the format recognition was.",
                                "url": "https://docs.aws.amazon.com/glue/latest/dg/add-classifier.html"
                            },
                            "improvementPlan": {
                                "displayText": "AWS Glue provides a set of built-in classifiers, but you can also create custom classifiers. AWS Glue invokes custom classifiers first, in the order that you specify in your crawler definition. Depending on the results that are returned from custom classifiers, AWS Glue might also invoke built-in classifiers.",
                                "url": "https://docs.aws.amazon.com/glue/latest/dg/add-classifier.html"
                            }
                        },
                        {
                            "id": "OPS4_4",
                            "title": "Centrally discover, control, and evolve data stream schemas",
                            "helpfulResource": {
                                "displayText": "The AWS Glue Schema Registry is a new feature that allows you to centrally discover, control, and evolve data stream schemas. A schema defines the structure and format of a data record.",
                                "url": "https://docs.aws.amazon.com/glue/latest/dg/schema-registry.html"
                            },
                            "improvementPlan": {
                                "displayText": "With AWS Glue Schema Registry, you can manage and enforce schemas on your data streaming applications using convenient integrations with Apache Kafka, Amazon Managed Streaming for Apache Kafka, Amazon Kinesis Data Streams, Amazon Kinesis Data Analytics for Apache Flink, and AWS Lambda",
                                "url": "https://docs.aws.amazon.com/glue/latest/dg/schema-registry.html"
                            }
                        },
                        {
                            "id": "OPS4_5",
                            "title": "Simplify data integration pipeline development using AWS Glue custom blueprints",
                            "helpfulResource": {
                                "displayText": "Organizations spend significant time developing and maintaining data integration pipelines. As data volume increases, data engineering teams struggle to keep up with new requests from business teams.",
                                "url": "https://aws.amazon.com/blogs/big-data/simplify-data-integration-pipeline-development-using-aws-glue-custom-blueprints/"
                            },
                            "improvementPlan": {
                                "displayText": "Data engineers need a way to enable non-data engineers; AWS Glue custom blueprints, which offer a framework for you to build and share reusable AWS Glue workflows.",
                                "url": "https://aws.amazon.com/blogs/big-data/simplify-data-integration-pipeline-development-using-aws-glue-custom-blueprints/"
                            }
                        }
                    ],
                    "riskRules": [
                        {
                            "condition": "OPS4_1 && OPS4_2 && OPS4_3 && OPS4_4 && OPS4_5",
                            "risk": "NO_RISK"
                        },
                        {
                            "condition": "(!OPS4_1)",
                            "risk": "HIGH_RISK"
                        },
                        {
                            "condition": "default",
                            "risk": "MEDIUM_RISK"
                        }
                    ]
                },
                {
                    "id": "OPS5",
                    "title": "How do you create and deploy your Glue Job",
                    "description": "How do you create and deploy your Glue Job",
                    "choices": [
                        {
                            "id": "OPS5_1",
                            "title": "Developing AWS Glue ETL jobs locally using a container",
                            "helpfulResource": {
                                "displayText": "AWS Glue comes with many improvements on top of Apache Spark and has its own ETL libraries that can fast-track the development process and reduce boilerplate code.",
                                "url": "https://aws.amazon.com/blogs/big-data/developing-aws-glue-etl-jobs-locally-using-a-container/"
                            },
                            "improvementPlan": {
                                "displayText": "The AWS Glue team released the AWS Glue binaries and let you set up an environment on your desktop to test your code.",
                                "url": "https://aws.amazon.com/blogs/big-data/developing-aws-glue-etl-jobs-locally-using-a-container/"
                            }
                        },
                        {
                            "id": "OPS5_2",
                            "title": "Deploy an AWS Glue job with your CI/CD pipeline",
                            "helpfulResource": {
                                "displayText": "Unit test scripts are one of the initial quality gates used by developers to provide a high-quality build.",
                                "url": "https://aws.amazon.com/blogs/devops/how-to-unit-test-and-deploy-aws-glue-jobs-using-aws-codepipeline/"
                            },
                            "improvementPlan": {
                                "displayText": "You can create a method to unit test Python-based ETL Glue Jobs, using the PyTest Framework in AWS CodePipeline.",
                                "url": "https://aws.amazon.com/blogs/devops/how-to-unit-test-and-deploy-aws-glue-jobs-using-aws-codepipeline/"
                            }
                        }
                    ],
                    "riskRules": [
                        {
                            "condition": "OPS5_1 && OPS5_2",
                            "risk": "NO_RISK"
                        },
                        {
                            "condition": "(!OPS5_2)",
                            "risk": "HIGH_RISK"
                        },
                        {
                            "condition": "default",
                            "risk": "MEDIUM_RISK"
                        }
                    ]
                }
            ]
        },
        {
            "id": "SEC",
            "name": "Security",
            "questions": [
                {
                    "id": "SEC1",
                    "title": "How do you protect data in AWS Glue?",
                    "description": "How do you protect data in AWS Glue?",
                    "choices": [
                        {
                            "id": "SEC1_1",
                            "title": "Encryption at rest",
                            "helpfulResource": {
                                "displayText": "You can encrypt metadata objects in your AWS Glue Data Catalog in addition to the data written to Amazon Simple Storage Service (Amazon S3) and Amazon CloudWatch Logs by jobs, crawlers, and development endpoints.",
                                "url": "https://docs.aws.amazon.com/glue/latest/dg/encryption-at-rest.html"
                            },
                            "improvementPlan": {
                                "displayText": "AWS Glue supports data encryption at rest for Authoring jobs in AWS Glue and Developing scripts using development endpoints. You can configure ETL jobs and development endpoints to use AWS KMS keys to write encrypted data at rest.",
                                "url": "https://docs.aws.amazon.com/glue/latest/dg/encryption-at-rest.html"
                            }
                        },
                        {
                            "id": "SEC1_2",
                            "title": "Encryption in transit",
                            "helpfulResource": {
                                "displayText": "AWS provides Transport Layer Security (TLS) encryption for data in motion.",
                                "url": "https://docs.aws.amazon.com/glue/latest/dg/encryption-in-transit.html"
                            },
                            "improvementPlan": {
                                "displayText": "You can configure encryption settings for crawlers, ETL jobs, and development endpoints using security configurations in AWS Glue. You can turn on AWS Glue Data Catalog encryption via the settings for the Data Catalog.",
                                "url": "https://docs.aws.amazon.com/glue/latest/dg/encryption-in-transit.html"
                            }
                        },
                        {
                            "id": "SEC1_3",
                            "title": "Identify the FIPS compliance requirement",
                            "helpfulResource": {
                                "displayText": "If you require FIPS 140-2 validated cryptographic modules when accessing AWS through a command line interface or an API, use a FIPS endpoint.",
                                "url": "https://docs.aws.amazon.com/glue/latest/dg/fips-compliance.html"
                            },
                            "improvementPlan": {
                                "displayText": "Glue support FIPS endpoint for Federal Information Processing Standard (FIPS) 140-2",
                                "url": "https://docs.aws.amazon.com/glue/latest/dg/fips-compliance.html"
                            }
                        },
                        {
                            "id": "SEC1_4",
                            "title": "Restrict access to your AWS Glue Data Catalog",
                            "helpfulResource": {
                                "displayText": "You can use AWS Identity and Access Management (IAM) with AWS Glue to define users, AWS resources, groups, roles and fine-grained policies regarding access, denial, and more.",
                                "url": "https://docs.aws.amazon.com/glue/latest/dg/key-management.html"
                            },
                            "improvementPlan": {
                                "displayText": "Using AWS Glue, you can also create policies to restrict access to different portions of the catalog based on users, roles, or applied at a resource level.",
                                "url": "https://aws.amazon.com/blogs/big-data/restrict-access-to-your-aws-glue-data-catalog-with-resource-level-iam-permissions-and-resource-based-policies/"
                            }
                        },
                        {
                            "id": "SEC1_5",
                            "title": "Awareness of AWS Glue dependency on other AWS services",
                            "helpfulResource": {
                                "displayText": "For a user to work with the AWS Glue console, that user must have a minimum set of permissions that allows them to work with the AWS Glue resources for their AWS account.",
                                "url": "https://docs.aws.amazon.com/glue/latest/dg/dependency-on-other-services.html"
                            },
                            "improvementPlan": {
                                "displayText": "In addition to these AWS Glue permissions, the console requires permissions from the following services: Amazon CloudWatch Logs, AWS IAM, AWS CloudFormation, Amazon EC2, source and target permission",
                                "url": "https://docs.aws.amazon.com/glue/latest/dg/dependency-on-other-services.html"
                            }
                        },
                        {
                            "id": "SEC1_6",
                            "title": "Use development endpoint to develop and test your AWS Glue scripts",
                            "helpfulResource": {
                                "displayText": "A development endpoint is an environment that you can use to develop and test your AWS Glue scripts. You can use AWS Glue to create, edit, and delete development endpoints.",
                                "url": "https://docs.aws.amazon.com/glue/latest/dg/dev-endpoints.html"
                            },
                            "improvementPlan": {
                                "displayText": "You can add, delete, or rotate the SSH key of a development endpoint. You can also create notebooks that use the development endpoint.",
                                "url": "https://docs.aws.amazon.com/glue/latest/dg/dev-endpoints.html"
                            }
                        }
                    ],
                    "riskRules": [
                        {
                            "condition": "SEC1_1 && SEC1_2 && SEC1_3 && SEC1_4 && SEC1_5 && SEC1_6",
                            "risk": "NO_RISK"
                        },
                        {
                            "condition": "(!SEC1_1) || (!SEC1_2) || (!SEC1_4) || (!SEC1_5) || (!SEC1_6)",
                            "risk": "HIGH_RISK"
                        },
                        {
                            "condition": "default",
                            "risk": "MEDIUM_RISK"
                        }
                    ]
                },
                {
                    "id": "SEC2",
                    "title": "How do you manage your identity and access in AWS Glue",
                    "description": "How do you manage your identity and access in AWS Glue",
                    "choices": [
                        {
                            "id": "SEC2_1",
                            "title": "Identity-based policies (IAM policies) for access control",
                            "helpfulResource": {
                                "displayText": "Identity-based policies are attached to an IAM identity (user, group, role, or service). This type of policy grants permissions for that IAM identity to access specified resources.",
                                "url": "https://docs.aws.amazon.com/glue/latest/dg/using-identity-based-policies.html"
                            },
                            "improvementPlan": {
                                "displayText": "By attaching a policy to an IAM role, you can grant cross-account access permissions to IAM identities in other AWS accounts.",
                                "url": "https://docs.aws.amazon.com/glue/latest/dg/using-identity-based-policies.html"
                            }
                        },
                        {
                            "id": "SEC2_2",
                            "title": "AWS Glue resource policies for access control",
                            "helpfulResource": {
                                "displayText": "A resource policy is a policy that is attached to a resource rather than to an IAM identity.",
                                "url": "https://docs.aws.amazon.com/glue/latest/dg/glue-resource-policies.html"
                            },
                            "improvementPlan": {
                                "displayText": "AWS Glue supports using resource policies to control access to Data Catalog resources. These resources include databases, tables, connections, and user-defined functions, along with the Data Catalog APIs that interact with these resources.",
                                "url": "https://docs.aws.amazon.com/glue/latest/dg/glue-resource-policies.html"
                            }
                        },
                        {
                            "id": "SEC2_3",
                            "title": "Granting cross-account access",
                            "helpfulResource": {
                                "displayText": "Granting access to Data Catalog resources across accounts enables your extract, transform, and load (ETL) jobs to query and join data from different accounts.",
                                "url": "https://docs.aws.amazon.com/glue/latest/dg/cross-account-access.html"
                            },
                            "improvementPlan": {
                                "displayText": "You can grant access to your data to external AWS accounts by using AWS Glue methods or by using AWS Lake Formation cross-account grants.",
                                "url": "https://docs.aws.amazon.com/glue/latest/dg/cross-account-access.html"
                            }
                        }
                    ],
                    "riskRules": [
                        {
                            "condition": "SEC2_1 && SEC2_2 && SEC2_3",
                            "risk": "NO_RISK"
                        },
                        {
                            "condition": "(!SEC2_1) || (!SEC2_2)",
                            "risk": "HIGH_RISK"
                        },
                        {
                            "condition": "default",
                            "risk": "MEDIUM_RISK"
                        }
                    ]
                }
            ]
        },
        {
            "id": "COST",
            "name": "Cost Optimization",
            "questions": [
                {
                    "id": "COST1",
                    "title": "How are you choosing the right compute unit and worker type for Glue Job?",
                    "description": "How are you choosing the right compute unit and worker type for Glue Job?",
                    "choices": [
                        {
                            "id": "COST1_1",
                            "title": "Developing AWS Glue ETL jobs locally using a container",
                            "helpfulResource": {
                                "displayText": "AWS Glue comes with many improvements on top of Apache Spark and has its own ETL libraries that can fast-track the development process and reduce boilerplate code.",
                                "url": "https://aws.amazon.com/blogs/big-data/developing-aws-glue-etl-jobs-locally-using-a-container/"
                            },
                            "improvementPlan": {
                                "displayText": "The AWS Glue team released the AWS Glue binaries and let you set up an environment on your desktop to test your code.",
                                "url": "https://aws.amazon.com/blogs/big-data/developing-aws-glue-etl-jobs-locally-using-a-container/"
                            }
                        },
                        {
                            "id": "COST1_2",
                            "title": "Structure your data to build high performant of Glue Job",
                            "helpfulResource": {
                                "displayText": "You can identify your ETL job query pattern and structure your data so that you can get better performance and reduce cost through target the partitioned data.",
                                "url": "https://aws.amazon.com/blogs/big-data/top-10-performance-tuning-tips-for-amazon-athena/"
                            },
                            "improvementPlan": {
                                "displayText": "You can apply the same practices to Amazon EMR data processing applications such as Spark, Presto, and Hive when your data is stored in Amazon S3.",
                                "url": "https://aws.amazon.com/blogs/big-data/top-10-performance-tuning-tips-for-amazon-athena/"
                            }
                        },
                        {
                            "id": "COST1_3",
                            "title": "Using auto scaling for AWS Glue",
                            "helpfulResource": {
                                "displayText": "One of the most common challenges to reduce cost is to identify the right amount of resources to run jobs.",
                                "url": "https://aws.amazon.com/blogs/big-data/introducing-aws-glue-auto-scaling-automatically-resize-serverless-computing-resources-for-lower-cost-with-optimized-apache-spark/"
                            },
                            "improvementPlan": {
                                "displayText": "Starting with AWS Glue version 3.0, AWS Glue auto scaling helps you dynamically scale resources up and down based on the workload",
                                "url": "https://docs.aws.amazon.com/glue/latest/dg/auto-scaling.html"
                            }
                        },
                        {
                            "id": "COST1_4",
                            "title": "Smaller worker type for streaming jobs",
                            "helpfulResource": {
                                "displayText": "Processing data in real time is a common use case for customers, but sometimes these streams have sporadic and low data volumes.",
                                "url": "https://aws.amazon.com/blogs/big-data/monitor-optimize-cost-glue-spark/"
                            },
                            "improvementPlan": {
                                "displayText": "G.1X and G.2X worker types could be too big for these workloads, especially if we consider streaming jobs may need to run 24/7. To help you reduce costs, in 2022 we released G.025X, a new quarter DPU worker type for streaming ETL jobs.",
                                "url": "https://aws.amazon.com/blogs/big-data/monitor-optimize-cost-glue-spark/"
                            }
                        },
                        {
                            "id": "COST1_5",
                            "title": "Flex-based jobs for non-urgent ETL jobs",
                            "helpfulResource": {
                                "displayText": "Flex-based jobs offer the same capabilities, including access to custom connectors, a visual job authoring experience, and a job scheduling system.",
                                "url": "https://aws.amazon.com/blogs/big-data/monitor-optimize-cost-glue-spark/"
                            },
                            "improvementPlan": {
                                "displayText": "For non-urgent data integration workloads that don t require fast job start times or can afford to rerun the jobs in case of a failure, Flex could be a good option.",
                                "url": "https://aws.amazon.com/blogs/big-data/monitor-optimize-cost-glue-spark/"
                            }
                        }
                    ],
                    "riskRules": [
                        {
                            "condition": "COST1_1 && COST1_2 && COST1_3 && COST1_4 && COST1_5",
                            "risk": "NO_RISK"
                        },
                        {
                            "condition": "(!COST1_2) || (!COST1_3)",
                            "risk": "HIGH_RISK"
                        },
                        {
                            "condition": "default",
                            "risk": "MEDIUM_RISK"
                        }
                    ]
                },
                {
                    "id": "COST2",
                    "title": "Have you monitor and optimize cost on AWS Glue for Apache Spark?",
                    "description": "Have you monitor and optimize cost on AWS Glue for Apache Spark?",
                    "choices": [
                        {
                            "id": "COST2_1",
                            "title": "Monitor overall costs on AWS Glue for Apache Spark",
                            "helpfulResource": {
                                "displayText": "AWS Glue for Apache Spark charges an hourly rate in 1-second increments with a minimum of 1 minute based on the number of data processing units (DPUs).",
                                "url": "https://aws.amazon.com/blogs/big-data/monitor-optimize-cost-glue-spark/"
                            },
                            "improvementPlan": {
                                "displayText": "In AWS Cost Explorer, you can see overall trends of DPU hours.",
                                "url": "https://aws.amazon.com/blogs/big-data/monitor-optimize-cost-glue-spark/"
                            }
                        },
                        {
                            "id": "COST2_2",
                            "title": "Monitor individual job run costs",
                            "helpfulResource": {
                                "displayText": "Monitor individual job run costs on AWS Glue for Apache Spark.",
                                "url": "https://aws.amazon.com/blogs/big-data/monitor-optimize-cost-glue-spark/"
                            },
                            "improvementPlan": {
                                "displayText": "On the Monitoring page in AWS Glue Studio, you can monitor the DPU hours you spent on a specific job run.",
                                "url": "https://aws.amazon.com/blogs/big-data/monitor-optimize-cost-glue-spark/"
                            }
                        },
                        {
                            "id": "COST2_3",
                            "title": "Set the job s timeout period appropriately",
                            "helpfulResource": {
                                "displayText": "Your job might idle when encounter issue, use job timeout can help you reduce the cost when idle happening.",
                                "url": "https://aws.amazon.com/blogs/big-data/monitor-optimize-cost-glue-spark/"
                            },
                            "improvementPlan": {
                                "displayText": "Set job timeout period iaccording to your expcted job run time in 'job details'",
                                "url": "https://aws.amazon.com/blogs/big-data/monitor-optimize-cost-glue-spark/"
                            }
                        },
                        {
                            "id": "COST2_4",
                            "title": "Interactive sessions",
                            "helpfulResource": {
                                "displayText": "Use interactive sesion to test your code so that you don't need to rerun the whole job every time",
                                "url": "https://aws.amazon.com/blogs/big-data/monitor-optimize-cost-glue-spark/"
                            },
                            "improvementPlan": {
                                "displayText": "You can use it on Glue console",
                                "url": "https://aws.amazon.com/blogs/big-data/monitor-optimize-cost-glue-spark/"
                            }
                        },
                        {
                            "id": "COST2_5",
                            "title": "Upgrade to the latest version",
                            "helpfulResource": {
                                "displayText": "Latest Glue version will use new spark version. It will have new feature to benefit your job",
                                "url": "https://aws.amazon.com/blogs/big-data/monitor-optimize-cost-glue-spark/"
                            },
                            "improvementPlan": {
                                "displayText": "Chose Latest glue version in glue  job details'",
                                "url": "https://aws.amazon.com/blogs/big-data/monitor-optimize-cost-glue-spark/"
                            }
                        },
                        {
                            "id": "COST2_6",
                            "title": "Performance tuning to optimize cost",
                            "helpfulResource": {
                                "displayText": "Performance tuning plays an important role in reducing cost. The first action for performance tuning is to identify the bottlenecks.",
                                "url": "https://aws.amazon.com/blogs/big-data/monitor-optimize-cost-glue-spark/"
                            },
                            "improvementPlan": {
                                "displayText": "It s highly recommended to enable Spark UI for your jobs and then view the UI to identify the bottleneck.",
                                "url": "https://aws.amazon.com/blogs/big-data/monitor-optimize-cost-glue-spark/"
                            }
                        }
                    ],
                    "riskRules": [
                        {
                            "condition": "COST2_1 && COST2_2 && COST2_3 && COST2_4 && COST2_5 && COST2_6",
                            "risk": "NO_RISK"
                        },
                        {
                            "condition": "(!COST2_1) || (!COST2_2) || (!COST2_3) || (!COST2_4) || (!COST2_5) || (!COST2_6)",
                            "risk": "HIGH_RISK"
                        },
                        {
                            "condition": "default",
                            "risk": "MEDIUM_RISK"
                        }
                    ]
                }
            ]
        }
    ]
}