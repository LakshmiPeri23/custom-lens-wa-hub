{
  "schemaVersion": "2021-11-01",
  "name": "Amazon Machine Learning - Intelligent Document Process (IDP) Lens",
  "description": "Best Practices on Intelligent Document Process (IDP) Best Practices",
  "_version": "1.1.0",
  "_release_date": "2023-12-08",
  "_release_note": "Setup _no option in each question.",
  "pillars": [
    {
      "id": "operationalExcellence",
      "name": "Operational Excellence",
      "questions": [
        {
          "id": "OPS_1",
          "title": "How does your organization operating model supports the design, deployment, and management of your IDP workload?",
          "description": "For workloads centered on document processing automation, it's not just about the tech stack, but also the interplay of the company's culture, internal practices, and procedural frameworks. This evaluation seeks to understand how well AWS methodologies are ingrained within the business, the organization's agility in adapting to changes, and its harmony with the principles of the Well-Architected Framework, with a special emphasis on the organizational aspect",
          "helpfulResource": {
            "displayText": "By evaluating the organization's culture and operating model against these best practices, you can identify areas of strength and areas that may need further attention or improvement. The goal is to ensure that the organization is well-positioned not just technically but also culturally and operationally to make the most of the AWS cloud environment for document processing.",
            "url": "https://docs.aws.amazon.com/wellarchitected/latest/operational-excellence-pillar/organization.html"
          },
          "choices": [
            {
              "id": "OPS_1_1",
              "title": "Continuous Training and Upskilling",
              "helpfulResource": {
                "displayText": "Our organization champions regular training sessions and encourages certifications, ensuring our teams are updated with the evolving AWS services and best practices."
              },
              "improvementPlan": {
                "displayText": "Periodically reassess roles to ensure relevance. Encourage cross-training to enhance adaptability and foster team collaboration. Initiate feedback mechanisms to identify and rectify any ambiguities",
                "url": "https://docs.aws.amazon.com/wellarchitected/latest/operational-excellence-pillar/organization.html"
              }
            },
            {
              "id": "OPS_1_2",
              "title": "Feedback-Driven Iterative Improvements",
              "helpfulResource": {
                "displayText": "We value feedback from all stakeholders, be it technical teams or end-users. This input helps us in refining our processes, ensuring our document processing system remains agile and responsive to changing needs"
              },
              "improvementPlan": {
                "displayText": "Introduce more flexible learning opportunities like self-paced courses or mentorship programs. Recognize and reward continuous learning endeavors. Allocate resources to support and encourage upskilling.",
                "url": "https://docs.aws.amazon.com/wellarchitected/latest/operational-excellence-pillar/organization.html"
              }
            },
            {
              "id": "OPS_1_3",
              "title": "Alignment with Business Objectives",
              "helpfulResource": {
                "displayText": "Our strategies for document processing, are always drafted in line with our business goals, ensuring technological efforts directly contribute to organizational success."
              },
              "improvementPlan": {
                "displayText": "Initiate structured methods for collecting feedback specifically about document processing automation challenges and successes. Regularly revisit and adjust the automation processes based on the feedback. Consider hosting dedicated forums to discuss document processing improvements.",
                "url": "https://aws.amazon.com/blogs/enterprise-strategy/creating-the-cloud-business-office/"
              }
            },
            {
              "id": "OPS_1_4",
              "title": "Change Management Processes in Place",
              "helpfulResource": {
                "displayText": "Changes in document processing automation workloads can have ripple effects. We've implemented processes to manage these changes, ensuring minimal disruption and maximum stakeholder awareness."
              },
              "improvementPlan": {
                "displayText": "Engage both technical teams and business stakeholders in regular discussions about the evolving needs of document processing. Adjust the automation strategies to cater to both immediate and long-term business objectives. Stay receptive to changing business landscapes, ensuring the automation workload remains adaptable.",
                "url": "https://docs.aws.amazon.com/wellarchitected/latest/operational-excellence-pillar/organization.html"
              }
            },
            {
              "id": "OPS_1_no",
              "title": "None of these"
            }
          ],
          "riskRules": [
            {
              "condition": "OPS_1_1 && OPS_1_2 && OPS_1_3 && OPS_1_4",
              "risk": "NO_RISK"
            },
            { "condition": "default", "risk": "MEDIUM_RISK" }
          ]
        },
        {
          "id": "OPS_2",
          "title": "How do you measure the effectiveness of your IDP workflows?",
          "description": "To achieve optimal efficiency in document processing, it's imperative to monitor, evaluate, and iterate on workflows. This question delves into your methods of measuring and analyzing the efficacy of your document processing systems. The focus is on understanding the metrics and KPIs you employ and how you harness these insights to refine and elevate your processes. Through continual measurement and refinement, organizations can enhance accuracy, speed, and overall performance in document processing tasks.",
          "choices": [
            {
              "id": "OPS_2_1",
              "title": "Defined Metrics for IDP Success",
              "helpfulResource": {
                "displayText": "Utilizing service-specific metrics allows for a granular understanding of how each component of the IDP workload performs, enabling fine-tuning and optimization. For instance, using CloudWatch, one could monitor the number of documents processed through Textract. Similarly, monitoring the volume and size of documents being uploaded to an S3 bucket can provide insights into the rate at which processing demand is increasing. Further, with AWS Step Functions, the built-in metrics can be leveraged to track the execution success rate, offering insights into the effectiveness of the workflow orchestration."
              },
              "improvementPlan": {
                "displayText": "Establish benchmark metrics based on current Textract extraction accuracy",
                "url": "https://docs.aws.amazon.com/textract/latest/dg/textract-monitoring.html"
              },
              "additionalResources": [
                {
                  "type": "IMPROVEMENT_PLAN",
                  "content": [
                    {
                      "displayText": "Establish benchmark metrics based on Comprehend classification or entity recognition scores.",
                      "url": "https://docs.aws.amazon.com/comprehend/latest/dg/cer-doc-class.html"
                    }
                  ]
                }
              ]
            },
            {
              "id": "OPS_2_2",
              "title": "Feedback Loop from Human Review",
              "helpfulResource": {
                "displayText": "Establishing feedback loops from human reviews can serve as a corrective metric for the automation process. When Textract or Comprehend results require human intervention due to low confidence scores, it's an indication of areas where automation might need refining. By measuring the frequency of such interventions, and the reasons behind them, one can iteratively improve the efficiency of the pipeline and training data. This continual feedback refines the automation process, improving accuracy over time."
              },
              "improvementPlan": {
                "displayText": "Human Review Logging: Log every human intervention, particularly noting areas where Textract may have missed content or where Comprehend's analysis was uncertain. Quantitative Analysis: Track patterns in the human review logs. For Textract, this could be certain document types or layouts that are problematic. \n\nDocument Refinement: Based on feedback, refine how documents are prepared for Textract. For instance, if certain layouts are problematic, consider preprocessing adjustments.\n",
                "url": "https://aws.amazon.com/blogs/machine-learning/part-2-intelligent-document-processing-with-aws-ai-services/"
              }
            },
            {
              "id": "OPS_2_3",
              "title": "Monitoring and Improving Retry Mechanisms",
              "helpfulResource": {
                "displayText": "The effectiveness of an IDP workflow is also seen in its ability to handle and recover from errors. By tracking how often retries occur (e.g., when Textract or Comprehend fails, or when there's a glitch in retrieving a document from S3), and the success rate of these retries, one can get insights into system robustness. Metrics derived from Step Functions on the outcomes of these retries can highlight bottlenecks or frequent failure points. Analyzing these metrics allows for refinements in the workflow to improve resilience and reduce bottlenecks."
              },
              "improvementPlan": {
                "displayText": "Error Logging: Ensure all errors are comprehensively logged, whether they're from Textract's extraction process or Comprehend's analysis.\n\nRoot Cause Analysis: Identify any consistent failure points.\n\nDocument Best Practices: Continually update and educate teams on best practices for preparing documents for Textract to reduce extraction errors.\n\nRefined Error Handling: Implement better error handling in the IDP pipeline, with specific responses to known issues. For example, if a certain type of document consistently causes Textract errors, the pipeline could automatically route it for human review.",
                "url": "https://aws.amazon.com/blogs/machine-learning/part-2-intelligent-document-processing-with-aws-ai-services/"
              }
            },
            {
              "id": "OPS_2_no",
              "title": "None of these"
            }
          ],
          "riskRules": [
            { "condition": "OPS_2_1 && OPS_2_2 && OPS_2_3", "risk": "NO_RISK" },
            { "condition": "default", "risk": "MEDIUM_RISK" }
          ]
        },
        {
          "id": "OPS_3",
          "title": "How do you design your IDP workloads so that it can handle varying processing demands and unexpected challenges?",
          "description": "What architectural choices have been made and what strategies are in place for your document processing workloads, emphasizing its adaptability to changing demands and unexpected issues. How does the system scales with varying document volumes, its resilience against disruptions, and its preparedness for unanticipated challenges in the document processing pipeline. Essentially, the emphasis is on the agility, flexibility, and robustness of your setup.",
          "choices": [
            {
              "id": "OPS_3_1",
              "title": "Use Amazon CloudWatch to monitor",
              "helpfulResource": {
                "displayText": "Monitor Usage Metrics: Textract and Comprehend"
              },
              "improvementPlan": {
                "displayText": "Utilize Amazon CloudWatch to continuously monitor the number of API calls being made to Textract. This will help you identify potential rate limit breaches before they happen.",
                "url": "https://docs.aws.amazon.com/textract/latest/dg/textract_monitoring.html"
              },
              "additionalResources": [{
                "type": "IMPROVEMENT_PLAN",
                "content": [
                  {
                    "displayText": "Utilize Amazon CloudWatch to continuously monitor the number of API calls being made to Comprehend. This will help you identify potential rate limit breaches before they happen.",
                    "url": "https://docs.aws.amazon.com/comprehend/latest/dg/manage-endpoints-monitor.html"
                  }
                ]
              }]
            },
        
            {
              "id": "OPS_3_2",
              "title": "Throttling Management",
              "helpfulResource": {
                "displayText": "Throttling Management refers to the methods and strategies employed to handle rate-limiting imposed by services like Amazon Textract and Amazon Comprehend. AWS services often have limits to prevent misuse or to maintain a quality of service for all users. For Textract and Comprehend, this includes quotas on the number of API calls per second or the size of data being processed. Effective throttling management ensures that these quota limits do not impact your application's performance or user experience, by implementing mechanisms like backoff retries, queueing, and request prioritization."
              },
              "improvementPlan": {
                "displayText": "Implement Exponential Backoff with Textract: When interfacing with Textract, ensure you manage throttling and dropped connections by setting the Config parameter when creating the Amazon Textract client. It's recommended to set a retry count of 5, as the AWS SDK retries an operation this specified number of times before considering it a failure. Incorporating this mechanism can handle throttling more effectively, using the SDK's built-in exponential backoff strategy.",
                "url": "https://docs.aws.amazon.com/textract/latest/dg/handling-errors.html"
              }
            },
            {
              "id": "OPS_3_3",
              "title": "Event Driven/Looseely coupled",
              "helpfulResource": {
                "displayText": "We utilize AWS EventBridge for capturing and routing events from external systems, ensuring decoupled integrations and streamlined event-driven processing.AWS EventBridge provides a serverless event bus that simplifies the connection between applications. Its event-driven nature is crucial for real-time responsiveness and operational excellence. Decoupling the core processing from external system events ensures stability and seamless handling of varying integration requirements."
              },
              "improvementPlan": {
                "displayText": "Use Amazon SQS: Implement Amazon Simple Queue Service (SQS) to queue up requests. This ensures that if there's a surge in demand or if the service starts throttling, the excess requests are queued up and processed in an orderly manner.Prioritize Critical Requests: If some document processing tasks are more critical than others, implement logic to prioritize these requests so that they are less likely to be throttled.Feedback Loop with Application Users: Inform users if there's a delay in document processing due to rate limiting. This enhances user experience by setting clear expectations.",
                "url": "https://aws.amazon.com/blogs/publicsector/scaling-intelligent-document-processing-workflows-aws-ai/"
              }
            },
            {
              "id": "OPS_3_4",
              "title": "Rules Specified for Human Review",
              "helpfulResource": {
                "displayText": "Setting clear conditions for when to involve humans ensures a balanced approach between automation efficiency and output accuracy. For example, with Textract. if the confidence score for extracting text from a document drops below a threshold, a human review process can be triggered. Similarly, if Comprehend's entity recognition identifies potential sensitive information but doesn't reach a high confidence score, a human verification step can be incorporated using Sagemaker GroudTruth. Using AWS Step Functions, workflows can be designed such that, based on output confidence scores from services like Textract or Comprehend, the flow can diverge to either continue with automation or switch to a human review state."
              },
              "improvementPlan": {
                "displayText": "Building an end-to-end intelligent document processing solution using AWS",
                "url": "https://aws.amazon.com/blogs/machine-learning/building-an-end-to-end-intelligent-document-processing-solution-using-aws/"
              },
              "additionalResources": [{
                "type": "IMPROVEMENT_PLAN",
                "content": [
                  {
                    "displayText": "AWS Step Functions for Workflow Automation:Design and implement workflows using AWS Step Functions where, based on the output confidence scores from Textract or Comprehend, the process can smoothly transition between automated steps and human review states.",
                    "url": "https://aws.amazon.com/blogs/machine-learning/processing-pdf-documents-with-a-human-loop-using-amazon-textract-and-amazon-augmented-ai/"
                  },
                  {
                    "displayText": "IDP AI Human in the Loop with SageMaker GroundTruth",
                    "url": "https://github.com/aws-samples/aws-ai-idp-human-in-loop/tree/main"
                  },
                  {
                    "displayText": "Use Amazon SageMaker Ground Truth to Label Data",
                    "url": "https://docs.aws.amazon.com/sagemaker/latest/dg/sms.html"
                  },
                  {
                    "displayText": "How Step Functions works",
                    "url": "https://docs.aws.amazon.com/step-functions/latest/dg/how-step-functions-works.html"
                  }
                ]
              }]
            },
            {
              "id": "OPS_3_no",
              "title": "None of these"
            }
          ],
          "riskRules": [
            {
              "condition": "OPS_3_1 && OPS_3_2 && OPS_3_3 && OPS_3_4",
              "risk": "NO_RISK"
            },
            { "condition": "default", "risk": "MEDIUM_RISK" }
          ]
        },
        {
          "id": "OPS_4",
          "title": "How do you evaluate document quality, and strategize pre and post-processing to optimize accuracy and insight?",
          "description": "Designing an IDP AI services-based workflow involves evaluating document quality and employing pre-processing measures, such as image sharpening and noise reduction, to ensure optimal data input. Post-processing, on the other hand, focuses on refining outputs, like using confidence scores to trigger human reviews or further data manipulations, ensuring the highest accuracy and actionable insights are derived.\n\n\n\n",
          "choices": [
            {
              "id": "OPS_4_2",
              "title": "Document quality is assessed before starting document processing",
              "helpfulResource": {
                "displayText": "Before processing documents, we assess document quality in terms of clarity, resolution, and legibility. Documents not meeting our standards are flagged for manual intervention or subjected to enhancement techniques like image sharpening and noise reduction. \n\nPost-processing, we further refine outputs using cross-referencing with bounding box information, filtering out low-confidence results, structuring data for downstream applications, and triggering human reviews when anomalies or certain thresholds are detected"
              },
              "improvementPlan": {
                "displayText": "Pre-processing: Before submitting documents to Textract or Comprehend, it's essential to ensure they are in an optimal format for accurate extraction or comprehension. This might involve techniques such as:\n\nImage enhancement to improve readability.\nNoise reduction to eliminate background artifacts.\nFormat conversion ensuring documents are in a supported format.\nSegmenting larger documents for efficient batch processing.",
                "url": "https://aws.amazon.com/blogs/machine-learning/process-text-and-images-in-pdf-documents-with-amazon-textract/"
              },
              "additionalResources": [{
                "type": "IMPROVEMENT_PLAN",
                "content": [
                  {
                    "displayText": "The following is a list of a few ways that you can optimize your input documents for better results",
                    "url": "https://docs.aws.amazon.com/textract/latest/dg/textract-best-practices.html"
                  },
                  {
                    "displayText": "Document file requirements for Textract",
                    "url": "https://docs.aws.amazon.com/textract/latest/dg/limits-document.html"
                  },
                  {
                    "displayText": "Document file guidelines for Comprehend",
                    "url": "https://docs.aws.amazon.com/comprehend/latest/dg/guidelines-and-limits.html#limits-custom-entity-recognition"
                  },
                  {
                    "displayText": "Post-processing: After receiving output from Textract or Comprehend, certain steps enhance or refine the results:With Textract, leveraging bounding box information can help map extracted data to its position in the original document, aiding in data validation.Filtering out erroneous or low-confidence extractions.Integrating with AWS Step Functions for workflow management, automating steps like human review when confidence scores fall below a certain threshold.Transforming raw extracted data into structured formats suitable for downstream applications or storage solutions like Amazon S3.",
                    "url": "https://aws.amazon.com/blogs/machine-learning/improve-data-extraction-and-document-processing-with-amazon-textract/"
                  }
                ]
              }]
            },
            {
              "id": "OPS_4_no",
              "title": "No specific setup for document quality evaluation"
            }
          ],
          "riskRules": [
            { "condition": "OPS_4_2", "risk": "NO_RISK" },
            { "condition": "default", "risk": "MEDIUM_RISK" }
          ]
        },
        {
          "id": "OPS_5",
          "title": "How does your organization optimize the build and release processes for document processing workloads?",
          "description": "Optimizing build and release processes are critical for ensuring agile, efficient, and robust deployments of document processing workloads that often demand high accuracy and reliability. This question evaluates how organizations approach this crucial step, leveraging AWS services and best practices, all in line with the AWS Well-Architected Framework's principles.\n",
          "choices": [
            {
              "id": "OPS_5_1",
              "title": "Utilization of Infrastructure as Code - IaC",
              "helpfulResource": {
                "displayText": "We leverage AWS services such as CloudFormation or the AWS CDK to define and provision our document processing resources. This ensures consistent, reproducible, and scalable infrastructure setups, enabling smoother build and release processes."
              },
              "improvementPlan": {
                "displayText": "Use IaC and IDP CDK constructs to build your IDP workflow",
                "url": "https://aws.amazon.com/blogs/machine-learning/improve-data-extraction-and-document-processing-with-amazon-textract/"
              }
            },
            {
              "id": "OPS_5_2",
              "title": "Continuous Integration and Continuous Deployment CI/CD Practices",
              "helpfulResource": {
                "displayText": "We use AWS services like AWS CodePipeline and AWS CodeBuild for our CI/CD workflows. This ensures continuous integration and seamless deployment of document processing workloads, minimizing manual errors and reducing deployment times."
              },
              "improvementPlan": {
                "displayText": "Use Continuous Integration and Continuous Deployment CICD Practices to deploy for IDP solution",
                "url": "https://docs.aws.amazon.com/prescriptive-guidance/latest/strategy-cicd-litmus/understanding-cicd.html"
              }
            },
            {
              "id": "OPS_5_no",
              "title": "None of these"
            }
          ],
          "riskRules": [
            { "condition": "OPS_5_1 && OPS_5_2", "risk": "NO_RISK" },
            { "condition": "default", "risk": "MEDIUM_RISK" }
          ]
        },
        {
          "id": "OPS_6",
          "title": "How do you orchestrate training and evaluating tasks of new custom model for optimized Build and Release processes?",
          "description": "Optimizing build and release processes are critical for ensuring agile, efficient, and robust deployments of document processing workloads that often demand high accuracy and reliability. This question evaluates how organizations approach this crucial step, leveraging AWS services and best practices, all in line with the AWS Well-Architected Frameworks principles.",
          "choices": [
            {
              "id": "OPS_6_1",
              "title": "Utilizing ML Flywheel for Model Versioning",
              "helpfulResource": {
                "displayText": "We leverage the capabilities of Amazon Comprehend's Flywheel to orchestrate the tasks related to training and evaluating new versions of our custom models. This streamlined approach allows for efficient model updates, ensuring our document processing solutions stay accurate and updated. The use of Flywheel, combined with AWS CloudFormation, facilitates consistent and reproducible deployment of model versions"
              },
              "improvementPlan": {
                "displayText": "Continuous Model Evaluation: Integrate continuous evaluation tools that constantly feed real-world, post-deployment data back to the Flywheel. This will help in identifying drifts in model performance, triggering re-training sessions, and deploying updated models more proactively.Enhanced Version Management:Collaborate with the DevOps team to ensure that every model version deployed via AWS CloudFormation has a clear version tag, enabling swift rollback to previous versions if required. Maintaining a changelog for each version will also aid in tracking performance improvements or regressions over time.Feedback Loop Integration: Establish a feedback mechanism wherein end-users or domain experts can provide input on model predictions. Integrating this feedback into the Flywheel can refine the training and evaluation processes, further enhancing the models accuracy and relevance to real-world scenarios.",
                "url": "https://aws.amazon.com/blogs/machine-learning/introducing-the-amazon-comprehend-flywheel-for-mlops/"
              }
            },
            {
              "id": "OPS_6_2",
              "title": "Create Amazon Comprehend custom models using Comprehend flywheel",
              "helpfulResource": {
                "displayText": "Our MLOps strategy is fundamentally aligned with our business goals. By focusing on the broader objectives, we ensure that all ML deployments, including those integrated through Comprehends Flywheel, directly contribute to driving business valuebe it opening new use-case avenues, enhancing team productivity, or minimizing operational overheads."
              },
              "improvementPlan": {
                "displayText": "Simplify continuous learning of Amazon Comprehend custom models using Comprehend flywheel",
                "url": "https://aws.amazon.com/blogs/machine-learning/simplify-continuous-learning-of-amazon-comprehend-custom-models-using-comprehend-flywheel/"
              }
            },
            {
              "id": "OPS_6_no",
              "title": "None of these"
            }
          ],
          "riskRules": [
            { "condition": "OPS_6_1 && OPS_6_2", "risk": "NO_RISK" },
            { "condition": "default", "risk": "MEDIUM_RISK" }
          ]
        }
      ]
    },
    {
      "id": "security",
      "name": "Security",
      "questions": [
        {
          "id": "SEC_1",
          "title": "Do you access S3, Textract and Comprehend via VPC endpoints in your IDP workflow?",
          "description": "You can use Amazon Textract, Comprehend and S3 APIs through the public internet or keeping your network traffic within the AWS network via using VPC endpoints",
          "helpfulResource": {
            "displayText": "Consider put your IDP workflow in your VPC while access to Textract, Comprehend, and S3 APIs via VPC endpoints to secure the IDP workflow",
            "url": "https://docs.aws.amazon.com/textract/latest/dg/vpc-interface-endpoints.htm"
          },
          "choices": [
            {
              "id": "SEC_1_2",
              "title": "Use VPC endpoints to establish private connection with Amazon Textract, Comprehend and S3",
              "helpfulResource": {
                "displayText": "Instead of using the public internet, establish private and secure connections by keeping your network traffic within the AWS network and VPC endpoints to Amazon Comprehend, Textract and S3.",
                "url": "https://docs.aws.amazon.com/textract/latest/dg/vpc-interface-endpoints.html"
              },
              "improvementPlan": {
                "displayText": "Using Amazon Textract with AWS PrivateLink",
                "url": "https://aws.amazon.com/blogs/machine-learning/using-amazon-textract-with-aws-privatelink/"
              },
              "additionalResources": [
                {
                  "type": "HELPFUL_RESOURCE",
                  "content": [
                    {
                      "displayText": "Amazon Comprehend and interface VPC endpoints (AWS PrivateLink)",
                      "url": "https://docs.aws.amazon.com/comprehend/latest/dg/vpc-interface-endpoints.html"
                    },
                    {
                      "displayText": "Gateway endpoints for Amazon S3",
                      "url": "https://docs.aws.amazon.com/vpc/latest/privatelink/vpc-endpoints-s3.html"
                    }
                  ]
                },
                {
                  "type": "IMPROVEMENT_PLAN",
                  "content": [
                    {
                      "displayText": "Securing Amazon Comprehend API calls with AWS PrivateLink",
                      "url": "https://aws.amazon.com/blogs/machine-learning/securing-amazon-comprehend-api-calls-with-aws-privatelink/"
                    },
                    {
                      "displayText": "Managing Amazon S3 access with VPC endpoints and S3 Access Points",
                      "url": "https://aws.amazon.com/blogs/storage/managing-amazon-s3-access-with-vpc-endpoints-and-s3-access-points/"
                    }
                  ]
                }
              ]
            },
            {
              "id": "SEC_1_no",
              "title": "No specific setup for VPC endpoints to establish private connection"
            }
          ],
          "riskRules": [
            { "condition": "SEC_1_2", "risk": "NO_RISK" },
            { "condition": "default", "risk": "MEDIUM_RISK" }
          ]
        },
        {
          "id": "SEC_2",
          "title": "Do you have a centralized identity provider for workforce identities?",
          "description": "For workforce identities to your IDP application, rely on an identity provider that allows you to manage identities in a centralized place.",
          "helpfulResource": {
            "displayText": "For workforce identities to your IDP application, rely on an identity provider that allows you to manage identities in a centralized place.",
            "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/sec_identities_identity_provider.html"
          },
          "choices": [
            {
              "id": "SEC_2_2",
              "title": "Set up a centralized identity provider",
              "helpfulResource": {
                "displayText": "Setting up a centralized identity provider makes it simpler to manage access across multiple IDP applications and services. This reduces the need for multiple credentials and provides an opportunity to integrate with existing human resources (HR) processes.",
                "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/sec_identities_identity_provider.html"
              },
              "improvementPlan": {
                "displayText": "For federation with individual AWS accounts, you can use centralized identities for AWS with a SAML 2.0-based provider with AWS Identity and Access Management. For federation to multiple accounts in your AWS Organizations, you can configure your identity source in AWS IAM Identity Center and specify where your users and groups are stored.",
                "url": "https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_providers_enable-console-saml.html"
              },
              "additionalResources": [
                {
                  "type": "IMPROVEMENT_PLAN",
                  "content": [
                    {
                      "displayText": "Manage identities in IAM Identity Center",
                      "url": "https://docs.aws.amazon.com/singlesignon/latest/userguide/manage-your-identity-source-sso.html"
                    }
                  ]
                }
              ]
            },
            {
              "id": "SEC_2_no",
              "title": "No specific setup for centralized identity provider",
              "helpfulResource": {
                "displayText": "Don't rely on an identity provider that allows to manage identities"
              }
            }
          ],
          "riskRules": [
            { "condition": "SEC_2_2", "risk": "NO_RISK" },
            { "condition": "default", "risk": "HIGH_RISK" }
          ]
        },
        {
          "id": "SEC_3",
          "title": "How do you manage and control user access to IDP services?",
          "description": "Do you use IAM roles to control user access and do you enforce least privilege access to services in your IDP application?",
          "helpfulResource": {
            "displayText": "Do you use IAM roles to control user access and do you enforce least privilege access to services in your IDP application?",
            "url": "https://docs.aws.amazon.com/IAM/latest/UserGuide/access.html"
          },
          "choices": [
            {
              "id": "SEC_3_2",
              "title": "Use IAM roles to control user access and enforce least privilege access via IAM policies and tags",
              "helpfulResource": {
                "displayText": "Create IAM roles for user access to services in IDP application and attach appropriate policies together with tags to achieve least privilege access",
                "url": "https://docs.aws.amazon.com/IAM/latest/UserGuide/access.html"
              },
              "improvementPlan": {
                "displayText": "Create IAM roles for user access to services in IDP application and attach appropriate policies together with tags to achieve least privilege access",
                "url": "https://docs.aws.amazon.com/IAM/latest/UserGuide/access_controlling.html"
              },
              "additionalResources": [
                {
                  "type": "IMPROVEMENT_PLAN",
                  "content": [
                    {
                      "displayText": "Controlling access to AWS resources using tags",
                      "url": "https://docs.aws.amazon.com/IAM/latest/UserGuide/access_tags.html"
                    }
                  ]
                }
              ]
            },
            {
              "id": "SEC_3_no",
              "title": "No specific setup to enforce least privilege access",
              "helpfulResource": {
                "displayText": "Create IAM roles for user access to services in IDP application and attach appropriate policies together with tags to achieve least privilege access",
                "url": "https://docs.aws.amazon.com/IAM/latest/UserGuide/access.html"
              }
            }
          ],
          "riskRules": [
            { "condition": "SEC_3_2", "risk": "NO_RISK" },
            { "condition": "default", "risk": "MEDIUM_RISK" }
          ]
        },
        {
          "id": "SEC_4",
          "title": "How do you protect Amazon Textract and Comprehend in your account from cross-service impersonation?",
          "description": "An IDP application usually has multiple services. One service may call another service. You need to prevent cross-service confused deputy.",
          "helpfulResource": {
            "displayText": "Cross-service impersonation can occur when one service calls another service. The calling service can be manipulated to act on another customer's resources even though it shouldn't have the proper permissions, resulting in the confused deputy problem.",
            "url": "https://docs.aws.amazon.com/IAM/latest/UserGuide/confused-deputy.html"
          },
          "choices": [
            {
              "id": "SEC_4_2",
              "title": "Use the aws:SourceArn and aws:SourceAccount global condition context keys in resource policies",
              "helpfulResource": {
                "displayText": "We recommend using the aws:SourceArn and aws:SourceAccount global condition context keys in resource policies to limit the permissions that Textract or Comprehend gives another service to the resource.",
                "url": "https://docs.aws.amazon.com/textract/latest/dg/cross-service-confused-deputy-prevention.html"
              },
              "improvementPlan": {
                "displayText": "We recommend using the aws:SourceArn and aws:SourceAccount global condition context keys in resource policies to limit the permissions that one service gives another service to the resource. If you use both global condition context keys, the aws:SourceAccount value and the account in the aws:SourceArn value must use the same account ID when used in the same policy statement.",
                "url": "https://docs.aws.amazon.com/textract/latest/dg/cross-service-confused-deputy-prevention.html"
              },
              "additionalResources": [
                {
                  "type": "IMPROVEMENT_PLAN",
                  "content": [
                    {
                      "displayText": "Amazon Comprehend - Cross-service confused deputy prevention",
                      "url": "https://docs.aws.amazon.com/comprehend/latest/dg/cross-service-confused-deputy-prevention.html"
                    }
                  ]
                },
                {
                  "type": "HELPFUL_RESOURCE",
                  "content": [
                    {
                      "displayText": "Amazon Comprehend - Cross-service confused deputy prevention",
                      "url": "https://docs.aws.amazon.com/comprehend/latest/dg/cross-service-confused-deputy-prevention.html"
                    }
                  ]
                }
              ]
            },
            {
              "id": "SEC_4_no",
              "title": "No specific setup to prevent cross-service confused deputy",
              "helpfulResource": {
                "displayText": "We recommend using the aws:SourceArn and aws:SourceAccount global condition context keys in resource policies to limit the permissions that Textract or Comprehend gives another service to the resource.",
                "url": "https://docs.aws.amazon.com/textract/latest/dg/cross-service-confused-deputy-prevention.html"
              }
            }
          ],
          "riskRules": [
            { "condition": "SEC_4_2", "risk": "NO_RISK" },
            { "condition": "default", "risk": "MEDIUM_RISK" }
          ]
        },
        {
          "id": "SEC_5",
          "title": "How do you secure sensitive data?",
          "description": "IDP process usually involves multiple data stores. Sensitive data in these data stores needs to be secured",
          "helpfulResource": {
            "displayText": "These sensitivie data may exist in s3, DynamoDB, or RDS, etc",
            "url": "https://docs.aws.amazon.com/whitepapers/latest/best-practices-building-data-lake-for-games/data-security-and-governance.html"
          },
          "choices": [
            {
              "id": "SEC_5_2",
              "title": "Follow the best practices to secure sensitive data in data stores",
              "helpfulResource": {
                "displayText": "The security best practices tie back to some of the key capabilities including defining IAM controls, multiple ways to implement detective controls on databases, strengthening infrastructure security surrounding your data via network flow control, and data protection through encryption and tokenization.",
                "url": "https://aws.amazon.com/blogs/database/best-practices-for-securing-sensitive-data-in-aws-data-stores/"
              },
              "improvementPlan": {
                "displayText": "Consider defining IAM controls, implementing detective controls on databases, strengthening infrastructure security surrounding your data via network flow control, and/or data protection through encryption and tokenization",
                "url": "https://aws.amazon.com/blogs/database/best-practices-for-securing-sensitive-data-in-aws-data-stores/"
              }
            },
            {
              "id": "SEC_5_no",
              "title": "No specific setup to secure sensitive data",
              "helpfulResource": {
                "displayText": "The security best practices tie back to some of the key capabilities including defining IAM controls, multiple ways to implement detective controls on databases, strengthening infrastructure security surrounding your data via network flow control, and data protection through encryption and tokenization.",
                "url": "https://aws.amazon.com/blogs/database/best-practices-for-securing-sensitive-data-in-aws-data-stores/"
              }
            }
          ],
          "riskRules": [
            { "condition": "SEC_5_2", "risk": "NO_RISK" },
            { "condition": "default", "risk": "MEDIUM_RISK" }
          ]
        },
        {
          "id": "SEC_6",
          "title": "How do you encrypt data at rest in Amazon Textract?",
          "description": "Data encryption refers to protecting data while in transit and at rest. Amazon Textract uses Transport Layer Security (TLS) and VPC endpoints to encrypt data in transit. But how do you encrypt data at rest?",
          "helpfulResource": {
            "displayText": "Data encryption refers to protecting data while in transit and at rest. Amazon Textract uses Transport Layer Security (TLS) and VPC endpoints to encrypt data in transit. You need to choose a way to encrypt data at rest",
            "url": "https://docs.aws.amazon.com/textract/latest/dg/encryption.html"
          },
          "choices": [
            {
              "id": "SEC_6_2",
              "title": "Encrypt data at rest with SSE-S3",
              "helpfulResource": {
                "displayText": "The primary method of encrypting data at rest in Amazon Textract is server-side encryption. You can do server-side encryption with Amazon S3-Managed Keys (SSE-S3)",
                "url": "https://docs.aws.amazon.com/textract/latest/dg/encryption.html"
              },
              "improvementPlan": {
                "displayText": "When you use SSE-S3, each object is encrypted with a unique key. As an additional safeguard, this method encrypts the key itself with a master key that it regularly rotates.",
                "url": "https://docs.aws.amazon.com/textract/latest/dg/encryption.html"
              }
            },
            {
              "id": "SEC_6_3",
              "title": "Encrypt data at rest with SSE-KMS",
              "helpfulResource": {
                "displayText": "The primary method of encrypting data at rest in Amazon Textract is server-side encryption. You can do server-side encryption with KMS keys Stored in AWS Key Management Service (SSE-KMS)",
                "url": "https://docs.aws.amazon.com/textract/latest/dg/encryption.html"
              },
              "improvementPlan": {
                "displayText": "SSE-KMS has some additional benefits and charges. There are separate permissions for the use of a KMS key that provides added protection against unauthorized access of your objects in Amazon S3. SSE-KMS also provides you with an audit trail that shows when your KMS key was used and by whom. Additionally, you can create and manage KMS keys or use AWS managed keys that are unique to you, your service, and your Region.",
                "url": "https://docs.aws.amazon.com/textract/latest/dg/encryption.html"
              }
            },
            {
              "id": "SEC_6_no",
              "title": "No encription for data at rest",
              "helpfulResource": {
                "displayText": "The primary method of encrypting data at rest in Amazon Textract is server-side encryption. You can do server-side encryption with Amazon S3-Managed Keys (SSE-S3)",
                "url": "https://docs.aws.amazon.com/textract/latest/dg/encryption.html"
              }
            }
          ],
          "riskRules": [
            { "condition": "SEC_6_2 || SEC_6_3", "risk": "NO_RISK" },
            { "condition": "default", "risk": "MEDIUM_RISK" }
          ]
        },
        {
          "id": "SEC_7",
          "title": "Do you encrypt output of Amazon Textract asynchronous API in custom S3 bucket?",
          "description": "When you call Textract's asynchronous API, the result can be output to a S3 bucket. Do you encrypt that output?",
          "helpfulResource": {
            "displayText": "When you call Textract's asynchronous API, the result can be output to a S3 bucket. Do you encrypt that output?",
            "url": "https://aws.amazon.com/about-aws/whats-new/2020/11/amazon-textract-supports-aws-kms/"
          },
          "choices": [
            {
              "id": "SEC_7_2",
              "title": "Specify output S3 bucket and use AWS KMS key",
              "helpfulResource": {
                "displayText": "When you start an Amazon Textract job by calling StartDocumentTextDetection or StartDocumentAnalysis, you can specify the S3 bucket for storing the output and specify the AWS KMS customer master key (CMK) to encrypt the output.",
                "url": "https://aws.amazon.com/blogs/machine-learning/store-output-in-custom-amazon-s3-bucket-and-encrypt-using-aws-kms-for-multi-page-document-processing-with-amazon-textract/"
              },
              "improvementPlan": {
                "displayText": "When you start an Amazon Textract job by calling StartDocumentTextDetection or StartDocumentAnalysis, an optional parameter in the API action is called OutputConfig. This parameter allows you to specify the S3 bucket for storing the output. Another optional input parameter KMSKeyId allows you to specify the AWS KMS customer master key (CMK) to use to encrypt the output.",
                "url": "https://aws.amazon.com/blogs/machine-learning/store-output-in-custom-amazon-s3-bucket-and-encrypt-using-aws-kms-for-multi-page-document-processing-with-amazon-textract/"
              }
            },
            {
              "id": "SEC_7_no",
              "title": "No specified output S3 bucket with AWS KMS key",
              "helpfulResource": {
                "displayText": "When you start an Amazon Textract job by calling StartDocumentTextDetection or StartDocumentAnalysis, you can specify the S3 bucket for storing the output and specify the AWS KMS customer master key (CMK) to encrypt the output.",
                "url": "https://aws.amazon.com/blogs/machine-learning/store-output-in-custom-amazon-s3-bucket-and-encrypt-using-aws-kms-for-multi-page-document-processing-with-amazon-textract/"
              }
            }
          ],
          "riskRules": [
            { "condition": "SEC_7_2", "risk": "NO_RISK" },
            { "condition": "default", "risk": "MEDIUM_RISK" }
          ]
        },
        {
          "id": "SEC_8",
          "title": "Do you leverage KMS encryption in Amazon Comprehend?",
          "description": "Amazon Comprehend works with AWS KMS to provide enhanced encryption for your data.",
          "helpfulResource": {
            "displayText": "Amazon Comprehend works with AWS Key Management Service (AWS KMS) to provide enhanced encryption for your data.",
            "url": "https://docs.aws.amazon.com/comprehend/latest/dg/kms-in-comprehend.html"
          },
          "choices": [
            {
              "id": "SEC_8_2",
              "title": "Leverage KMS encryption in Amazon Comprehend to enhance data encryption for Start and Create jobs",
              "helpfulResource": {
                "displayText": "Amazon Comprehend works with AWS KMS to provide enhanced encryption for your data.Integration with AWS KMS enables you to encrypt the data in the storage volume for Start and Create jobs, and it encrypts the output results of Start jobs using your own KMS key.",
                "url": "https://docs.aws.amazon.com/comprehend/latest/dg/kms-in-comprehend.html"
              },
              "improvementPlan": {
                "displayText": "For the AWS Management Console, Amazon Comprehend encrypts custom models with its own KMS key. For the AWS CLI, Amazon Comprehend can encrypt custom models using either its own KMS key or a provided customer managed key (CMK). All Amazon Comprehend Start and Create API operations support KMS encrypted input documents.",
                "url": "https://docs.aws.amazon.com/comprehend/latest/dg/kms-in-comprehend.html"
              }
            },
            {
              "id": "SEC_8_no",
              "title": "No KMS encryption setup in Amazon Comprehend",
              "helpfulResource": {
                "displayText": "Amazon Comprehend works with AWS KMS to provide enhanced encryption for your data.Integration with AWS KMS enables you to encrypt the data in the storage volume for Start and Create jobs, and it encrypts the output results of Start jobs using your own KMS key.",
                "url": "https://docs.aws.amazon.com/comprehend/latest/dg/kms-in-comprehend.html"
              }
            }
          ],
          "riskRules": [
            { "condition": "SEC_8_2", "risk": "NO_RISK" },
            { "condition": "default", "risk": "MEDIUM_RISK" }
          ]
        },
        {
          "id": "SEC_9",
          "title": "How do you protect PII in IDP output?",
          "description": "For documents including Personal Identifying Information (PII), the PII from IDP output needs to be protected",
          "helpfulResource": {
            "displayText": "Depending on whether or not you need to store the PII in your IDP workflow's downstream, there are different ways to protect the PII.",
            "url": "https://docs.aws.amazon.com/whitepapers/latest/best-practices-building-data-lake-for-games/data-security-and-governance.html"
          },
          "choices": [
            {
              "id": "SEC_9_2",
              "title": "Secure the output PII in your data store",
              "helpfulResource": {
                "displayText": "If you need to store the PII in your IDP downstream, follow SEC01-BP04.",
                "url": "https://aws.amazon.com/blogs/database/best-practices-for-securing-sensitive-data-in-aws-data-stores/"
              },
              "improvementPlan": {
                "displayText": "Consider defining IAM controls, implementing detective controls on databases, strengthening infrastructure security surrounding your data via network flow control, and/or data protection through encryption and tokenization",
                "url": "https://aws.amazon.com/blogs/database/best-practices-for-securing-sensitive-data-in-aws-data-stores/"
              }
            },
            {
              "id": "SEC_9_3",
              "title": "Redact the PII in your IDP output",
              "helpfulResource": {
                "displayText": "If you do not need to store the PII in your IDP downstream, consider redacting the PII in your IDP output.",
                "url": "https://aws.amazon.com/blogs/machine-learning/detecting-and-redacting-pii-using-amazon-comprehend/"
              },
              "improvementPlan": {
                "displayText": "Design a PII redation step using Amazon Comprehend in your IDP workflow ",
                "url": "https://aws.amazon.com/blogs/machine-learning/detecting-and-redacting-pii-using-amazon-comprehend/"
              }
            },
            {
              "id": "SEC_9_no",
              "title": "No protection for PII in IDP output",
              "helpfulResource": {
                "displayText": "Depending on whether or not you need to store the PII in your IDP workflow's downstream, there are different ways to protect the PII.",
                "url": "https://docs.aws.amazon.com/whitepapers/latest/best-practices-building-data-lake-for-games/data-security-and-governance.html"
              }
            }
          ],
          "riskRules": [
            { "condition": "SEC_9_2 || SEC_9_3", "risk": "NO_RISK" },
            { "condition": "default", "risk": "MEDIUM_RISK" }
          ]
        },
        {
          "id": "SEC_10",
          "title": "Do you implement secure key management?",
          "description": "You need to define an encryption approach that includes the storage, rotation, and access control of keys, which helps provide protection for your content",
          "helpfulResource": {
            "displayText": "By defining an encryption approach that includes the storage, rotation, and access control of keys, you can help provide protection for your content against unauthorized users and against unnecessary exposure to authorized users.",
            "url": "https://docs.aws.amazon.com/kms/latest/developerguide/overview.html"
          },
          "choices": [
            {
              "id": "SEC_10_2",
              "title": "Use AWS Key Management Service (KMS)",
              "helpfulResource": {
                "displayText": "AWS KMS helps you manage encryption keys and integrates with many AWS services. It provides durable, secure, and redundant storage for your AWS KMS keys.",
                "url": "https://docs.aws.amazon.com/kms/latest/developerguide/overview.html"
              },
              "improvementPlan": {
                "displayText": "You can define your key aliases as well as key-level policies. The policies help you define key administrators as well as key users. You can use the AWS KMS API to create and manage KMS keys and special features, such as custom key stores, and use KMS keys in cryptographic operations.",
                "url": "https://docs.aws.amazon.com/pdfs/wellarchitected/latest/security-pillar/wellarchitected-security-pillar.pdf#welcome"
              }
            },
            {
              "id": "SEC_10_no",
              "title": "No implementation of secure key management",
              "helpfulResource": {
                "displayText": "AWS KMS helps you manage encryption keys and integrates with many AWS services. It provides durable, secure, and redundant storage for your AWS KMS keys.",
                "url": "https://docs.aws.amazon.com/kms/latest/developerguide/overview.html"
              }
            }
          ],
          "riskRules": [
            { "condition": "SEC_10_2", "risk": "NO_RISK" },
            { "condition": "default", "risk": "MEDIUM_RISK" }
          ]
        },
        {
          "id": "SEC_11",
          "title": "Do you have secrets management?",
          "description": "How do you manage secrets, such as API keys in your document processing workflow?",
          "helpfulResource": {
            "displayText": "An IDP workflow may have secrets such as API keys in multiple services or stages, you need to have a tool to store, manage, retrieve, and rotate these secrets",
            "url": "https://aws.amazon.com/blogs/aws/aws-secrets-manager-store-distribute-and-rotate-credentials-securely/"
          },
          "choices": [
            {
              "id": "SEC_11_2",
              "title": "Use AWS Secrets Manager",
              "helpfulResource": {
                "displayText": "AWS Secrets Manager helps you manage, retrieve, and rotate database credentials, application credentials, OAuth tokens, API keys, and other secrets throughout their lifecycles. Storing the credentials in Secrets Manager helps avoid possible compromise by anyone who can inspect your application or the components.",
                "url": "https://docs.aws.amazon.com/secretsmanager/latest/userguide/intro.html"
              },
              "improvementPlan": {
                "displayText": "With Secrets Manager, you can configure an automatic rotation schedule for your secrets. This enables you to replace long-term secrets with short-term ones, significantly reducing the risk of compromise. Since the credentials are no longer stored with the application, rotating credentials no longer requires updating your applications and deploying changes to application clients.",
                "url": "https://docs.aws.amazon.com/secretsmanager/latest/userguide/intro.html"
              }
            },
            {
              "id": "SEC_11_no",
              "title": "No secrets management",
              "helpfulResource": {
                "displayText": "AWS Secrets Manager helps you manage, retrieve, and rotate database credentials, application credentials, OAuth tokens, API keys, and other secrets throughout their lifecycles. Storing the credentials in Secrets Manager helps avoid possible compromise by anyone who can inspect your application or the components.",
                "url": "https://docs.aws.amazon.com/secretsmanager/latest/userguide/intro.html"
              }
            }
          ],
          "riskRules": [
            { "condition": "SEC_11_2", "risk": "NO_RISK" },
            { "condition": "default", "risk": "MEDIUM_RISK" }
          ]
        },
        {
          "id": "SEC_12",
          "title": "Do you separate workloads using different accounts?",
          "description": "If you have multiple IDP workloads, do you separate them using different accounts?",
          "helpfulResource": {
            "displayText": "If you have multiple IDP workloads, do you separate them using different accounts?",
            "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/sec_securely_operate_multi_accounts.html"
          },
          "choices": [
            {
              "id": "SEC_12_2",
              "title": "Separate workloads using accounts",
              "helpfulResource": {
                "displayText": "Establish common guardrails and isolation between environments (such as production, development, and test) and workloads through a multi-account strategy. Account-level separation is strongly recommended, as it provides a strong isolation boundary for security, billing, and access.",
                "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/sec_securely_operate_multi_accounts.html"
              },
              "improvementPlan": {
                "displayText": "AWS provides tools to manage your cloud workloads at scale through a multi-account strategy to leverage this isolation boundary.When you have multiple AWS accounts under central management, your accounts should be organized into a hierarchy defined by layers of organizational units (OUs). Security controls can then be organized and applied to the OUs and member accounts, establishing consistent preventative controls on member accounts in the organization.",
                "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/sec_securely_operate_multi_accounts.html"
              }
            },
            {
              "id": "SEC_12_no",
              "title": "Multiple workloads are all in one account",
              "helpfulResource": {
                "displayText": "Establish common guardrails and isolation between environments (such as production, development, and test) and workloads through a multi-account strategy. Account-level separation is strongly recommended, as it provides a strong isolation boundary for security, billing, and access.",
                "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/sec_securely_operate_multi_accounts.html"
              }
            }
          ],
          "riskRules": [
            { "condition": "SEC_12_2", "risk": "NO_RISK" },
            { "condition": "default", "risk": "MEDIUM_RISK" }
          ]
        },
        {
          "id": "SEC_13",
          "title": "Do you configure IDP services and application logging?",
          "description": "During a security investigation or other use cases based on your requirements, you need to be able to review relevant logs to record and understand the full scope and timeline of the incident. Logs are also required for alert generation, indicating that certain actions of interest have happened.",
          "helpfulResource": {
            "displayText": "Retain security event logs from services and applications. This is a fundamental principle of security for audit, investigations, and operational use cases, and a common security requirement driven by governance, risk, and compliance (GRC) standards, policies, and procedures.",
            "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/sec_detect_investigate_events_app_service_logging.html"
          },
          "choices": [
            {
              "id": "SEC_13_2",
              "title": "Logging Amazon Textract and Comprehend API calls with AWS CloudTrail",
              "helpfulResource": {
                "displayText": "Both Amazon Textract and Amazon Comprehend are integrated with AWS CloudTrail, a service that provides a record of actions taken by a user, role, or an AWS service. CloudTrail captures API calls for Textract and Comprehend as events. The calls captured include calls from the service console and code calls to the service API operations.",
                "url": "https://docs.aws.amazon.com/textract/latest/dg/logging-using-cloudtrail.html"
              },
              "improvementPlan": {
                "displayText": "If you create a trail, you can enable continuous delivery of CloudTrail events to an Amazon S3 bucket, including events for Amazon Textract/Comprehend. If you don't configure a trail, you can still view the most recent events in the CloudTrail console in Event history.",
                "url": "https://docs.aws.amazon.com/textract/latest/dg/logging-using-cloudtrail.html"
              },
              "additionalResources": [
                {
                  "type": "HELPFUL_RESOURCE",
                  "content": [
                    {
                      "displayText": "Logging Amazon Comprehend API calls with AWS CloudTrail",
                      "url": "https://docs.aws.amazon.com/comprehend/latest/dg/logging-using-cloudtrail.html"
                    }
                  ]
                },
                {
                  "type": "IMPROVEMENT_PLAN",
                  "content": [
                    {
                      "displayText": "Logging Amazon Comprehend API calls with AWS CloudTrail",
                      "url": "https://docs.aws.amazon.com/comprehend/latest/dg/logging-using-cloudtrail.html"
                    }
                  ]
                }
              ]
            },
            {
              "id": "SEC_13_no",
              "title": "No specific configuration for IDP services and application logging",
              "helpfulResource": {
                "displayText": "Both Amazon Textract and Amazon Comprehend are integrated with AWS CloudTrail, a service that provides a record of actions taken by a user, role, or an AWS service. CloudTrail captures API calls for Textract and Comprehend as events. The calls captured include calls from the service console and code calls to the service API operations.",
                "url": "https://docs.aws.amazon.com/textract/latest/dg/logging-using-cloudtrail.html"
              }
            }
          ],
          "riskRules": [
            { "condition": "SEC_13_2", "risk": "NO_RISK" },
            { "condition": "default", "risk": "MEDIUM_RISK" }
          ]
        },
        {
          "id": "SEC_14",
          "title": "Do you have incident response procedures?",
          "description": "Do you have incident response procedures in place to handle potential security incidents in your doc processing system?",
          "helpfulResource": {
            "displayText": "Even with extremely mature preventive and detective controls, your organization should still put processes in place to respond to and mitigate the potential impact of security incidents.",
            "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/sec-incresp.html"
          },
          "choices": [
            {
              "id": "SEC_14_2",
              "title": "Establish incident response procedures",
              "helpfulResource": {
                "displayText": "The architecture of your workload strongly affects the ability of your teams to operate effectively during an incident, to isolate or contain systems, and to restore operations to a known good state.",
                "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/sec-incresp.html"
              },
              "improvementPlan": {
                "displayText": "Putting in place the tools and access ahead of a security incident, then routinely practicing incident response through game days, will help you verify that your architecture can accommodate timely investigation and recovery.",
                "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/sec-incresp.html"
              }
            },
            {
              "id": "SEC_14_no",
              "title": "No established incident response procedures",
              "helpfulResource": {
                "displayText": "The architecture of your workload strongly affects the ability of your teams to operate effectively during an incident, to isolate or contain systems, and to restore operations to a known good state.",
                "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/sec-incresp.html"
              }
            }
          ],
          "riskRules": [
            { "condition": "SEC_14_2", "risk": "NO_RISK" },
            { "condition": "default", "risk": "MEDIUM_RISK" }
          ]
        }
      ]
    },
    {
      "id": "reliability",
      "name": "Reliability",
      "questions": [
        {
          "id": "REL_1",
          "title": "How do you manage service quotas and constraints in your IDP workload?",
          "description": "Service quotas exist to prevent accidentally provisioning more resources than you need and to limit request rates on API operations so as to protect services from abuse. There are also resource constraints, for example, the rate that you can write/read files to/from Amazon S3.",
          "helpfulResource": {
            "displayText": "Service quotas exist to prevent accidentally provisioning more resources than you need and to limit request rates on API operations so as to protect services from abuse. There are also resource constraints, for example, the rate that you can write/read files to/from Amazon S3."
          },
          "choices": [
            {
              "id": "REL_1_2",
              "title": "Adjust Amazon Textract and Amazon Comprehend service quota values to meet your use case.",
              "helpfulResource": {
                "displayText": "When requesting an increase to a default quota, there are several recommended best practices to follow. These include smooth spiky traffic, configuring retries, and configuring exponential backoff and jitters.\nFor Amazon Textract, estimate your optimal quota values using Textract Service Quota Calculator.As an alternative to raising a request directly from the calculator, you can also use the Service quotas console.\nFor Amazon Comprehend use the Service quotas console.",
                "url": "https://docs.aws.amazon.com/textract/latest/dg/limits-quotas-explained.html"
              },
              "improvementPlan": {
                "displayText": "When requesting an increase to a default quota, there are several recommended best practices to follow. These include smooth spiky traffic, configuring retries, and configuring exponential backoff and jitters.\nFor Amazon Textract, estimate your optimal quota values using Textract Service Quota Calculator.As an alternative to raising a request directly from the calculator, you can also use the Service quotas console.\nFor Amazon Comprehend use the Service quotas console.",
                "url": "https://docs.aws.amazon.com/textract/latest/dg/limits-quotas-explained.html"
              },
              "additionalResources": [
                {
                  "type": "HELPFUL_RESOURCE",
                  "content": [
                    {
                      "displayText": "Amazon Comprehend endpoints and quotas",
                      "url": "https://docs.aws.amazon.com/general/latest/gr/comprehend.html"
                    }
                  ]
                },
                {
                  "type": "IMPROVEMENT_PLAN",
                  "content": [
                    {
                      "displayText": "Amazon Comprehend endpoints and quotas",
                      "url": "https://docs.aws.amazon.com/general/latest/gr/comprehend.html"
                    }
                  ]
                }
              ]
            },
            {
              "id": "REL_1_3",
              "title": "Be aware of unchangeable Amazon Textract and Amazon Comprehend Service Quotas, limits and contraints",
              "helpfulResource": {
                "displayText": "When designing your IDP workflow architecture, be aware of Amazon Textract and Amazon Comprehend service limits and quotas, which cannot be changed.",
                "url": "https://docs.aws.amazon.com/textract/latest/dg/limits-document.html"
              },
              "improvementPlan": {
                "displayText": "Design your IDP workflow architecture to prevent these limits from impacting reliability.",
                "url": "https://docs.aws.amazon.com/textract/latest/dg/limits-document.html"
              },
              "additionalResources": [
                {
                  "type": "HELPFUL_RESOURCE",
                  "content": [
                    {
                      "displayText": "Amazon Comprehend - Guidelines and quotas",
                      "url": "https://docs.aws.amazon.com/comprehend/latest/dg/guidelines-and-limits.html"
                    },
                    {
                      "displayText": "Amazon Comprehend - Best practices for images",
                      "url": "https://docs.aws.amazon.com/comprehend/latest/dg/idp-images-bp.html"
                    }
                  ]
                },
                {
                  "type": "IMPROVEMENT_PLAN",
                  "content": [
                    {
                      "displayText": "Amazon Comprehend - Guidelines and quotas",
                      "url": "https://docs.aws.amazon.com/comprehend/latest/dg/guidelines-and-limits.html"
                    },
                    {
                      "displayText": "Amazon Comprehend - Best practices for images",
                      "url": "https://docs.aws.amazon.com/comprehend/latest/dg/idp-images-bp.html"
                    }
                  ]
                }
              ]
            },
            {
              "id": "REL_1_4",
              "title": "Manage service quotas across accounts and regions",
              "helpfulResource": {
                "displayText": "If you are using multiple accounts or Regions, request the appropriate quotas in all environments in which your production workloads run.",
                "url": "https://docs.aws.amazon.com/pdfs/wellarchitected/latest/reliability-pillar/wellarchitected-reliability-pillar.pdf#welcome"
              },
              "improvementPlan": {
                "displayText": "If you are using multiple accounts or Regions, request the appropriate quotas in all environments in which your production workloads run.",
                "url": "https://docs.aws.amazon.com/pdfs/wellarchitected/latest/reliability-pillar/wellarchitected-reliability-pillar.pdf#welcome"
              }
            },
            {
              "id": "REL_1_no",
              "title": "No specific setup to manage service quotas or constraints in the IDP workload",
              "helpfulResource": {
                "displayText": "if you don't service quotas, such as Amazon Textract or Comprehend, or other contraints related with IDP workload"
              }
            }
          ],
          "riskRules": [
            { "condition": "REL_1_2 && REL_1_3 && REL_1_4", "risk": "NO_RISK" },
            { "condition": "default", "risk": "MEDIUM_RISK" }
          ]
        },
        {
          "id": "REL_2",
          "title": "How do you design your IDP workload to adopt to changes?",
          "description": "Changes to your workload or its environment must be anticipated and accommodated to achieve reliable operation of the workload. Changes include those imposed on your workload such as spikes in demand, as well as those from within such as feature deployments and security patches.",
          "helpfulResource": {
            "displayText": "Changes to your workload or its environment must be anticipated and accommodated to achieve reliable operation of the workload. Changes include those imposed on your workload such as spikes in demand, as well as those from within such as feature deployments and security patches."
          },
          "choices": [
            {
              "id": "REL_2_2",
              "title": "Use Amazon Comprehend flywheel to simplify the process of improving a custom model over time.",
              "helpfulResource": {
                "displayText": "Use Amazon Comprehend flywheel to simplify the process of improving a custom model over time. You can create a flywheel to use an existing trained model or create and train a new one. Flywheel orchestrate the tasks associated with training and evaluating new custom model versions.",
                "url": "https://aws.amazon.com/blogs/machine-learning/simplify-continuous-learning-of-amazon-comprehend-custom-models-using-comprehend-flywheel/"
              },
              "improvementPlan": {
                "displayText": "Use Amazon Comprehend flywheel to simplify the process of improving a custom model over time. You can create a flywheel to use an existing trained model or create and train a new one. Flywheel orchestrate the tasks associated with training and evaluating new custom model versions.",
                "url": "https://aws.amazon.com/blogs/machine-learning/simplify-continuous-learning-of-amazon-comprehend-custom-models-using-comprehend-flywheel"
              },
              "additionalResources": [
                {
                  "type": "HELPFUL_RESOURCE",
                  "content": [
                    {
                      "displayText": "Amazon Comprehend Flywheels simplifies the process of improving a custom model over time.",
                      "url": "https://docs.aws.amazon.com/comprehend/latest/dg/flywheels.html"
                    }
                  ]
                },
                {
                  "type": "IMPROVEMENT_PLAN",
                  "content": [
                    {
                      "displayText": "Amazon Comprehend Flywheels simplifies the process of improving a custom model over time.",
                      "url": "https://docs.aws.amazon.com/comprehend/latest/dg/flywheels.html"
                    }
                  ]
                }
              ]
            },
            {
              "id": "REL_2_3",
              "title": "Monitor, send notifications and automate responses using Amazon CloudWatch",
              "helpfulResource": {
                "displayText": "Use Amazon CloudWatch to monitor your IDP workflow component, such as Amazon Textract and Amazon Comprehend. Collect metrics from IDP workflow components, automate response to alarms and send notifications as required to your workload",
                "url": "https://docs.aws.amazon.com/comprehend/latest/dg/manage-endpoints-monitor.html"
              },
              "improvementPlan": {
                "displayText": "Use Amazon CloudWatch to monitor Amazon Comprehend document classification and entity recognizer endpoints",
                "url": "https://docs.aws.amazon.com/comprehend/latest/dg/manage-endpoints-monitor.html"
              },
              "additionalResources": [
                {
                  "type": "HELPFUL_RESOURCE",
                  "content": [
                    {
                      "displayText": "Amazon Comprehend - Auto scaling with endpoints",
                      "url": "https://docs.aws.amazon.com/comprehend/latest/dg/comprehend-autoscaling.html"
                    },
                    {
                      "displayText": "Monitoring Amazon Textract",
                      "url": "https://docs.aws.amazon.com/textract/latest/dg/textract-monitoring.html"
                    }
                  ]
                },
                {
                  "type": "IMPROVEMENT_PLAN",
                  "content": [
                    {
                      "displayText": "Amazon Comprehend - Use auto scaling feature to automatically set endpoint provisioning to fit your capacity needs.",
                      "url": "https://docs.aws.amazon.com/comprehend/latest/dg/comprehend-autoscaling.html"
                    },
                    {
                      "displayText": "Use Amazon CloudWatch to monitor Amazon Textract metrics, such as request errors, latency or if your application has reached the maximum number of requests per second.",
                      "url": "https://docs.aws.amazon.com/textract/latest/dg/textract-monitoring.html"
                    },
                    {
                      "displayText": "Use Amazon CloudWatch alarms to notify you when one or more metrics fall outside a defined threshold.",
                      "url": "https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/AlarmThatSendsEmail.html"
                    }
                  ]
                }
              ]
            },
            {
              "id": "REL_2_4",
              "title": "Use IaC, such as CDK and pre-built IDP CDK constructs to deploy IDP workflows",
              "helpfulResource": {
                "displayText": "Deploy all changes with automation, using IaC, removes the potential for introduction of human error and provides the ability to test before changing production environment",
                "url": "https://github.com/aws-samples/amazon-textract-idp-cdk-constructs"
              },
              "improvementPlan": {
                "displayText": "Deploy all changes with automation, using IaC, removes the potential for introduction of human error and provides the ability to test before changing production environment",
                "url": "https://github.com/aws-samples/amazon-textract-idp-cdk-constructs"
              },
              "additionalResources": [
                {
                  "type": "HELPFUL_RESOURCE",
                  "content": [
                    {
                      "displayText": "Amazon Textract IDP Stack Samples",
                      "url": "https://github.com/aws-solutions-library-samples/guidance-for-low-code-intelligent-document-processing-on-aws"
                    }
                  ]
                },
                {
                  "type": "IMPROVEMENT_PLAN",
                  "content": [
                    {
                      "displayText": "Amazon Textract IDP Stack Samples",
                      "url": "https://github.com/aws-solutions-library-samples/guidance-for-low-code-intelligent-document-processing-on-aws"
                    }
                  ]
                }
              ]
            },
            {
              "id": "REL_2_no",
              "title": "None of these"
            }
          ],
          "riskRules": [
            { "condition": "REL_2_2 && REL_2_3 && REL_2_4", "risk": "NO_RISK" },
            { "condition": "default", "risk": "MEDIUM_RISK" }
          ]
        },
        {
          "id": "REL_3",
          "title": "How do you prepare your IDP workflow to manage and withstand failures?",
          "description": "In any system of reasonable complexity, it is expected that failures will occur. Reliability requires that your workload be aware of failures as they occur and take action to avoid impact on availability. Workloads must be able to both withstand failures and automatically repair issues.",
          "helpfulResource": {
            "displayText": "In any system of reasonable complexity, it is expected that failures will occur. Reliability requires that your workload be aware of failures as they occur and take action to avoid impact on availability. Workloads must be able to both withstand failures and automatically repair issues."
          },
          "choices": [
            {
              "id": "REL_3_2",
              "title": "Use Amazon S3 as your scalable datastore for IDP workflow Data capture stage.",
              "helpfulResource": {
                "displayText": "Amazon S3 provides a highly durable storage infrastructure designed for mission-critical and primary data storage.",
                "url": "https://docs.aws.amazon.com/AmazonS3/latest/userguide/DataDurability.html"
              },
              "improvementPlan": {
                "displayText": "Consider Amazon S3 cross-region replication to futher increase the reliability and take advantage of disaster recovery options",
                "url": "https://docs.aws.amazon.com/AmazonS3/latest/userguide/DataDurability.html"
              },
              "additionalResources": [
                {
                  "type": "HELPFUL_RESOURCE",
                  "content": [
                    {
                      "displayText": "Protect Data on Amazon S3 Against Accidental Deletion or Application Bugs Using S3 Versioning, S3 Object Lock, and S3 Replication",
                      "url": "https://aws.amazon.com/getting-started/hands-on/protect-data-on-amazon-s3/?ref=docs_gateway/amazons3/DataDurability.html"
                    }
                  ]
                },
                {
                  "type": "IMPROVEMENT_PLAN",
                  "content": [
                    {
                      "displayText": "Protect Data on Amazon S3 Against Accidental Deletion or Application Bugs Using S3 Versioning, S3 Object Lock, and S3 Replication",
                      "url": "https://aws.amazon.com/getting-started/hands-on/protect-data-on-amazon-s3/?ref=docs_gateway/amazons3/DataDurability.html"
                    }
                  ]
                }
              ]
            },
            {
              "id": "REL_3_3",
              "title": "Identify and back up IDP workflow data that needs to be backed up.",
              "helpfulResource": {
                "displayText": "Back up all IDP workflow data according to your business requirements. In case of data lost, the strategy implemented allows recovery or the reproduction of data within the defined RPO and RTO.",
                "url": "https://docs.aws.amazon.com/wellarchitected/latest/reliability-pillar/rel_backing_up_data_identified_backups_data.html"
              },
              "improvementPlan": {
                "displayText": "Back up all IDP workflow data according to your business requirements. Analyse the storage for your IDP Data Capture and consumption stages. Then, establish a strategy for data recovery based on the RPO. This strategy involves either backing up these data sources, or having the ability to reproduce data from other sources. In case of data lodd, the strategy implemented allows recovery or the reproduction of data within the defined RPO and RTO.",
                "url": "https://docs.aws.amazon.com/wellarchitected/latest/reliability-pillar/rel_backing_up_data_identified_backups_data.html"
              },
              "additionalResources": [
                {
                  "type": "HELPFUL_RESOURCE",
                  "content": [
                    {
                      "displayText": "Disaster recovery options in the cloud",
                      "url": "https://docs.aws.amazon.com/whitepapers/latest/disaster-recovery-workloads-on-aws/disaster-recovery-options-in-the-cloud.html"
                    }
                  ]
                },
                {
                  "type": "IMPROVEMENT_PLAN",
                  "content": [
                    {
                      "displayText": "Disaster recovery options in the cloud",
                      "url": "https://docs.aws.amazon.com/whitepapers/latest/disaster-recovery-workloads-on-aws/disaster-recovery-options-in-the-cloud.html"
                    }
                  ]
                }
              ]
            },
            {
              "id": "REL_3_4",
              "title": "Design your workload architecture following the IDP workflow",
              "helpfulResource": {
                "displayText": "Although the stages in an IDP workflow may vary and be influenced by use case and business requirements, the stages of data capture, document classification, text extraction, content enrichment, review/validation, and consumption are typically parts of an IDP workflow. Processing documents such as tax forms, claims, medical notes, new customer forms, invoices, legal contracts, and more are just a few of the use cases for IDP.",
                "url": "https://docs.aws.amazon.com/wellarchitected/latest/reliability-pillar/rel_service_architecture_monolith_soa_microservice.html"
              },
              "improvementPlan": {
                "displayText": "Although the stages in an IDP workflow may vary and be influenced by use case and business requirements, the stages of data capture, document classification, text extraction, content enrichment, review/validation, and consumption are typically parts of an IDP workflow. Processing documents such as tax forms, claims, medical notes, new customer forms, invoices, legal contracts, and more are just a few of the use cases for IDP.",
                "url": "https://docs.aws.amazon.com/wellarchitected/latest/reliability-pillar/rel_service_architecture_monolith_soa_microservice.html"
              },
              "additionalResources": [
                {
                  "type": "HELPFUL_RESOURCE",
                  "content": [
                    {
                      "displayText": "AWS Machine Learning Blog: Intelligent document processing with AWS AI services: Part 1",
                      "url": "https://aws.amazon.com/blogs/machine-learning/part-1-intelligent-document-processing-with-aws-ai-services/"
                    }
                  ]
                },
                {
                  "type": "IMPROVEMENT_PLAN",
                  "content": [
                    {
                      "displayText": "AWS Machine Learning Blog: Intelligent document processing with AWS AI services: Part 1",
                      "url": "https://aws.amazon.com/blogs/machine-learning/part-1-intelligent-document-processing-with-aws-ai-services/"
                    }
                  ]
                }
              ]
            },
            {
              "id": "REL_3_5",
              "title": "Implement loosely coupled IDP workflow stages",
              "helpfulResource": {
                "displayText": "Use Amazon SQS to decouple an IDP architecture. Decoupling pattern helps to isolate behavior of architecture components from other components that depend on it, increasing resiliency and agility.",
                "url": "https://docs.aws.amazon.com/wellarchitected/latest/reliability-pillar/rel_prevent_interaction_failure_loosely_coupled_system.html"
              },
              "improvementPlan": {
                "displayText": "Use Amazon SQS to decouple an IDP workflow stages",
                "url": "https://docs.aws.amazon.com/wellarchitected/latest/reliability-pillar/rel_prevent_interaction_failure_loosely_coupled_system.html"
              },
              "additionalResources": [
                {
                  "type": "HELPFUL_RESOURCE",
                  "content": [
                    {
                      "displayText": "Best Practices for Service Quota Increase Requests",
                      "url": "https://docs.aws.amazon.com/textract/latest/dg/limits-quotas-explained.html#best-quota-practices"
                    }
                  ]
                },
                {
                  "type": "IMPROVEMENT_PLAN",
                  "content": [
                    {
                      "displayText": "Best Practices for Service Quota Increase Requests",
                      "url": "https://docs.aws.amazon.com/textract/latest/dg/limits-quotas-explained.html#best-quota-practices"
                    }
                  ]
                }
              ]
            },
            {
              "id": "REL_3_6",
              "title": "Control and limit retry calls",
              "helpfulResource": {
                "displayText": "An Amazon Textract operation can fail if you exceed the maximum number of transactions per second (TPS), causing the service to throttle your application, or when your connection drops. For example, if you make too many calls to Amazon Textract operations in a short period of time.\nYou can manage throttling and dropped connections by automatically retrying the operation. You can specify the number of retries by including the Config parameter when you create the Amazon Textract client. We recommend a retry count of 5. The AWS SDK retries an operation the specified number of times before failing and throwing an exception.",
                "url": "https://docs.aws.amazon.com/textract/latest/dg/handling-errors.html"
              },
              "improvementPlan": {
                "displayText": "Use exponential backoff to retry requests at progressively longer intervals between each retry. Introduce jitter between retries to randomize retry intervals. Limit the maximum number of retries.",
                "url": "https://docs.aws.amazon.com/textract/latest/dg/handling-errors.html"
              },
              "additionalResources": [
                {
                  "type": "HELPFUL_RESOURCE",
                  "content": [
                    {
                      "displayText": "Retry behavior",
                      "url": "https://docs.aws.amazon.com/sdkref/latest/guide/feature-retry-behavior.html"
                    }
                  ]
                },
                {
                  "type": "IMPROVEMENT_PLAN",
                  "content": [
                    {
                      "displayText": "Retry behavior",
                      "url": "https://docs.aws.amazon.com/sdkref/latest/guide/feature-retry-behavior.html"
                    }
                  ]
                }
              ]
            },
            {
              "id": "REL_3_no",
              "title": "None of these"
            }
          ],
          "riskRules": [
            {
              "condition": "REL_3_2 && REL_3_3 && REL_3_4 && REL_3_5 && REL_3_6",
              "risk": "NO_RISK"
            },
            { "condition": "default", "risk": "MEDIUM_RISK" }
          ]
        }
      ]
    },
    {
      "id": "performance",
      "name": "Performance Efficiency",
      "questions": [
        {
          "id": "PERF_1",
          "title": "Does your solution follow the IDP workflow?",
          "description": "The stages in an IDP workflow may vary and be influenced by use case and business requirements. However in general, an IDP workflow includes some typical stages",
          "helpfulResource": {
            "displayText": "The stages in an IDP workflow may vary and be influenced by use case and business requirements. However in general, an IDP workflow includes some typical stages",
            "url": "https://aws.amazon.com/blogs/machine-learning/part-1-intelligent-document-processing-with-aws-ai-services/"
          },

          "choices": [
            {
              "id": "PERF_1_1",
              "title": "The project includes six phases in the workload.",
              "helpfulResource": {
                "displayText": "Although the stages in an IDP workflow may vary and be influenced by use case and business requirements, the stages of data capture, document classification, text extraction, content enrichment, review/validation, and consumption are typically parts of an IDP workflow. Processing documents such as tax forms, claims, medical notes, new customer forms, invoices, legal contracts, and more are just a few of the use cases for IDP.",
                "url": "https://aws.amazon.com/machine-learning/ml-use-cases/document-processing/"
              },
              "improvementPlan": {
                "displayText": "The stages in an IDP workflow may vary and be influenced by use case and business requirements. However in general, an IDP workflow includes some typical stages. See links below"
              },
              "additionalResources": [
                {
                  "type": "HELPFUL_RESOURCE",
                  "content": [
                    {
                      "displayText": "Intelligent document processing with AWS AI services",
                      "url": "https://aws.amazon.com/blogs/machine-learning/part-1-intelligent-document-processing-with-aws-ai-services/"
                    },
                    {
                      "displayText": "Guidance for Intelligent Document Processing on AWS",
                      "url": "https://aws.amazon.com/solutions/guidance/intelligent-document-processing-on-aws/"
                    }
                  ]
                }
              ]
            },
            {
              "id": "PERF_1_2",
              "title": "The project includes 3-5 phases in the workload.",
              "helpfulResource": {
                "displayText": "Although the stages in an IDP workflow may vary and be influenced by use case and business requirements, the stages of data capture, document classification, text extraction, content enrichment, review/validation, and consumption are typically parts of an IDP workflow. Processing documents such as tax forms, claims, medical notes, new customer forms, invoices, legal contracts, and more are just a few of the use cases for IDP.",
                "url": "https://aws.amazon.com/machine-learning/ml-use-cases/document-processing/"
              },
              "improvementPlan": {
                "displayText": "Design multiple stages in IDP workflow - part 1",
                "url": "https://aws.amazon.com/blogs/machine-learning/part-1-intelligent-document-processing-with-aws-ai-services/"
              },
              "additionalResources": [
                {
                  "type": "IMPROVEMENT_PLAN",
                  "content": [
                    {
                      "displayText": "Design multiple stages in IDP workflow - part 2",
                      "url": "https://aws.amazon.com/blogs/machine-learning/part-2-intelligent-document-processing-with-aws-ai-services/"
                    }
                  ]
                },
                {
                  "type": "HELPFUL_RESOURCE",
                  "content": [
                    {
                      "displayText": "Intelligent document processing with AWS AI services",
                      "url": "https://aws.amazon.com/blogs/machine-learning/part-1-intelligent-document-processing-with-aws-ai-services/"
                    },
                    {
                      "displayText": "Guidance for Intelligent Document Processing on AWS",
                      "url": "https://aws.amazon.com/solutions/guidance/intelligent-document-processing-on-aws/"
                    }
                  ]
                }
              ]
            },
            {
              "id": "PERF_1_3",
              "title": "The project includes 0-2 phases in the workload.",
              "helpfulResource": {
                "displayText": "Although the stages in an IDP workflow may vary and be influenced by use case and business requirements, the stages of data capture, document classification, text extraction, content enrichment, review/validation, and consumption are typically parts of an IDP workflow. Processing documents such as tax forms, claims, medical notes, new customer forms, invoices, legal contracts, and more are just a few of the use cases for IDP.",
                "url": "https://aws.amazon.com/machine-learning/ml-use-cases/document-processing/"
              },
              "improvementPlan": {
                "displayText": "Design multiple stages in IDP workflow - part 1",
                "url": "https://aws.amazon.com/blogs/machine-learning/part-1-intelligent-document-processing-with-aws-ai-services/"
              },
              "additionalResources": [
                {
                  "type": "IMPROVEMENT_PLAN",
                  "content": [
                    {
                      "displayText": "Design multiple stages in IDP workflow - part 2",
                      "url": "https://aws.amazon.com/blogs/machine-learning/part-2-intelligent-document-processing-with-aws-ai-services/"
                    }
                  ]
                },
                {
                  "type": "HELPFUL_RESOURCE",
                  "content": [
                    {
                      "displayText": "Intelligent document processing with AWS AI services",
                      "url": "https://aws.amazon.com/blogs/machine-learning/part-1-intelligent-document-processing-with-aws-ai-services/"
                    },
                    {
                      "displayText": "Guidance for Intelligent Document Processing on AWS",
                      "url": "https://aws.amazon.com/solutions/guidance/intelligent-document-processing-on-aws/"
                    }
                  ]
                }
              ]
            },
            {
               "id": "PERF_1_no",
               "title": "None of these"
            }
          ],
          "riskRules": [
            { "condition": "PERF_1_1 || PERF_1_2", "risk": "NO_RISK" },
            { "condition": "PERF_1_3", "risk": "MEDIUM_RISK" },
            { "condition": "default", "risk": "HIGH_RISK" }
          ]
        },
        {
          "id": "PERF_2",
          "title": "How do you decouple the IDP architecture components when document volume is high?",
          "description": "For instance, you need to process more than 50 documents in Ireland region, which is higher than the maximum number of asynchronous Analyze Lending jobs that can simultaneously exist. When thedocument volume is over thanTextract service quotas, we need to decouple an IDP architecture to avoid throttling issue, as well as for better extendability and performance efficiency.",
          "helpfulResource": {
            "displayText": "For instance, you need to process more than 50 documents in Ireland region, which is higher than the maximum number of asynchronous Analyze Lending jobs that can simultaneously exist. When thedocument volume is over thanTextract service quotas, we need to decouple an IDP architecture to avoid throttling issue, as well as for better extendability and performance efficiency.",
            "url": "https://docs.aws.amazon.com/textract/latest/dg/async-analyzing-with-sqs.html"
          },
          "choices": [
            {
              "id": "PERF_2_2",
              "title": "Use Amazon SQS to decouple an IDP architecture",
              "helpfulResource": {
                "displayText": "You can use Amazon SQS between service components of your architecture to decouple an architecture. Or you can consider using Amazon Textract IDP CDK Constructs which has built-in SQS to implement an IDP architecture.",
                "url": "https://docs.aws.amazon.com/textract/latest/dg/async-analyzing-with-sqs.html, https://catalog.us-east-1.prod.workshops.aws/workshops/f2dd7c46-e022-4f9c-8399-dcad742be516/en-US/lab-3/step-3a"
              },
              "improvementPlan": {
                "displayText": "Decouple an IDP architecture using Amazon SQS, Amazon Textract async API, or leverage Amazon Textract IDP CDK Constructs to do the decoupling implementation ",
                "url": "https://docs.aws.amazon.com/general/latest/gr/textract.html"
              },
              "additionalResources": [
                {
                  "type": "IMPROVEMENT_PLAN",
                  "content": [
                    {
                      "displayText": "Detecting or Analyzing Text in a Multipage Document",
                      "url": "https://docs.aws.amazon.com/textract/latest/dg/async-analyzing-with-sqs.html"
                    },
                    {
                      "displayText": "Amazon Textract IDP CDK Constructs",
                      "url": "https://catalog.us-east-1.prod.workshops.aws/workshops/f2dd7c46-e022-4f9c-8399-dcad742be516/en-US/lab-3/step-3a"
                    },
                    {
                      "displayText": "Calling Amazon Textract Synchronous Operations",
                      "url": "https://docs.aws.amazon.com/textract/latest/dg/sync-calling.html"
                    }
                  ]
                }
              ]
            },
            {
              "id": "PERF_2_3",
              "title": "Leverage async APIs to decouple an IDP architecture",
              "helpfulResource": {
                "displayText": "Async APIs can be used to handling event-based processing, long-running tasks, highly concurrent systems, rate limit scenarios, and distributed systems.",
                "url": "https://docs.aws.amazon.com/textract/latest/dg/sync-calling.html"
              },
              "improvementPlan": {
                "displayText": "Processing Documents with Asynchronous Operations",
                "url": "https://docs.aws.amazon.com/textract/latest/dg/async.html"
              }
            },
            {
              "id": "PERF_2_no",
              "title": "Do not monitor the user traffic, not clear about the highest TPS for the workload.",
              "helpfulResource": {
                "displayText": "You can useAmazon Textract endpoints and quotas to help you evaluate the critial API calls.",
                "url": "https://docs.aws.amazon.com/general/latest/gr/textract.html"
              }
            }
          ],
          "riskRules": [
            { "condition": "PERF_2_2 && PERF_2_3", "risk": "NO_RISK" },
            { "condition": "default", "risk": "HIGH_RISK" }
          ]
        },
        {
          "id": "PERF_3",
          "title": "Use of output config to scale the async workload",
          "description": "(For Async Workload) Use of output config to scale the async workload.This will mitigate customers hitting throttling on Get requests (GetDocumentAnalysis or GetDocumentTextDetection) as they can directly consume the output from their S3 bucket.",
          "helpfulResource": {
            "displayText": "(For Async Workload) Use of output config to scale the async workload.This will mitigate customers hitting throttling on Get requests (GetDocumentAnalysis or GetDocumentTextDetection) as they can directly consume the output from their S3 bucket.",
            "url": "https://docs.aws.amazon.com/textract/latest/dg/API_OutputConfig.html"
          },
          "choices": [
            {
              "id": "PERF_3_1",
              "title": "Optimise with Output Config",
              "helpfulResource": {
                "displayText": "Use OutputConfig when making Textract API async requests.",
                "url": "https://aws.amazon.com/blogs/machine-learning/store-output-in-custom-amazon-s3-bucke[]-kms-for-multi-page-document-processing-with-amazon-textract/"
              },
              "improvementPlan": {
                "displayText": "Use OutputConfig when making Textract API async requests.",
                "url": "https://docs.aws.amazon.com/textract/latest/dg/API_OutputConfig.html"
              },
              "additionalResources": [
                {
                  "type": "IMPROVEMENT_PLAN",
                  "content": [
                    {
                      "displayText": "Store output in custom Amazon S3 bucket",
                      "url": "https://aws.amazon.com/blogs/machine-learning/store-output-in-custom-amazon-s3-bucket-and-encrypt-using-aws-kms-for-multi-page-document-processing-with-amazon-textract/"
                    }
                  ]
                }
              ]
            },
            {
              "id": "PERF_3_no",
              "title": "We do not use Output Config to scale the async workload"
            }
          ],
          "riskRules": [
            { "condition": "PERF_3_1", "risk": "NO_RISK" },
            { "condition": "default", "risk": "MEDIUM_RISK" }
          ]
        },
        {
          "id": "PERF_4",
          "title": "Are the limits for TPS configured correct for the production workload. Start API TPS, job queue limit, token bucket for proces",
          "description": "Use the TPS calculator in the Textract console to identify the TPS limits needed for your workload. Start APIs include, StartDocumentAnalysis, StartDocumentTextDetection, StartExpenseAnalysis, and StartLendingAnalysis.",
          "helpfulResource": {
            "displayText": "TPS refers to the number of Textract API calls (Detect Document Text, Analyze Document, etc.) per second that your workload will need.Depending on the type and complexity of your documents, each API call may process 1 page or multiple pages of a document.",
            "url": "https://docs.aws.amazon.com/textract/latest/dg/limits-quotas-explained.html"
          },
          "choices": [
            {
              "id": "PERF_4_2",
              "title": "Have used TPS calculator to identify the workload limitation.",
              "helpfulResource": {
                "displayText": "Have used TPS calculator to identify the workload limitation.",
                "url": "https://docs.aws.amazon.com/textract/latest/dg/limits-quotas-explained.html"
              },
              "improvementPlan": {
                "displayText": "Use TPS Calculator to indentify the workload limitation",
                "url": "https://docs.aws.amazon.com/general/latest/gr/textract.html"
              }
            },
            {
              "id": "PERF_4_no",
              "title": "Have not used TPS calculator to identify the workload limitation.",
              "helpfulResource": {
                "displayText": "Have not used TPS calculator to identify the workload limitation.",
                "url": "https://docs.aws.amazon.com/textract/latest/dg/limits-quotas-explained.html"
              }
            }
          ],
          "riskRules": [
            { "condition": "PERF_4_2", "risk": "NO_RISK" },
            { "condition": "default", "risk": "MEDIUM_RISK" }
          ]
        },
        {
          "id": "PERF_6",
          "title": "Are documents processed in parellel or sequential?",
          "description": "Process documents or pages in parallel, not sequential.\nPre-processing or post-processing steps should be performed in parallel when they dont have dependencies.",
          "helpfulResource": {
            "displayText": "Process documents or pages in parallel, not sequential.\nPre-processing or post-processing steps should be performed in parallel when they dont have dependencies.",
            "url": "https://docs.aws.amazon.com/step-functions/latest/dg/amazon-states-language-parallel-state.html"
          },
          "choices": [
            {
              "id": "PERF_6_1",
              "title": "Use a Step Funtion's Parellel state to perform mutiple functions at the same time.",
              "helpfulResource": {
                "displayText": "A Parallel state causes AWS Step Functions to execute each branch, starting with the state named in that branch's StartAt field, as concurrently as possible, and wait until all branches terminate (reach a terminal state) before processing the Parallel state's Next field.",
                "url": "https://docs.aws.amazon.com/step-functions/latest/dg/amazon-states-language-parallel-state.html"
              },
              "improvementPlan": {
                "displayText": "Use a Step Funtion's Parellel state to perform mutiple functions at the same time.",
                "url": "https://docs.aws.amazon.com/step-functions/latest/dg/amazon-states-language-parallel-state.html"
              }
            },
            {
              "id": "PERF_6_no",
              "title": "Does not use a Step Funtion's Parellel state to perform mutiple functions at the same time.",
              "helpfulResource": {
                "displayText": "A Parallel state causes AWS Step Functions to execute each branch, starting with the state named in that branch's StartAt field, as concurrently as possible, and wait until all branches terminate (reach a terminal state) before processing the Parallel state's Next field.",
                "url": "https://docs.aws.amazon.com/step-functions/latest/dg/amazon-states-language-parallel-state.html"
              }
            }
          ],
          "riskRules": [
            { "condition": "PERF_6_1", "risk": "NO_RISK" },
            { "condition": "default", "risk": "MEDIUM_RISK" }
          ]
        },
        {
          "id": "PERF_7",
          "title": "When using Textract Start APIs do the Lambda function wait for a response before continuing?",
          "description": "If the Start API is call and the Lambda waits for the job to finish, the job could exceed the Lambda timeout. if it exceeds the Lambda timeout, the function will terminate and restart, leading to multiple calls to the Textract service. This will incur additional cost and the execution of the call will not be successful.",
          "helpfulResource": {
            "displayText": "If the Start API is call and the Lambda waits for the job to finish, the job could exceed the Lambda timeout. if it exceeds the Lambda timeout, the function will terminate and restart, leading to multiple calls to the Textract service. This will incur additional cost and the execution of the call will not be successful.",
            "url": "https://docs.aws.amazon.com/textract/latest/dg/API_StartDocumentAnalysis.html"
          },
          "choices": [
            {
              "id": "PERF_7_1",
              "title": "Use queues to handle Textract API responses.",
              "helpfulResource": {
                "displayText": "StartDocumentAnalysis returns a job identifier (JobId) that you use to get the results of the operation. When text analysis is finished, Amazon Textract publishes a completion status to the Amazon Simple Notification Service (Amazon SNS) topic that you specify in NotificationChannel. To get the results of the text analysis operation, first check that the status value published to the Amazon SNS topic is SUCCEEDED. If so, call GetDocumentAnalysisand pass the job identifier (JobId) from the initial call to StartDocumentAnalysis.",
                "url": "https://docs.aws.amazon.com/textract/latest/dg/API_StartDocumentAnalysis.html"
              },
              "improvementPlan": {
                "displayText": "Use queues to handle Textract API responses.",
                "url": "https://docs.aws.amazon.com/textract/latest/dg/API_StartDocumentAnalysis.html"
              }
            },
            {
              "id": "PERF_7_2",
              "title": "Handling Throttled Calls and Dropped Connections",
              "helpfulResource": {
                "displayText": "You can manage throttling and dropped connections by automatically retrying the operation. You can specify the number of retries by including the Config parameter when you create the Amazon Textract client. We recommend a retry count of 5. The AWS SDK retries an operation the specified number of times before failing and throwing an exception.",
                "url": "https://docs.aws.amazon.com/textract/latest/dg/handling-errors.html"
              },
              "improvementPlan": {
                "displayText": "Handling Throttled Calls and Dropped Connections",
                "url": "https://docs.aws.amazon.com/textract/latest/dg/handling-errors.html"
              }
            },
            {
              "id": "PERF_7_no",
              "title": "Lambda function always waits for a response before continue",
              "helpfulResource": {
                "displayText": "You can manage throttling and dropped connections by automatically retrying the operation. You can specify the number of retries by including the Config parameter when you create the Amazon Textract client. We recommend a retry count of 5. The AWS SDK retries an operation the specified number of times before failing and throwing an exception.",
                "url": "https://docs.aws.amazon.com/textract/latest/dg/handling-errors.html"
              }
            }
          ],
          "riskRules": [
            { "condition": "PERF_7_1 || PERF_7_2", "risk": "NO_RISK" },
            { "condition": "default", "risk": "MEDIUM_RISK" }
          ]
        },
        {
          "id": "PERF_8",
          "title": "What type of storage do you use for the Data capture phase in the IDP workflow?",
          "description": "IDP workflow starts with a data capture stage to securely store and aggregate different file formats (PDF, JPEG, PNG, TIFF) and layouts of documents from different sources.",
          "helpfulResource": {
            "displayText": "IDP workflow starts with a data capture stage to securely store and aggregate different file formats (PDF, JPEG, PNG, TIFF) and layouts of documents from different sources. ",
            "url": "https://docs.aws.amazon.com/s3/index.html"
          },
          "choices": [
            {
              "id": "PERF_8_1",
              "title": "Use S3 to securely store documents for the IDP",
              "helpfulResource": {
                "displayText": "S3 is highly scalable and durable storage. itoffers industry-leading scalability, data availability, security, and performance. Amazon S3 is designed for 11 9s of durability.",
                "url": "https://aws.amazon.com/blogs/machine-learning/part-1-intelligent-document-processing-with-aws-ai-services/"
              },
              "improvementPlan": {
                "displayText": "Use S3 to securely store documents for the IDP",
                "url": "https://aws.amazon.com/blogs/machine-learning/part-1-intelligent-document-processing-with-aws-ai-services/"
              }
            },
            {
              "id": "PERF_8_2",
              "title": "Use DynamoDB to securely store documents for the IDP",
              "helpfulResource": {
                "displayText": "Amazon DynamoDB is a fully managed, serverless, key-value NoSQL database designed to run high-performance applications at any scale.",
                "url": "https://docs.aws.amazon.com/dynamodb/"
              },
              "improvementPlan": {
                "displayText": "The document metadata, and extracted information can store at DynamoDB.",
                "url": "https://aws.amazon.com/blogs/machine-learning/real-estate-brokerage-firm-john-l-scott-uses-amazon-textract-and-amazon-comprehend-to-strike-racially-restrictive-language-from-property-deeds-for-homeowners/"
              }
            },
            {
              "id": "PERF_8_3",
              "title": "Use Kendra or other Vector Storage to securely store documents for the IDP",
              "helpfulResource": {
                "displayText": "Amazon Kendra is an intelligent enterprise search service that helps you search across different content repositories with built-in connectors.",
                "url": "https://docs.aws.amazon.com/kendra/"
              },
              "improvementPlan": {
                "displayText": "The document metadata, and extracted information can store at Kendra for document retrieval later.",
                "url": "https://aws.amazon.com/blogs/machine-learning/augment-search-with-metadata-by-chaining-amazon-textract-amazon-comprehend-and-amazon-kendra/"
              },
              "additionalResources": [
                {
                  "type": "IMPROVEMENT_PLAN",
                  "content": [
                    {
                      "displayText": "AWS Machine Learning Blog : Bring structure to diverse documents with Amazon Textract and transformer-based models on Amazon SageMaker",
                      "url": "https://aws.amazon.com/blogs/machine-learning/bring-structure-to-diverse-documents-with-amazon-textract-and-transformer-based-models-on-amazon-sagemaker/"
                    }
                  ]
                }
              ]
            },
            {
              "id": "PERF_8_no",
              "title": "Others",
              "helpfulResource": {
                "displayText": "Other AWS services",
                "url": "https://docs.aws.amazon.com/"
              }
            }
          ],
          "riskRules": [
            {
              "condition": "PERF_8_1 || PERF_8_2 || PERF_8_3",
              "risk": "NO_RISK"
            },
            { "condition": "default", "risk": "MEDIUM_RISK" }
          ]
        },
        {
          "id": "PERF_9",
          "title": "How do you get notification and setup retry mechanism when a document fails?",
          "description": "How do you receive notifications or alerts when document processing fails?  Are there mechanisms in place to notify relevant stakeholders or trigger automated actions based on the failiure events?Do you have defined process (auto/manual) for resolving failed document processing, including the identification of root causes and subsequent corrective actions?\n\nWhat is your approach to handling failed documents? \n\nHave you implemented a retry mechanism to auto retry failed document processing attempts? Does your retry mechanism implement strategies such as exponential backoff/Client Side Rate Limiting to avoid running into TPS limits?",
          "helpfulResource": {
            "displayText": "An Amazon Textract operation can fail if you exceed the maximum number of transactions per second (TPS), causing the service to throttle your application, or when your connection drops. For example, if you make too many calls to Amazon Textract operations in a short period of time, it throttles your calls and sends a ProvisionedThroughputExceededException error in the operation response. For information about Amazon Textract TPS quotas, see Amazon Textract Quotas. To change a limit, you can access the Amazon Textract option in the Service Quotas console.\nYou can manage throttling and dropped connections by automatically retrying the operation. You can specify the number of retries by including the Config parameter when you create the Amazon Textract client. We recommend a retry count of 5. The AWS SDK retries an operation the specified number of times before failing and throwing an exception. For more information, see Error Retries and Exponential Backoff in AWS.",
            "url": "https://docs.aws.amazon.com/sdkref/latest/guide/feature-retry-behavior.html"
          },
          "choices": [
            {
              "id": "PERF_9_2",
              "title": "Config the error handing of exceeding the maximum transactions per second (TPS) limit",
              "helpfulResource": {
                "displayText": "Config the error handing of exceeding the maximum transactions per second (TPS) limit",
                "url": "https://docs.aws.amazon.com/general/latest/gr/textract.html"
              },
              "improvementPlan": {
                "displayText": "Config the error handing of exceeding the maximum transactions per second (TPS) limit",
                "url": "https://docs.aws.amazon.com/sdkref/latest/guide/feature-retry-behavior.html"
              }
            },
            {
              "id": "PERF_9_3",
              "title": "Setup the exponential backoff on AWS.",
              "helpfulResource": {
                "displayText": "Setup the exponential backoff on AWS.",
                "url": "https://docs.aws.amazon.com/sdkref/latest/guide/feature-retry-behavior.html"
              },
              "improvementPlan": {
                "displayText": "Setup the exponential backoff on AWS.",
                "url": "https://docs.aws.amazon.com/sdkref/latest/guide/feature-retry-behavior.html"
              }
            },
            {
              "id": "PERF_9_4",
              "title": "Setup a retry workflow and follow up mechanisim to solve the unfinished workflow.",
              "helpfulResource": {
                "displayText": "Setup a retry workflow and follow up mechanisim to solve the unfinished workflow."
              },
              "improvementPlan": {
                "displayText": "Setup a retry workflow and follow up mechanisim to solve the unfinished workflow.",
                "url": "https://docs.aws.amazon.com/sdkref/latest/guide/feature-retry-behavior.html"
              }
            },
            {
              "id": "PERF_9_no",
              "title": "None of these",
              "helpfulResource": {
                "displayText": "Do not have any retry mechanism setup when a document fails"
              }
            }
          ],
          "riskRules": [
            {
              "condition": "PERF_9_2 && PERF_9_3 && PERF_9_4",
              "risk": "NO_RISK"
            },
            { "condition": "default", "risk": "MEDIUM_RISK" }
          ]
        },
        {
          "id": "PERF_10",
          "title": "Use OutputConfig and SNS notifications to avoid calling Get for all the paginated responses and avoid running into TPS limits ",
          "description": "Are you leveraging Textract's output configuration & SNS options to be notified of job completion to retrieve the required data without having to make redundant/repetitive calls?\n\nHave you configured Textract to send SNS notifications upon job completion instead of continously polling for job statuses?",
          "helpfulResource": {
            "displayText": "Are you leveraging Textract's output configuration & SNS options to be notified of job completion to retrieve the required data without having to make redundant/repetitive calls?\n\nHave you configured Textract to send SNS notifications upon job completion instead of continously polling for job statuses?",
            "url": "https://docs.aws.amazon.com/textract/latest/dg/api-async-roles.html"
          },
          "choices": [
            {
              "id": "PERF_10_2",
              "title": "Retry with out having to make redundant/repetitive calls",
              "helpfulResource": {
                "displayText": "Retry with out having to make redundant/repetitive calls"
              },
              "improvementPlan": {
                "displayText": "Retry with out having to make redundant/repetitive calls",
                "url": "https://docs.aws.amazon.com/textract/latest/dg/api-async-roles.html"
              }
            },
            {
              "id": "PERF_10_3",
              "title": "Textract to send SNS notifications upon job completion instead of continously polling for job statuses.",
              "helpfulResource": {
                "displayText": "Textract to send SNS notifications upon job completion instead of continously polling for job statuses."
              },
              "improvementPlan": {
                "displayText": "Textract to send SNS notifications upon job completion instead of continously polling for job statuses.",
                "url": "https://docs.aws.amazon.com/textract/latest/dg/api-async-roles.html"
              }
            },
            {
              "id": "PERF_10_no",
              "title": "None of these"
            }
          ],
          "riskRules": [
            { "condition": "PERF_10_2 && PERF_10_3", "risk": "NO_RISK" },
            { "condition": "default", "risk": "MEDIUM_RISK" }
          ]
        },
        {
          "id": "PERF_11",
          "title": "How often do you compare the performance of Comprehend Custom Classifier after rolling out the service on production?",
          "description": "Amazon Comprehend provides you with metrics based on training of the recognizer model. These metrics provide an insight into how accurately the trained model will perform when you use it to identify entities. ",
          "helpfulResource": {
            "displayText": "Amazon Comprehend provides you with metrics based on training of the recognizer model. These metrics provide an insight into how accurately the trained model will perform when you use it to identify entities. ",
            "url": "https://docs.aws.amazon.com/comprehend/latest/dg/flywheels.html"
          },
          "choices": [
            {
              "id": "PERF_11_2",
              "title": "Keep track and evaluate the performance of Comprehend Custom Classifier model",
              "helpfulResource": {
                "displayText": "Have in place a process to monitor and improve a custom model over time",
                "url": "https://aws.amazon.com/blogs/machine-learning/introducing-the-amazon-comprehend-flywheel-for-mlops/"
              },
              "improvementPlan": {
                "displayText": "Have in place a process to monitor and improve a custom model over time",
                "url": "https://aws.amazon.com/blogs/machine-learning/introducing-the-amazon-comprehend-flywheel-for-mlops/"
              }
            },
            {
              "id": "PERF_11_3",
              "title": "Establish data quality assurance process to prepare data for training",
              "helpfulResource": {
                "displayText": "Make sure to follow the guidelines in the respective documentation to improve data quality.",
                "url": "https://docs.aws.amazon.com/comprehend/latest/dg/cer-metrics.html"
              },
              "improvementPlan": {
                "displayText": "Establish data quality assurance process to prepare data for training",
                "url": "https://docs.aws.amazon.com/comprehend/latest/dg/cer-metrics.html"
              },
              "additionalResources": [
                {
                  "type": "HELPFUL_RESOURCE",
                  "content": [
                    {
                      "displayText": "AWS Machine Learning Blog: Build a custom entity recognizer for PDF documents using Amazon Comprehend",
                      "url": "https://aws.amazon.com/blogs/machine-learning/build-a-custom-entity-recognizer-for-pdf-documents-using-amazon-comprehend/"
                    },
                    {
                      "displayText": "AWS Machine Learning Blog: Amazon Comprehend announces lower annotation limits for custom entity recognition",
                      "url": "https://aws.amazon.com/blogs/machine-learning/amazon-comprehend-announces-lower-annotation-limits-for-custom-entity-recognition/"
                    }
                  ]
                },
                {
                  "type": "IMPROVEMENT_PLAN",
                  "content": [
                    {
                      "displayText": "AWS Machine Learning Blog: Build a custom entity recognizer for PDF documents using Amazon Comprehend",
                      "url": "https://aws.amazon.com/blogs/machine-learning/build-a-custom-entity-recognizer-for-pdf-documents-using-amazon-comprehend/"
                    },
                    {
                      "displayText": "AWS Machine Learning Blog: Amazon Comprehend announces lower annotation limits for custom entity recognition",
                      "url": "https://aws.amazon.com/blogs/machine-learning/amazon-comprehend-announces-lower-annotation-limits-for-custom-entity-recognition/"
                    }
                  ]
                }
              ]
            },
            {
              "id": "PERF_11_no",
              "title": "None of these"
            }
          ],
          "riskRules": [
            { "condition": "PERF_11_2 && PERF_11_3", "risk": "NO_RISK" },
            { "condition": "default", "risk": "MEDIUM_RISK" }
          ]
        },
        {
          "id": "PERF_12",
          "title": "How do you monitor the ML Performance?",
          "description": "How often do you monitor, evaluate, and improve the model performance after rolling out the workload on production?Do you use and tools and mechanisim to monitor, evaluate, and improve the model performance?",
          "helpfulResource": {
            "displayText": "Do you use and tools and mechanisim to monitor, evaluate, and improve the model performance?",
            "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/model-evaluation.html"
          },
          "choices": [
            {
              "id": "PERF_12_1",
              "title": "Have the model monitoring mechanisms setup.",
              "helpfulResource": {
                "displayText": "Ensure that input documents follow Amazon Textract best practices to get the best results from your documents",
                "url": "https://aws.amazon.com/blogs/machine-learning/monitoring-in-production-ml-models-at-large-scale-using-amazon-sagemaker-model-monitor/"
              },
              "improvementPlan": {
                "displayText": "Setup system monitoring with tools and mechanisms",
                "url": "https://docs.aws.amazon.com/textract/latest/dg/cloudwatch-metricsdim.html"
              }
            },
            {
              "id": "PERF_12_no",
              "title": "Don't have the model monitoring mechanisms setup."
            }
          ],
          "riskRules": [
            { "condition": "PERF_12_1", "risk": "NO_RISK" },
            { "condition": "default", "risk": "MEDIUM_RISK" }
          ]
        },
        {
          "id": "PERF_13",
          "title": "How often do you compare the Textract confidence score performance / WER after rolling out the service on production?",
          "description": "Textract confidence score performance/WER variantes based on the quality and type of input document. you should monitor Textract performance scores, and raise alarms when thresholds are breached.",
          "helpfulResource": {
            "displayText": "Textract confidence score performance/WER variantes based on the quality and type of input document. you should monitor Textract performance scores, and raise alarms when thresholds are breached.",
            "url": "https://repost.aws/questions/QU338kk0teQJmB6qWR8OmKvg/aws-textract-accuracy-calculation"
          },
          "choices": [
            {
              "id": "PERF_13_2",
              "title": "Establish requirements for your input documents",
              "helpfulResource": {
                "displayText": "Ensure that input documents follow Amazon Textract best practices to get the best results from your documents",
                "url": "https://docs.aws.amazon.com/textract/latest/dg/textract-best-practices.html"
              },
              "improvementPlan": {
                "displayText": "Establish requirements for your input documents",
                "url": "https://docs.aws.amazon.com/textract/latest/dg/textract-best-practices.html"
              }
            },
            {
              "id": "PERF_13_3",
              "title": "Use human review for results that have a low confidence score",
              "helpfulResource": {
                "displayText": "In applications sensitive to error detection (false positives), enforce a minimum confidence score threshold. The application should discard results below that threshold or flag situations as requiring a higher level of human scrutiny.",
                "url": "https://docs.aws.amazon.com/textract/latest/dg/a2i-textract.html"
              },
              "improvementPlan": {
                "displayText": "Use human review for results that have a low confidence score",
                "url": "https://docs.aws.amazon.com/textract/latest/dg/a2i-textract.html"
              }
            },
            {
              "id": "PERF_13_no",
              "title": "Never compare the Textract confidence score performance / WER after rolling out the service on production",
              "helpfulResource": {
                "displayText": "Textract confidence score performance/WER variantes based on the quality and type of input document. you should monitor Textract performance scores, and raise alarms when thresholds are breached.",
                "url": "https://repost.aws/questions/QU338kk0teQJmB6qWR8OmKvg/aws-textract-accuracy-calculation"
              }
            }
          ],
          "riskRules": [
            { "condition": "PERF_13_2 && PERF_13_3", "risk": "NO_RISK" },
            { "condition": "default", "risk": "MEDIUM_RISK" }
          ]
        },
        {
          "id": "PERF_14",
          "title": "Have your company setup a mechanism to monitor, evaluate, and improve the end-to-end automation rate after rolling out the wor",
          "description": "Have your company setup a mechanism to monitor, evaluate, and improve the end-to-end automation rate after rolling out the workload on production? Which can include, metrics monitoring, evaluating bottlenecks, A/B testing, user feedback, incremental enhancement, log analysis, change management, and more.",
          "helpfulResource": {
            "displayText": "Have your company setup a mechanism to monitor, evaluate, and improve the end-to-end automation rate after rolling out the workload on production? Which can include, metrics monitoring, evaluating bottlenecks, A/B testing, user feedback, incremental enhancement, log analysis, change management, and more.",
            "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/performance-efficiency-pillar-best-practices-5.html"
          },
          "choices": [
            {
              "id": "PERF_14_2",
              "title": "Evaluate data drift",
              "helpfulResource": {
                "displayText": "Understand the effects of data drift on model performance. In cases where the data has drifted, the model could generate inaccurate predictions. Consider a strategy that monitors and adapts to data drift through re-training.",
                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/performance-efficiency-pillar-best-practices-5.html"
              },
              "improvementPlan": {
                "displayText": "Evaluate data drift",
                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/performance-efficiency-pillar-best-practices-5.html"
              }
            },
            {
              "id": "PERF_14_3",
              "title": "Include human-in-the-loop monitoring",
              "helpfulResource": {
                "displayText": "Use human-in-the-loop monitoring to monitor model performance efficiently. When automating decision processes, the human labeling of model results is a reliable quality test for model inferences.Compare human labels with model inferences to estimate model performance degradation. Perform mitigation as model re-training.",
                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/performance-efficiency-pillar-best-practices-5.html"
              },
              "improvementPlan": {
                "displayText": "Include human-in-the-loop monitoring",
                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/performance-efficiency-pillar-best-practices-5.html"
              }
            },
            {
              "id": "PERF_14_no",
              "title": "We do not evaluate data drift nor include human-in-the-loop monitoring"
            }
          ],
          "riskRules": [
            { "condition": "PERF_14_2 && PERF_14_3", "risk": "NO_RISK" },
            { "condition": "default", "risk": "MEDIUM_RISK" }
          ]
        },
        {
          "id": "PERF_15",
          "title": "What metrics do you monitor the IDP workload ?",
          "description": "Metrics provides a quantifiable way to understand the project outcome. After the IDP workload deployed to production, there are both business metrics and technical metrics can appply to it. For instances, mins of document classification, percentage of automated document extraction, price per page, accuracy per entity extraction, and accuracy per document classfication.",
          "helpfulResource": {
            "displayText": "Metrics provides a quantifiable way to understand the project outcome. After the IDP workload deployed to production, there are both business metrics and technical metrics can appply to it. For instances, mins of document classification, percentage of automated document extraction, price per page, accuracy per entity extraction, and accuracy per document classfication."
          },
          "choices": [
            {
              "id": "PERF_15_1",
              "title": "Technical Metrics",
              "helpfulResource": {
                "displayText": "Technical Metrics: include (1) OCR metrics: WER (2) document classification metrics: confusion metrix (3) entity recognition:Precision,Recall, F1 (4) endpoint latency per each service API (5) invoke endpoint error"
              },
              "improvementPlan": {
                "displayText": "(1) Adjust current technical metrics with the common IDP technical metrics list\n(2) Add Business metrics from common IDP business metrics list to the daily, monthly review metrics"
              }
            },
            {
              "id": "PERF_15_2",
              "title": "Business Metrics",
              "helpfulResource": {
                "displayText": "Business Metrics: include (1) End-to-EndDocument Processing Time (2) percentage of automated document (3) Time to value when new document type is added"
              },
              "improvementPlan": {
                "displayText": "(1) Adjust current technical metrics with the common IDP technical metrics list\n(2) Add Business metrics from common IDP business metrics list to the daily, monthly review metrics"
              }
            },
            {
              "id": "PERF_15_no",
              "title": "None",
              "helpfulResource": {
                "displayText": "No Metric is used at the moment. (1) Add Technical metrics from common IDP technical metrics list to the daily, monthly review metrics\n(2) Add Business metrics from common IDP business metrics list to the daily, monthly review metrics"
              }
            }
          ],
          "riskRules": [
            {
              "condition": "PERF_15_1 && PERF_15_2",
              "risk": "NO_RISK"
            },
            { "condition": "default", "risk": "MEDIUM_RISK" }
          ]
        }
      ]
    },
    {
      "id": "costOptimization",
      "name": "Cost Optimization",
      "questions": [
        {
          "id": "COST_1",
          "title": "Do you establish a cost optimization function or team for the IDP solution?",
          "description": "Create a team (Cloud Business Office or Cloud Center of Excellence) that is responsible for establishing and maintaining cost awareness across your organization. The team requires people from finance, technology, and business roles across the organization.",
          "helpfulResource": {
            "displayText": "Establish a Cloud Business Office (CBO) or Cloud Center of Excellence (CCOE) team that is responsible for establishing and maintaining a culture of cost awareness in cloud computing. It can be an existing individual, a team within your organization, or a new team of key finance, technology and organization stakeholders from across the organization.",
            "url": "https://docs.aws.amazon.com/wellarchitected/latest/cost-optimization-pillar/cost_cloud_financial_management_function.html"
          },
          "choices": [
            {
              "id": "COST_1_2",
              "title": "We have a specific team for cloud business(cost optimization team).",
              "helpfulResource": {
                "displayText": "Establishing a team that can take responsibility for cost optimization is critical for successfully implementing cloud technology at scale for your organization.",
                "url": "https://docs.aws.amazon.com/wellarchitected/latest/cost-optimization-pillar/cost_cloud_financial_management_function.html"
              },
              "improvementPlan": {
                "displayText": "Define key members: You need to ensure that all relevant parts of your organization contribute and have a stake in cost management. Common teams within organizations typically include: finance, application or product owners, management, and technical teams (DevOps).\n\nDefine goals and metrics: The function needs to deliver value to the organization in different ways. These goals are defined and continually evolve as the organization evolves. Common activities include: creating and running education programs on cost optimization across the organization, developing organization-wide standards, such as monitoring and reporting for cost optimization, and setting workload goals on optimization. This function also needs to regularly report to the organization on the organization's cost optimization capability.\n\nEstablish regular cadence: The group (finance, technology, and business teams) should come together regularly to review their goals and metrics. A typical cadence involves reviewing the state of the organization, reviewing any programs currently running, and reviewing overall financial and optimization metrics. Then key workloads are reported on in greater detail.",
                "url": ""
              },
              "additionalResources": [
                {
                  "type": "IMPROVEMENT_PLAN",
                  "content": [
                    {
                      "displayText": "Establish ownership of cost optimization",
                      "url": "https://docs.aws.amazon.com/wellarchitected/latest/cost-optimization-pillar/cost_cloud_financial_management_function.html"
                    },
                    {
                      "displayText": "AWS Cloud Enterprise Strategy Blog: Creating the Cloud Business Office",
                      "url": "https://aws.amazon.com/blogs/enterprise-strategy/creating-the-cloud-business-office/"
                    },
                    {
                      "displayText": "Create a Cloud Center of Excellence",
                      "url": "https://docs.aws.amazon.com/whitepapers/latest/cost-optimization-laying-the-foundation/cloud-center-of-excellence.html"
                    }
                  ]
                }
              ]
            },
            {
              "id": "COST_1_no",
              "title": "No specific team for cloud business(cost optimization team).",
              "helpfulResource": {
                "displayText": "Establishing a team that can take responsibility for cost optimization is critical for successfully implementing cloud technology at scale for your organization.",
                "url": "https://docs.aws.amazon.com/wellarchitected/latest/cost-optimization-pillar/cost_cloud_financial_management_function.html"
              }
            }
          ],
          "riskRules": [
            { "condition": "COST_1_2", "risk": "NO_RISK" },
            { "condition": "default", "risk": "HIGH_RISK" }
          ]
        },
        {
          "id": "COST_2",
          "title": "Do you establish a partnership between finance and technology through your development lifecycle?",
          "description": "Involve finance and technology teams in cost and usage discussions at all stages of your cloud journey. Teams regularly meet and discuss topics such as organizational goals and targets, current state of cost and usage, and financial and accounting practices",
          "helpfulResource": {
            "displayText": "Technology teams innovate faster in the cloud due to shortened approval, procurement, and infrastructure deployment cycles.With the adoption of cloud, infrastructure procurement and consumption are no longer beholden to a chain of dependencies. In the cloud model, technology and product teams are no longer just builders, but operators and owners of their products, responsible for most of the activities historically associated with finance and operations teams, including procurement and deployment.",
            "url": "https://docs.aws.amazon.com/wellarchitected/latest/cost-optimization-pillar/cost_cloud_financial_management_partnership.html"
          },
          "choices": [
            {
              "id": "COST_2_2",
              "title": "We involve finance team and goals in our development lifecycle.",
              "helpfulResource": {
                "displayText": "Establish a partnership between key finance and technology stakeholders to create a shared understanding of organizational goals and develop mechanisms to succeed financially in the variable spend model of cloud computing. Relevant teams within your organization must be involved in cost and usage discussions at all stages of your cloud journey",
                "url": "https://docs.aws.amazon.com/wellarchitected/latest/cost-optimization-pillar/cost_cloud_financial_management_partnership.html"
              },
              "improvementPlan": {
                "displayText": "Relevant teams within your organization must be involved in cost and usage discussions at all stages of your cloud journey, including:\n\nFinancial leads: CFOs, financial controllers, financial planners, business analysts, procurement, sourcing, and accounts payable must understand the cloud model of consumption, purchasing options, and the monthly invoicing process. Finance needs to partner with technology teams to create and socialize an IT value story, helping business teams understand how technology spend is linked to business outcomes. This way, technology expenditures are viewed not as costs, but rather as investments. Due to the fundamental differences between the cloud (such as the rate of change in usage, pay as you go pricing, tiered pricing, pricing models, and detailed billing and usage information) compared to on-premises operation, it is essential that the finance organization understands how cloud usage can impact business aspects including procurement processes, incentive tracking, cost allocation and financial statements.\n\nTechnology leads: Technology leads (including product and application owners) must be aware of the financial requirements (for example, budget constraints) as well as business requirements (for example, service level agreements). This allows the workload to be implemented to achieve the desired goals of the organization.",
                "url": "https://docs.aws.amazon.com/wellarchitected/latest/cost-optimization-pillar/cost_cloud_financial_management_partnership.html"
              }
            },
            {
              "id": "COST_2_no",
              "title": "No finance team and goals in our development lifecycle.",
              "helpfulResource": {
                "displayText": "Establish a partnership between key finance and technology stakeholders to create a shared understanding of organizational goals and develop mechanisms to succeed financially in the variable spend model of cloud computing. Relevant teams within your organization must be involved in cost and usage discussions at all stages of your cloud journey",
                "url": "https://docs.aws.amazon.com/wellarchitected/latest/cost-optimization-pillar/cost_cloud_financial_management_partnership.html"
              }
            }
          ],
          "riskRules": [
            { "condition": "COST_2_2", "risk": "NO_RISK" },
            { "condition": "default", "risk": "MEDIUM_RISK" }
          ]
        },
        {
          "id": "COST_3",
          "title": "How do you manage Amazon Comprehend endpoint's inference units (IUs) ?",
          "description": "In Amazon Comprehend, endpoints make your custom models available for real-time classification or entity detection. After you create an endpoint, you can make changes to it as your business needs evolve. For example, you can monitor your endpoint utilization and apply auto scaling to automatically set endpoint provisioning to fit your capacity needs.",
          "helpfulResource": {
            "displayText": "Amazon Comprehend assigns throughput to an endpoint using Inference units (IU). An IU represents data throughput of 100 characters per second. You can provision the endpoint with up to 10 inference units. You can scale the endpoint throughput either up or down by updating the endpoint.",
            "url": "https://docs.aws.amazon.com/comprehend/latest/dg/using-endpoints.html"
          },
          "choices": [
            {
              "id": "COST_3_1",
              "title": "After creating an endpoint, we monitor it with CloudWatch, update it to change its IU, or delete it when no longer needed",
              "helpfulResource": {
                "displayText": "Depending on your needs, you might need to adjust the throughput of your endpoint after creating it. This can be achieved by updating the endpoint's inference units (IUs). When you edit an endpoint, you can add more IUs to an endpoint, or you can decrease the IUs.Based on the CloudWatch metrics, you can also set up auto scaling to automatically adjust the throughput of your endpoint. ",
                "url": "https://docs.aws.amazon.com/comprehend/latest/dg/manage-endpoints.html"
              },
              "improvementPlan": {
                "displayText": "If you are not actively using the endpoint for an extended period, you should set up an auto scaling policy to reduce your costs.\n\nIf you are no longer using an endpoint you can delete the endpoint to avoid incurring additional cost.",
                "url": "https://docs.aws.amazon.com/comprehend/latest/dg/manage-endpoints.html"
              }
            },
            {
              "id": "COST_3_no",
              "title": "No monitor for Amazon Comprehend endpoint's inference units (IUs)",
              "helpfulResource": {
                "displayText": "No monitoring process implemented to control Amazon Comprehend endpoint's inference units (IUs) usage",
                "url": ""
              }
            }
          ],
          "riskRules": [
            { "condition": "COST_3_1", "risk": "NO_RISK" },
            { "condition": "default", "risk": "HIGH_RISK" }
          ]
        },
        {
          "id": "COST_4",
          "title": "How do you choose async vs sync inference for Comprehend custom classifier or custom entity recognizer in your architecture?",
          "description": "Given the considerable cost difference between asynchronous and synchronous inference choices for Amazon Comprehend custom models, what are some key factors you take into account when making the choice to balance between business needs and cost optimization?",
          "helpfulResource": {
            "displayText": "Consider your inference need with Amazon Comprehend custom models: do you need inference responses in real-time? Do you need to process multiple documents in one batch? How big are the documents you need to process?",
            "url": "https://docs.aws.amazon.com/comprehend/latest/dg/how-document-classification.html"
          },
          "choices": [
            {
              "id": "COST_4_1",
              "title": "We decide based on if we need real-time response and document size.",
              "helpfulResource": {
                "displayText": "Adopt synchronous inference for real-time processing of a single document; choose asynchronous jobs to analyze large documents or multiple documents in one batch",
                "url": "https://docs.aws.amazon.com/comprehend/latest/dg/running-class-sync.html"
              },
              "improvementPlan": {
                "displayText": "Use asynchronous jobs to process your multiple documents as a batch, or a single document that is very large (see URL for input data size limits).\n\nAdopt synchronous inference endpoint only when you need to process a single document (see URL for input data size limits) in real-time.",
                "url": "https://docs.aws.amazon.com/comprehend/latest/dg/idp-inputs-async.html"
              },
              "additionalResources": [
                {
                  "type": "HELPFUL_RESOURCE",
                  "content": [
                    {
                      "displayText": "Amazon Comprehend - Running asynchronous jobs",
                      "url": "https://docs.aws.amazon.com/comprehend/latest/dg/running-classifiers.html"
                    }
                  ]
                },
                {
                  "type": "IMPROVEMENT_PLAN",
                  "content": [
                    {
                      "displayText": "Amazon Comprehend - Running asynchronous jobs",
                      "url": "https://docs.aws.amazon.com/comprehend/latest/dg/running-classifiers.html"
                    }
                  ]
                }
              ]
            },
            {
              "id": "COST_4_no",
              "title": "No specific criteria to choose between async vs sync inference ",
              "helpfulResource": {
                "displayText": "Adopt synchronous inference for real-time processing of a single document; choose asynchronous jobs to analyze large documents or multiple documents in one batch",
                "url": "https://docs.aws.amazon.com/comprehend/latest/dg/running-class-sync.html"
              }
            }
          ],
          "riskRules": [
            { "condition": "COST_4_1", "risk": "NO_RISK" },
            { "condition": "default", "risk": "HIGH_RISK" }
          ]
        },
        {
          "id": "COST_5",
          "title": "Do you run your experiment workload in a separate account to take advantage of AWS Free Tier?",
          "description": "The AWS Free Tier provides customers the ability to explore and try out AWS services free of charge up to specified limits for each service. ",
          "helpfulResource": {
            "displayText": "The AWS Free Tier provides new AWS customers with free usage tiers for certain AWS services to help you get started. If you have a new idea that youd like to launch or if you have an existing experiment you want to run in the cloud, this is a great way to get started for free.",
            "url": "https://aws.amazon.com/free/"
          },
          "choices": [
            {
              "id": "COST_5_1",
              "title": "We use AWS Free Tier for experiment workload.",
              "helpfulResource": {
                "displayText": "The AWS Free Tier is available to all types of customers  students, entrepreneurs, small businesses, and Fortune 500 companies are all welcome to sign up. If you are linked to an Organization (under AWS Organizations), only one account within the organization can benefit from the Free Tier offers. ",
                "url": "https://aws.amazon.com/free/free-tier-faqs/"
              },
              "improvementPlan": {
                "displayText": "The AWS Free Tier is comprised of three different types of offerings, a 12-month Free Tier, an Always Free offer, and short term trials. Many of the AI services, such as Textract, Comprehend, have specific free tier specifications. Take advantage of the feature for experimentation workload can help with cost optimization.",
                "url": "https://docs.aws.amazon.com/whitepapers/latest/how-aws-pricing-works/get-started-with-the-aws-free-tier.html"
              },
              "additionalResources": [
                {
                  "type": "IMPROVEMENT_PLAN",
                  "content": [
                    {
                      "displayText": "Free Machine Learning Services on AWS",
                      "url": "https://aws.amazon.com/free/machine-learning/"
                    }
                  ]
                }
              ]
            },
            {
              "id": "COST_5_no",
              "title": "No, our experiements require more than what the free tier offers so we do not leverage the free tier",
              "helpfulResource": {
                "displayText": "The AWS Free Tier is available to all types of customers  students, entrepreneurs, small businesses, and Fortune 500 companies are all welcome to sign up. If you are linked to an Organization (under AWS Organizations), only one account within the organization can benefit from the Free Tier offers. ",
                "url": "https://aws.amazon.com/free/free-tier-faqs/"
              }
            }
          ],
          "riskRules": [
            { "condition": "COST_5_1", "risk": "NO_RISK" },
            { "condition": "default", "risk": "MEDIUM_RISK" }
          ]
        },
        {
          "id": "COST_6",
          "title": "Do you have strategies for efficient data storage & management for your IDP workflow?",
          "description": "What strategies have you implemented to ensure cost-effective storage and management of your data?",
          "helpfulResource": {
            "displayText": "Given the main storage service in IDP is Amazon S3, what are some features you can use for cost-effective data storage and management?",
            "url": "https://docs.aws.amazon.com/AmazonS3/latest/userguide/intelligent-tiering-overview.html"
          },
          "choices": [
            {
              "id": "COST_6_1",
              "title": "We adopt Intelligent-Tiering for our data storage in S3.",
              "helpfulResource": {
                "displayText": "The S3 Intelligent-Tiering storage class is designed to optimize storage costs by automatically moving data to the most cost-effective access tier when access patterns change, without operational overhead or impact on performance.",
                "url": "https://docs.aws.amazon.com/AmazonS3/latest/userguide/intelligent-tiering.html"
              },
              "improvementPlan": {
                "displayText": "There are two ways to move data into S3 Intelligent-Tiering: (1) Directly PUT data into S3 Intelligent-Tiering by specifying INTELLIGENT_TIERING in the x-amz-storage-class header; (2) Configure S3 Lifecycle configurations to transition objects from S3 Standard or S3 Standard-Infrequent Access to S3 Intelligent-Tiering.\n\nYou can optionally enable S3 Intelligent-Tiering Archive Access and Deep Archive Access tiers on top of the automatically provisioned tiers (Frequent Access tier, Infrequent Access tier, and Archive Instant Access tier) to get the lowest storage cost on data.",
                "url": "https://docs.aws.amazon.com/AmazonS3/latest/userguide/intelligent-tiering-overview.html"
              },
              "additionalResources": [
                {
                  "type": "IMPROVEMENT_PLAN",
                  "content": [
                    {
                      "displayText": "Using S3 Intelligent-Tiering",
                      "url": "https://docs.aws.amazon.com/AmazonS3/latest/userguide/using-intelligent-tiering.html"
                    },
                    {
                      "displayText": "Managing S3 Intelligent-Tiering",
                      "url": "https://docs.aws.amazon.com/AmazonS3/latest/userguide/intelligent-tiering-managing.html"
                    }
                  ]
                }
              ]
            },
            {
              "id": "COST_6_no",
              "title": "No specifc strategy"
            }
          ],
          "riskRules": [
            { "condition": "COST_6_1", "risk": "NO_RISK" },
            { "condition": "default", "risk": "MEDIUM_RISK" }
          ]
        },
        {
          "id": "COST_7",
          "title": "Do you split the document into single pages to process rather than apply all FeatureTypes to the whole multi-page document?",
          "description": "To analyze a bunch of multi-page documents all having same structure, do you split the document into single pages to process using different FeatureTypes for each page rather than apply all FeatureTypes to the whole document?",
          "helpfulResource": {
            "displayText": "FeatureType is a parameter for the Document Analysis (both sync and async) API calls in Textract, currently it includes the following values:TABLES | FORMS | QUERIES | SIGNATURES | LAYOUT.",
            "url": "https://docs.aws.amazon.com/textract/latest/dg/API_AnalyzeDocument.html"
          },
          "choices": [
            {
              "id": "COST_7_1",
              "title": "We split the multi-page documents into single pages to only apply specific FeatureType processing that are absolutely necessary",
              "helpfulResource": {
                "displayText": "Amazon Textract charges you based on the number of pages and images processed. Not all pages might include the information you need to extract. Splitting documents into single pages and only focus on the single pages with the FeatureType you need to extract can reduce the cost.",
                "url": "https://aws.amazon.com/textract/pricing/"
              },
              "improvementPlan": {
                "displayText": "Prepare the documents by splitting them into single pages, perform Document Analysis on the pages that include the FeatureType you need to extract. Specify FeatureType in the Textract API call.",
                "url": "https://docs.aws.amazon.com/prescriptive-guidance/latest/patterns/automatically-extract-content-from-pdf-files-using-amazon-textract.html"
              },
              "additionalResources": [
                {
                  "type": "HELPFUL_RESOURCE",
                  "content": [
                    {
                      "displayText": "Amazon Textract - API Reference: StartDocumentAnalysis",
                      "url": "https://docs.aws.amazon.com/textract/latest/dg/API_StartDocumentAnalysis.html#Textract-StartDocumentAnalysis-request-FeatureTypes"
                    }
                  ]
                }
              ]
            },
            {
              "id": "COST_7_no",
              "title": "No, we run the entire multi-page document against a set of FeatureTypes"
            }
          ],
          "riskRules": [
            { "condition": "COST_7_1", "risk": "NO_RISK" },
            { "condition": "default", "risk": "MEDIUM_RISK" }
          ]
        },
        {
          "id": "COST_8",
          "title": "Do you enforce data retention policies throughout the IDP workflow?",
          "description": "Define data retention policies on supported resources to handle object deletion per your organizations requirements. Identify and delete unnecessary or orphaned resources and objects that are no longer required.",
          "helpfulResource": {
            "displayText": "Use data retention policies and lifecycle policies to reduce the associated costs of the decommissioning process and storage costs for the identified resources.",
            "url": "https://docs.aws.amazon.com/wellarchitected/latest/cost-optimization-pillar/cost_decomissioning_resources_data_retention.html"
          },
          "choices": [
            {
              "id": "COST_8_1",
              "title": "We enforce data retention policies.",
              "helpfulResource": {
                "displayText": "Defining your data retention policies and lifecycle policies to perform automated storage class migration and deletion will reduce the overall storage costs during its lifetime. ",
                "url": "https://docs.aws.amazon.com/wellarchitected/latest/cost-optimization-pillar/cost_decomissioning_resources_data_retention.html"
              },
              "improvementPlan": {
                "displayText": "Set up lifecycle configuration on a bucket for you IDP solution: Use Amazon S3 lifecycle configuration on a bucket to define actions for Amazon S3 to take during an object's lifecycle, as well as deletion at the end of the object's lifecycle, based on your business requirements.",
                "url": "https://docs.aws.amazon.com/AmazonS3/latest/userguide/how-to-set-lifecycle-configuration-intro.html"
              },
              "additionalResources": [
                {
                  "type": "IMPROVEMENT_PLAN",
                  "content": [
                    {
                      "displayText": "Amazon S3 - Managing your storage lifecycle",
                      "url": "https://docs.aws.amazon.com/AmazonS3/latest/userguide/object-lifecycle-mgmt.html"
                    },
                    {
                      "displayText": "Defining your data retention policies and lifecycle policies to perform automated storage class migration and deletion will reduce the overall storage costs during its lifetime.",
                      "url": "https://docs.aws.amazon.com/wellarchitected/latest/cost-optimization-pillar/cost_decomissioning_resources_data_retention.html"
                    }
                  ]
                }
              ]
            },
            {
              "id": "COST_8_no",
              "title": "No data retention policies."              
            }
          ],
          "riskRules": [
            { "condition": "COST_8_1", "risk": "NO_RISK" },
            { "condition": "default", "risk": "HIGH_RISK" }
          ]
        },
        {
          "id": "COST_9",
          "title": "Do you track resources over their lifetime in the IDP workflow?",
          "description": "After you manage a list of projects, employees, and technology resources over time you will be able to identify which resources are no longer being used, and which projects that no longer have an owner.",
          "helpfulResource": {
            "displayText": "Define and implement a method to track resources and their associations with systems over their lifetime. You can use tagging to identify the workload or function of the resource.",
            "url": "https://docs.aws.amazon.com/wellarchitected/latest/cost-optimization-pillar/cost_decomissioning_resources_track.html"
          },
          "choices": [
            {
              "id": "COST_9_1",
              "title": "We enforce the policy of tracking resources over their lifetime.",
              "helpfulResource": {
                "displayText": "Decommission workload resources that are no longer required. Using tags is an effective way to track resources, by labeling the resource with its function, or a known date when it can be decommissioned.",
                "url": "https://docs.aws.amazon.com/wellarchitected/latest/cost-optimization-pillar/cost_decomissioning_resources_track.html"
              },
              "improvementPlan": {
                "displayText": "Implement a tagging scheme: Implement a tagging scheme that identifies the workload the resource belongs to, verifying that all resources within the workload are tagged accordingly. Tagging helps you categorize resources by purpose, team, environment, or other criteria relevant to your business. For more detail on tagging uses cases, strategies, and techniques, see AWS Tagging Best Practices.\nImplement workload throughput or output monitoring: Implement workload throughput monitoring or alarming, initiating on either input requests or output completions. Configure it to provide notifications when workload requests or outputs drop to zero, indicating the workload resources are no longer used. Incorporate a time factor if the workload periodically drops to zero under normal conditions. For more detail on unused or underutilized resources, see AWS Trusted Advisor Cost Optimization checks.\nGroup AWS resources: Create groups for AWS resources. You can use AWS Resource Groups to organize and manage your AWS resources that are in the same AWS Region. You can add tags to most of your resources to help identify and sort your resources within your organization. Use Tag Editor add tags to supported resources in bulk. Consider using AWS Service Catalog to create, manage, and distribute portfolios of approved products to end users and manage the product lifecycle.",
                "url": "https://docs.aws.amazon.com/tag-editor/latest/userguide/tagging.html"
              },
              "additionalResources": [
                {
                  "type": "IMPROVEMENT_PLAN",
                  "content": [
                    {
                      "displayText": "Use AWS Auto Scaling",
                      "url": "https://aws.amazon.com/autoscaling/"
                    },
                    {
                      "displayText": "Amazon Comprehend Underutilized Endpoints",
                      "url": "https://docs.aws.amazon.com/awssupport/latest/user/cost-optimization-checks.html#amazon-comprehend-underutilized-endpoints"
                    },
                    {
                      "displayText": "How do I optimize costs using AWS Trusted Advisor?",
                      "url": "https://repost.aws/knowledge-center/trusted-advisor-cost-optimization"
                    }
                  ]
                }
              ]
            },
            {
              "id": "COST_9_no",
              "title": "No resource tracking" 
            }
          ],
          "riskRules": [
            { "condition": "COST_9_1", "risk": "NO_RISK" },
            { "condition": "default", "risk": "HIGH_RISK" }
          ]
        },
        {
          "id": "COST_10",
          "title": "How do you monitor and control cost by AWS services in the IDP solution?",
          "description": "How do you monitor & control costs associated with the usages of Textract, Comprehend and other AWS IDP suite of services?",
          "helpfulResource": {
            "displayText": "What are the cost monitor and control tools you can utilize in line with your organization policies to manage and optimize cloud spend?",
            "url": "https://docs.aws.amazon.com/wellarchitected/latest/cost-optimization-pillar/cost_monitor_usage_config_tools.html"
          },
          "choices": [
            {
              "id": "COST_10_1",
              "title": "We monitor and control AWS service usage with tools such as AWS Cost Explorer and AWS Budgets and grant team-based access",
              "helpfulResource": {
                "displayText": "You can use AWS tools like AWS Cost Explorer, AWS Billing, or AWS Budgets for essentials, or you can integrate CUR data with Amazon Athena and Amazon QuickSight to provide this capability for more detailed views. If you don't have essential skills or bandwidth in your organization, you can work with AWS ProServ, AWS Managed Services (AMS), or AWS Partners and use their tools. You can also use third-party tools, but verify first that the cost provides value to your organization.",
                "url": "https://docs.aws.amazon.com/wellarchitected/latest/cost-optimization-pillar/cost_monitor_usage_detailed_source.html"
              },
              "improvementPlan": {
                "displayText": "Allow team-based access to tools: Configure your accounts and create groups that have access to the required cost and usage reports for their consumptions and use AWS Identity and Access Management to control access to the tools such as AWS Cost Explorer. These groups must include representatives from all teams that own or manage an application. This certifies that every team has access to their cost and usage information to track their consumption.\nConfigure AWS Budgets: Configure AWS Budgets on all accounts for your workload. Set budgets for the overall account spend, and budgets for the workloads by using tags. Configure notifications in AWS Budgets to receive alerts for when you exceed your budgeted amounts, or when your estimated costs exceed your budgets.\nConfigure AWS Cost Explorer: Configure AWS Cost Explorer for your workload and accounts to visualize your cost data for further analysis. Create a dashboard for the workload that tracks overall spend, key usage metrics for the workload, and forecast of future costs based on your historical cost data.\nConfigure AWS Cost Anomaly Detection: Use AWS Cost Anomaly Detection for your accounts, core services, or Cost Categories you created to monitor your cost and usage and detect unusual spends. You can receive alerts individually in aggregated reports, and receive alerts in an email or an Amazon Simple Notification Service topic which allows you to analyze and determine the root cause of the anomaly, and identify the factor that is driving the cost increase.\nConfigure advanced tools: Optionally, you can create custom tools for your organization that provide additional detail and granularity. You can implement advanced analysis capability using Amazon Athena, and dashboards using Amazon QuickSight. Consider using Cloud Intelligence Dashboards (CID) for pre-configured, advanced dashboards. There are also AWS Partners you can work with and adopt their cloud management solutions to activate cloud bill monitoring and optimization in one convenient location.",
                "url": "https://docs.aws.amazon.com/cost-management/latest/userguide/what-is-costmanagement.html"
              },
              "additionalResources": [
                {
                  "type": "IMPROVEMENT_PLAN",
                  "content": [
                    {
                      "displayText": "AWS Cost Management - Analyzing your costs with AWS Cost Explorer",
                      "url": "https://docs.aws.amazon.com/cost-management/latest/userguide/ce-what-is.html"
                    },
                    {
                      "displayText": "Using Cost Explorer reports",
                      "url": "https://docs.aws.amazon.com/cost-management/latest/userguide/ce-reports.html"
                    },
                    {
                      "displayText": "Managing your costs with AWS Budgets",
                      "url": "https://docs.aws.amazon.com/cost-management/latest/userguide/budgets-managing-costs.html"
                    },
                    {
                      "displayText": "Detecting unusual spend with AWS Cost Anomaly Detection",
                      "url": "https://docs.aws.amazon.com/cost-management/latest/userguide/manage-ad.html"
                    }
                  ]
                }
              ]
            },
            {
              "id": "COST_10_no",
              "title": "No budget control or usage monitoring"
            }
          ],
          "riskRules": [
            { "condition": "COST_10_1", "risk": "NO_RISK" },
            { "condition": "default", "risk": "HIGH_RISK" }
          ]
        },
        {
          "id": "COST_11",
          "title": "Do you have any cost attribution process of the IDP solution for your business to ensure accountability?",
          "description": "How are you tracking and attributing AWS Costs to specific projects or LOBs to ensure accountability?",
          "helpfulResource": {
            "displayText": "Identify organization categories such as business units, departments, or projects that could be used to allocate cost within your organization to the internal consuming entities so that spend accountability can be enforced and consumption behaviors can be driven effectively.",
            "url": "https://docs.aws.amazon.com/wellarchitected/latest/cost-optimization-pillar/cost_monitor_usage_define_attribution.html"
          },
          "choices": [
            {
              "id": "COST_11_1",
              "title": "We define AWS Cost Categories that map to our organization or functional categories.",
              "helpfulResource": {
                "displayText": "The process of categorizing costs is crucial in budgeting, accounting, financial reporting, decision making, benchmarking, and project management. By classifying and categorizing expenses, teams can gain a better understanding of the types of costs they will incur throughout their cloud journey, helping teams make informed decisions and manage budgets effectively.",
                "url": "https://docs.aws.amazon.com/wellarchitected/latest/cost-optimization-pillar/cost_monitor_usage_define_attribution.html"
              },
              "improvementPlan": {
                "displayText": "Define your organization categories: Meet with stakeholders to define categories that reflect your organization's structure and requirements. These will directly map to the structure of existing financial categories, such as business unit, budget, cost center, or department. Multiple categories can be assigned to a resource, and a resource can be in multiple different categories, so define as many categories as needed.\nDefine your functional categories: Meet with stakeholders to define categories that reflect the functions that you have within your business. This may be the workload or application names, and the type of environment, such as production, testing, or development. Multiple categories can be assigned to a resource, and a resource can be in multiple different categories, so define as many categories as needed so that you can manage your costs within the categorized structure using AWS Cost Categories.\nDefine AWS Cost Categories: You can create cost categories to organize your cost and usage information. Use AWS Cost Categories to map your AWS costs and usage into meaningful categories. With cost categories, you can organize your costs using a rule-based engine. T",
                "url": "https://docs.aws.amazon.com/wellarchitected/latest/cost-optimization-pillar/cost_monitor_usage_define_attribution.html"
              },
              "additionalResources": [
                {
                  "type": "IMPROVEMENT_PLAN",
                  "content": [
                    {
                      "displayText": "Cloud Financial Management - AWS Cost Categories Features",
                      "url": "https://aws.amazon.com/aws-cost-management/aws-cost-categories/features/"
                    },
                    {
                      "displayText": "AWS Billing - Managing your costs with AWS Cost Categories",
                      "url": "https://docs.aws.amazon.com/awsaccountbilling/latest/aboutv2/manage-cost-categories.html"
                    },
                    {
                      "displayText": "AWS Cloud Financial Management: Organize your cost and usage data with AWS Cost Categories",
                      "url": "https://aws.amazon.com/blogs/aws-cloud-financial-management/organize-your-cost-and-usage-data-with-aws-cost-categories/"
                    }
                  ]
                }
              ]
            },
            {
              "id": "COST_11_no",
              "title": "No specific process for cost attribution"
            }
          ],
          "riskRules": [
            { "condition": "COST_11_1", "risk": "NO_RISK" },
            { "condition": "default", "risk": "HIGH_RISK" }
          ]
        },
        {
          "id": "COST_12",
          "title": "How do you align expenditure to your business objectives and create Comprehend usage awareness ?",
          "description": "How to easily identify Comprehend Analysis jobs, Custom classification models, Custom entity recognition models, and endpointsusage and costs? This helps measure return on investment (ROI) and gives workload owners an opportunity to optimize their resources and reduce costs.",
          "helpfulResource": {
            "displayText": "Ensure cost effective decisions are made with respect to long-term resource allocation.",
            "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlcost-01.html"
          },
          "choices": [
            {
              "id": "COST_13_1",
              "title": "We use tags on Comprehend Analysis jobs, Custom classification models, Custom entity recognition models, and endpoints.",
              "helpfulResource": {
                "displayText": "A tag is a key-value pair that you can add to an Amazon Comprehend resource as metadata.\nTags have two major functions: organizing your resources and providing tag-based access control.",
                "url": "https://docs.aws.amazon.com/comprehend/latest/dg/tagging.html"
              },
              "improvementPlan": {
                "displayText": "Assign resource tags to Amazon Comprehend. Tagging resources helps identify, track, and itemize their usage and costs.",
                "url": "https://aws.amazon.com/blogs/machine-learning/amazon-comprehend-now-supports-resource-tagging-for-custom-models/"
              }
            },
            {
              "id": "COST_13_no",
              "title": "No specific process or mechanism"
            }
          ],
          "riskRules": [
            { "condition": "COST_13_1", "risk": "NO_RISK" },
            { "condition": "default", "risk": "HIGH_RISK" }
          ]
        }
      ]
    },
    {
      "id": "sustainability",
      "name": "Sustainability",
      "questions": [
        {
          "id": "SUS_1",
          "title": "Do you set up your IDP workflow in a region that meets your business requirements and sustainability goals?",
          "description": "To decide for the best regions for business requirements and sustainability goals, we recommend the following two steps: 1. Evaluate and shortlist potential regions for your workload based on your business requirements. 2. Select regions close to Amazon's renewable energy projects and regions listed as being powered by 100 percent renewable energy.",
          "helpfulResource": {
            "displayText": "When considering key business factors, you should evaluate latency, cost, available services and features and compliance.Based on the Greenhouse Gas (GHG) Protocol, there are two methods for tracking emissions from electricity production: market-based and location-based. Companies may choose one of these methods based on their relevant sustainability guidelines to track and compare their emissions year-to-year. Amazon uses themarket-based model to report our emissions.",
            "url": "https://aws.amazon.com/blogs/architecture/how-to-select-a-region-for-your-workload-based-on-sustainability-goals/"
          },
          "choices": [
            {
              "id": "SUS_1_1",
              "title": "Select a region that meets your business requirements.",
              "helpfulResource": {
                "displayText": "When considering key business factors, you should evaluate latency, cost, available services and features and compliance.",
                "url": "https://docs.aws.amazon.com/wellarchitected/latest/sustainability-pillar/sus_sus_region_a2.html"
              },
              "improvementPlan": {
                "displayText": "Start by shortlisting potential Regions for your workload based on your business requirements, including compliance, cost, and latency. Newer services and features are deployed to Regions gradually. Refer to List of AWS Services Available by Region to check which Regions have the services and features you need to run your IDP workload.",
                "url": "https://docs.aws.amazon.com/wellarchitected/latest/sustainability-pillar/sus_sus_region_a2.html"
              }
            },
            {
              "id": "SUS_1_2",
              "title": "Select a region listed as powered by 100 percent renewable energy.",
              "helpfulResource": {
                "displayText": "Identify your relevant sustainability guidelines to track and compare year-to-year carbon emissions based on Greenhouse Gas Protocol (market-based and location based methods).\nChoose region based on method you use to track carbon emissions. Amazon is on a path to powering our operations with 100 percent renewable energy by 2025. In the below link you can find all regions which are already powered by 100 percent renewable energy",
                "url": "https://sustainability.aboutamazon.com/products-services/the-cloud?energyType=true"
              },
              "improvementPlan": {
                "displayText": "From your shortlist, identify Regions close to Amazon’s renewable energy projects and Regions where, in 2022, the electricity consumed was attributable to 100% renewable energy.",
                "url": "https://sustainability.aboutamazon.com/products-services/the-cloud?energyType=true"
              }
            },
            {
              "id": "SUS_1_no",
              "title": "None of these"
            }
          ],
          "riskRules": [
            { "condition": "SUS_1_1 && SUS_1_2", "risk": "NO_RISK" },
            { "condition": "default", "risk": "MEDIUM_RISK" }
          ]
        },
        {
          "id": "SUS_2",
          "title": "How do you manage your data and the lifecycle of your data to optimize your sustainability footprint?",
          "description": "Managing your data and data lifecycle and using different storage tiers are key components to optimizing storage for sustainability.",
          "helpfulResource": {
            "displayText": "Storing and accessing data efficiently, in addition to reducing idle storage resources results in a more efficient and sustainable architecture. When you consider different storage mechanisms, remember that youre introducing a trade-off between resource efficiency, access latency, and reliability. This means youll need to select your management pattern accordingly.",
            "url": "https://aws.amazon.com/blogs/architecture/optimizing-your-aws-infrastructure-for-sustainability-part-ii-storage/"
          },
          "choices": [
            {
              "id": "SUS_2_1",
              "title": "Create and ingest only relevant data",
              "helpfulResource": {
                "displayText": "To optimize your storage footprint for sustainability, evaluate what data is needed to meet your business objectives and create and ingest only relevant data.",
                "url": "https://aws.amazon.com/blogs/architecture/optimize-your-modern-data-architecture-for-sustainability-part-1-data-ingestion-and-data-lake/"
              },
              "improvementPlan": {
                "displayText": "To optimize your storage footprint for sustainability, evaluate what data is needed to meet your business objectives and create and ingest only relevant data along your IDP workflow.",
                "url": "https://aws.amazon.com/blogs/architecture/optimize-your-modern-data-architecture-for-sustainability-part-1-data-ingestion-and-data-lake/"
              }
            },
            {
              "id": "SUS_2_2",
              "title": "Ingest data at the optimal resolution for your business goals, rather than choosing the maximum resolution available",
              "helpfulResource": {
                "displayText": "To optimize your data ingest and storage, consider the optimal data resolution that satisfies the use case. Amazon Textract requires at least 150 DPI. If your document isn’t in a supported Amazon Textract format (PDF, TIFF, JPEG, and PNG) and you need to convert it, experiment to find the optimal resolution for best results rather than choosing the maximum resolution.",
                "url": "https://docs.aws.amazon.com/textract/latest/dg/textract-best-practices.html"
              },
              "improvementPlan": {
                "displayText": "To optimize your data ingest and storage, consider the optimal data resolution that satisfies the use case. Amazon Textract requires at least 150 DPI. If your document isn’t in a supported Amazon Textract format (PDF, TIFF, JPEG, and PNG) and you need to convert it, experiment to find the optimal resolution for best results rather than choosing the maximum resolution.",
                "url": "https://docs.aws.amazon.com/textract/latest/dg/textract-best-practices.html"
              }
            },
            {
              "id": "SUS_2_3",
              "title": "Store only relevant data",
              "helpfulResource": {
                "displayText": "When designing your IDP workflow, consider for each step in your workflow which intermediate data outputs need to be stored. In most IDP workflows, it’s not necessary to store the data used or created in each intermediate step because it can be easily reproduced.Only store data that is relevant and not easily reproducible. If you need to store intermediate results, consider whether they qualify for a lifecycle rule that archives and deletes them more quickly than data with stricter retention requirements.Preserve data across computing environments such as development and staging. Implement mechanisms to enforce a data lifecycle management process including archiving and deletion and continuously identify unused data and delete it.",
                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlsec-07.html"
              },
              "improvementPlan": {
                "displayText": "To improve sustainability, only store data that is not easily reproducible. If you need to store intermediate results, consider whether they qualify for a lifecycle rule that archives and deletes them more quickly than data with stricter retention requirements.Preserve data across computing environments such as development and staging. Implement mechanisms to enforce a data lifecycle management process including archiving and deletion and continuously identify unused data and delete it.",
                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlsec-07.html"
              }
            },
            {
              "id": "SUS_2_4",
              "title": "Use the right technology to store data",
              "helpfulResource": {
                "displayText": "For IDP workflows, most of the data is likely to be documents. Amazon Simple Storage Service (Amazon S3) is an object storage built to store and retrieve any amount of data from anywhere, making it well suited for IDP workflows. Using different Amazon S3 storage tiers is a key component of optimizing storage for sustainability. When considering different storage mechanisms, remember that you're making tradeoffs between resource efficiency, access latency, and reliability. That means you'll need to select your management pattern accordingly. By storing less volatile data on technologies designed for efficient long-term storage, you can optimize your storage footprint.",
                "url": "https://aws.amazon.com/blogs/architecture/optimizing-your-aws-infrastructure-for-sustainability-part-ii-storage/"
              },
              "improvementPlan": {
                "displayText": "Use the right technology to store data. Storing and accessing data efficiently results in a more sustainable architecture. Amazon CloudWatch offers storage metrics that can be used to assess storage improvements. Using different Amazon S3 storage tiers is a key component of optimizing storage for sustainability. When considering different storage mechanisms, remember that you're making tradeoffs between resource efficiency, access latency, and reliability. That means you'll need to select your management pattern accordingly. By storing less volatile data on technologies designed for efficient long-term storage, you can optimize your storage footprint. ",
                "url": "https://aws.amazon.com/blogs/architecture/optimizing-your-aws-infrastructure-for-sustainability-part-ii-storage/"
              }
            },
            {
              "id": "SUS_2_5",
              "title": "Actively manage your data lifecycle according to your sustainability goals",
              "helpfulResource": {
                "displayText": "Managing your data lifecycle means optimizing your storage footprint. To store your data efficiently throughout its lifetime, create Amazon S3 Lifecycle configurations that automatically transfers objects to a different storage class based on your pre-defined rules. For data with unknown or changing access patterns, use Amazon S3 Intelligent-Tiering to monitor access patterns and move objects among tiers automatically. In general, you have to make a trade-off between resource efficiency, access latency, and reliability when considering these storage mechanisms.",
                "url": "https://aws.amazon.com/blogs/architecture/optimizing-your-aws-infrastructure-for-sustainability-part-ii-storage/"
              },
              "improvementPlan": {
                "displayText": "Actively manage your data lifecycle according to your sustainability goals. Use Amazon S3 Lifecycle configurations that automatically transfers objects to a different storage class based on your pre-defined rules. Consider expiring Amazon S3 objects based on last accessed date.",
                "url": "https://aws.amazon.com/blogs/architecture/optimizing-your-aws-infrastructure-for-sustainability-part-ii-storage/"
              }
            },
            {
              "id": "SUS_2_6",
              "title": "Continuously optimize your storage footprint by using the right tools",
              "helpfulResource": {
                "displayText": "Tools like Amazon S3 Storage Lens delivers visibility into storage usage, activity trends, and even makes recommendations for improvements. This information can be used to lower the environmental impact of storing data.",
                "url": "https://aws.amazon.com/s3/storage-analytics-insights/"
              },
              "improvementPlan": {
                "displayText": "Leverage tools like Amazon S3 Storage Lens to continuously analyze and optimize your storage footprint of your IDP workflow.",
                "url": "https://aws.amazon.com/s3/storage-analytics-insights/"
              }
            },
            {
              "id": "SUS_2_7",
              "title": "Enable data and compute proximity",
              "helpfulResource": {
                "displayText": "As you make your IDP workflow available to more customers, the amount of data traveling over the network will increase. Similarly, the larger the size of the data and the greater the distance a packet must travel, the more resources are required to transmit it. Reducing the amount of data sent over the network and optimizing the path a packet takes will result in more efficient data transfer. Setting up data storage closely to data processing helps optimize sustainability at the network layer.",
                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlcost-21.html"
              },
              "improvementPlan": {
                "displayText": "Ensure that the region used to store the data is the same region where ou have deployed your IDP workflow. This approach helps minimize the time and cost of transferring data to the computing environment.",
                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlcost-21.html"
              }
            },
            {
              "id": "SUS_2_no",
              "title": "None of these"
            }
          ],
          "riskRules": [
            {
              "condition": "SUS_2_1 && SUS_2_2 && SUS_2_3 && SUS_2_4 && SUS_2_5 && SUS_2_6 && SUS_2_7",
              "risk": "NO_RISK"
            },
            { "condition": "default", "risk": "MEDIUM_RISK" }
          ]
        },
        {
          "id": "SUS_3",
          "title": "Do you re-evaluate your IDP workflow when a new feature is released in a related service?",
          "description": "Keeping your IDP workloads up to date will help you reduce the sustainability impact and gain performance efficiencies. There are several blogs and resources available to help you stay on top of AWS announcements.",
          "helpfulResource": {
            "displayText": "Keep your workload up-to-date to adopt efficient features, remove issues, and improve the overall efficiency of your workload.",
            "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/sus_sus_dev_a3.html"
          },
          "choices": [
            {
              "id": "SUS_3_1",
              "title": "Use AWS re:post to stay informed about feature updates",
              "helpfulResource": {
                "displayText": "re:Post is a community-driven, questions-and-answers service designed to help AWS customers remove technical roadblocks, accelerate innovation, and enhance operations. AWS re:Post has 40+ topics including a community dedicated to AWS Well-Architected.",
                "url": "https://repost.aws/"
              },
              "improvementPlan": {
                "displayText": "Use AWS re:post to stay informed about feature updates and get support for improving sustainability in a community dedicated to AWS Well-Architected.",
                "url": "https://aws.amazon.com/about-aws/whats-new/2022/05/aws-community-well-architected-tool/"
              }
            },
            {
              "id": "SUS_3_2",
              "title": "Use AWS Blogs to stay up to date for Amazon Textract",
              "helpfulResource": {
                "displayText": "AWS blogs help customers stay up-to-date on the most important services they use. To stay up to date on Amazon Textract, check out the Machine Learning blog.",
                "url": "https://aws.amazon.com/blogs/machine-learning/category/artificial-intelligence/amazon-textract/"
              },
              "improvementPlan": {
                "displayText": "Use AWS Blogs to stay up to date for Amazon Textract",
                "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/sus_sus_dev_a3.html"
              }
            },
            {
              "id": "SUS_3_3",
              "title": "Use AWS Blogs to stay up to date for Amazon Comprehend",
              "helpfulResource": {
                "displayText": "AWS blogs help customers stay up-to-date on the most important services they use. To stay up to date on Amazon Comprehend, check out the Machine Learning blog.",
                "url": "https://aws.amazon.com/blogs/machine-learning/category/artificial-intelligence/amazon-comprehend/"
              },
              "improvementPlan": {
                "displayText": "Use AWS Blogs to stay up to date for Amazon Comprehend",
                "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/sus_sus_dev_a3.html"
              }
            },
            {
              "id": "SUS_3_no",
              "title": "None of these"
            }
          ],
          "riskRules": [
            { "condition": "SUS_3_1 && SUS_3_2 && SUS_3_3", "risk": "NO_RISK" },
            { "condition": "default", "risk": "MEDIUM_RISK" }
          ]
        },
        {
          "id": "SUS_4",
          "title": "How do you design your IDP solution for continuous improvement?",
          "description": "Creating a flexible, extensible architecture for your IDP solution enables you to optimize resource usage over time.",
          "helpfulResource": {
            "displayText": "Improving sustainability is a continuous process that requires flexible architectures and automation to support frequent improvements. When your architecture is loosely coupled and leverages serverless and managed services, it is easy to enable new features and replace components for increased sustainability.",
            "url": "https://docs.aws.amazon.com/wellarchitected/latest/sustainability-pillar/improvement-process.html"
          },
          "choices": [
            {
              "id": "SUS_4_1",
              "title": "Improve safely and continuously through automation",
              "helpfulResource": {
                "displayText": "Using automation to deploy all changes reduces the potential for human error and enables you to test before making production changes to ensure your plans are complete. Automate your software delivery process using continuous integration and continuous delivery (CI/CD) pipelines to test and deploy potential improvements to reduce effort and limit errors caused by manual processes. Define changes using infrastructure as code (IaC): all configurations should be defined declaratively and stored in a source control system like AWS CodeCommit, just like application code. Infrastructure provisioning, orchestration, and deployment should also support IaC.",
                "url": "https://aws.amazon.com/getting-started/hands-on/set-up-ci-cd-pipeline/"
              },
              "improvementPlan": {
                "displayText": "Improve safely and continuously through automation. Automate your software delivery process using continuous integration and continuous delivery (CI/CD) pipelines.Define changes using infrastructure as code (IaC): all configurations should be defined declaratively and stored in a source control system like AWS CodeCommit, just like application code. Infrastructure provisioning, orchestration, and deployment should also support IaC.",
                "url": "https://aws.amazon.com/getting-started/hands-on/set-up-ci-cd-pipeline/"
              }
            },
            {
              "id": "SUS_4_2",
              "title": "Use an event-driven architecture",
              "helpfulResource": {
                "displayText": "IDP workflows are typically characterized by high peaks and periods of inactivity (such as outside of business hours), and are mostly driven by events (for example, when a new document is uploaded). This makes them a good fit for serverless solutions. Using AWS serverless services to implement an event-driven approach will allow you to build scalable, fault-tolerant IDP workflows and minimize idle resources.",
                "url": "https://aws.amazon.com/event-driven-architecture/"
              },
              "improvementPlan": {
                "displayText": "Using AWS serverless services to implement an event-driven approach will allow you to build scalable, fault-tolerant IDP workflows and minimize idle resources.For example, you can configure Amazon S3 to start a new workflow when a new document is uploaded. Amazon S3 can trigger EventBridge or call a Lambda function to start an Amazon Textract detection job. You can use Amazon Simple Notification Service (Amazon SNS) topics for event fanout or to send job completion messages. You can use Amazon Simple Queue Service (Amazon SQS) for reliable and durable communication between microservices, such as invoking a Lambda function to read Amazon Textract output and then calling a custom Amazon Comprehend classifier to classify a document.",
                "url": "https://aws.amazon.com/event-driven-architecture/"
              }
            },
            {
              "id": "SUS_4_3",
              "title": "Use serverless services for workflow orchestration",
              "helpfulResource": {
                "displayText": "AWS serverless services can help you build a scalable solution for IDP workflows quickly and sustainably. Services such as AWS Lambda, AWS Step Functions, and Amazon EventBridge help orchestrate your workflow driven by events and minimize idle resources to improve sustainability.",
                "url": "https://docs.aws.amazon.com/prescriptive-guidance/latest/cloud-design-patterns/orchestration-choreography.html"
              },
              "improvementPlan": {
                "displayText": "IDP workflows are typically characterized by high peaks and periods of inactivity (such as outside of business hours), and are mostly driven by events (for example, when a new document is uploaded). This makes them a good fit for serverless solutions. AWS serverless services can help you build a scalable solution for IDP workflows quickly and sustainably. Services such as AWS Lambda, AWS Step Functions, and Amazon EventBridge help orchestrate your workflow driven by events and minimize idle resources to improve sustainability.",
                "url": "https://docs.aws.amazon.com/prescriptive-guidance/latest/cloud-design-patterns/orchestration-choreography.html"
              }
            },
            {
              "id": "SUS_4_4",
              "title": "Use managed services like Textract and Comprehend",
              "helpfulResource": {
                "displayText": "IDP can be performed using a custom model or managed services such as Amazon Textract and Amazon Comprehend, reducing the effort required to develop and retrain your service. By using managed services instead of your own custom model, you can reduce the amount of energy required to train a model.",
                "url": "https://aws.amazon.com/solutions/guidance/intelligent-document-processing-on-aws/"
              },
              "improvementPlan": {
                "displayText": "Use managed services like Textract and Comprehend.",
                "url": "https://aws.amazon.com/solutions/guidance/intelligent-document-processing-on-aws/"
              }
            },
            {
              "id": "SUS_4_no",
              "title": "None of these"
            }
          ],
          "riskRules": [
            {
              "condition": "SUS_4_1 && SUS_4_2 && SUS_4_3 && SUS_4_4",
              "risk": "NO_RISK"
            },
            { "condition": "default", "risk": "MEDIUM_RISK" }
          ]
        }
      ]
    }
  ],
  "ready": true
}
