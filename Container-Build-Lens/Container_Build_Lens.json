{
    "schemaVersion":"2021-11-01",
    "name":"Container Build Lens",
    "description":"The Container Build Lens will focus specifically on the container design and build process. Topics such as best practices for container orchestration architecture design principals and general best practices in software development are considered out of scope for this lens. These topics are addressed in other AWS publications. See the Resources sections under Pillars of the Well-Architected Framework for more information.",
    "pillars":[
       {
          "id":"OPS",
          "name":"Operational Excellence",
          "questions":[
             {
                "id":"OPS1",
                "title":"How do you manage the lifecycle of your containers and images?",
                "description":"It is important to understand what is built into your container image.",
                "choices":[
                   {
                      "id":"OPS1_1",
                      "title":" Understand the lineage of your container image",
                      "helpfulResource":{
                         "displayText":"Understanding the lineage of your container image helps you efficiently develop, run, manage, and maintain your containers. It also helps maintain your security posture. You can find more details in the Security Pillar whitepaper.",
                         "url":"https://docs.aws.amazon.com/wellarchitected/latest/container-build-lens/prepare.html"
                      },
                      "improvementPlan":{
                         "displayText":" It is important to understand what is built into your container image. When you start building a new project, at times it’s easier to use a base image from a verified source, such as an official Ubuntu image. While these help developers get up and running faster, often images contain packages and libraries that are not required to run your application and take up additional space. Starting with a minimal container image will save space and speed up the starting of your container when it’s deployed into production. Many customers that we speak with take the additional step of creating parent images. These images form the base for what all containers in the organization are built on top of. These parent images are minimal images that put into place requirements and security controls established by the organization. For example, the parent image can configure an internal package source repository that contains curated and validated library package versions."
                      }
                   },
                   {
                      "id":"OPS1_2",
                      "title":"Have parity between your deployment environments",
                      "helpfulResource":{
                         "displayText":"A major benefit of using containers is to provide the ability for the development team to develop new updates and features using an identical artifact that runs in production. As much as possible, development, testing, QA, and production environments in that it will be eventually deployed should be as similar as possible.",
                         "url":"https://docs.aws.amazon.com/wellarchitected/latest/container-build-lens/prepare.html"
                      },
                      "improvementPlan":{
                         "displayText":" All environments should share best practices for everything, with the differences between them being the ability to scale and the data operated upon. Best practices for development environments differ between orchestration tools so make sure you are following recommendations based on your containerized platform of choice."
                      }
                   },
                   {
                      "id":"OPS1_3",
                      "title":"Build the image once and use the same image in all environments",
                      "helpfulResource":{
                         "displayText":"Once the new image has been built with the updates in place for deployment, promote the same image into the next environment, testing, QA, and production, to provide for consistency across all environments. This will reduce the number of changes introduced in each new environment and provide for more consistent behavior.",
                         "url":"https://docs.aws.amazon.com/wellarchitected/latest/container-build-lens/prepare.html"
                      },
                      "improvementPlan":{
                         "displayText":"Promote the same image into the next environment, testing, QA, and production, to provide for consistency across all environments."
                      }
                   },
                   {
                      "id":"OPS1_4",
                      "title":"Use a CI/CD build process",
                      "helpfulResource":{
                         "displayText":"Like with your applications, you should use a CI/CD pipeline to build and test your images through every stage in your development process. The CI process usually starts upon a trigger that is sent from a version control system (usually git). Whether your application requires compilation or not, there are several steps to take to build the container.",
                         "url":"https://docs.aws.amazon.com/wellarchitected/latest/container-build-lens/prepare.html"
                      },
                      "improvementPlan":{
                         "displayText":"Check the code out from the code repository.Build the application artifact (executable binary or language-specific archive).Build the container image from the artifact that you just created.Run tests against the built container image.Push the container image to the target container registry.Once built, you will begin continuous deployment where an automated deployment pipeline takes the recently built container image, its manifests, and container package (Helm chart, Kustomization overlay, and so on), and deploys it to the target environment."
                      }
                   },
                   {
                      "id":"OPS1_5",
                      "title":"Multi-stage builds",
                      "helpfulResource":{
                         "displayText":"Small container images have undeniable performance advantages. The pull from the registry is faster because less data is transferred over the network, and the container startup time is also reduced. This can be achieved by using multi-stage builds. With this mechanism, you can split the build-phase of the image from the final image that will be used to run the application.",
                         "url":"https://docs.aws.amazon.com/wellarchitected/latest/container-build-lens/prepare.html"
                      },
                      "improvementPlan":{
                         "displayText":"In this example, we start building a container image with the build stage builder that will be referenced in the target image. In the builder-stage, we generate the complete build environment with all the dependencies (in this case JDK and Maven) and build the JAR-file containing the application. In the second step of the build process, there is an additional FROM statement that indicates we start a new build stage. The COPY command references the former builder-stage and copies the JAR-file into the current stage of the build. With this approach, it is possible to implement reproducible builds with all necessary dependencies and lightweight target images. However, this build process is more complicated compared to standard builds and usually takes longer."
                      }
                   },
                   {
                      "id":"OPS1_6",
                      "title":"Implement a minimal container image design to achieve your business and security objectives",
                      "helpfulResource":{
                         "displayText":"It is important to build into your container image only what is necessary.",
                         "url":"https://docs.aws.amazon.com/wellarchitected/latest/container-build-lens/prepare.html"
                      },
                      "improvementPlan":{
                         "displayText":"Pictures and other static assets should be stored in a data store, for example Amazon Simple Storage Service (Amazon S3) in AWS, and served through a content delivery network (CDN). This will achieve a minimal container image size, which does not only reduce the storage and running host resource requirements, but it also speeds up the instantiation of a new container from an image if the image itself is not cached locally."
                      }
                   },
                   {
                      "id":"OPS1_7",
                      "title":"Using package managers to deploy your containerized applications",
                      "helpfulResource":{
                         "displayText":"When building a containerized application, the deployable unit can be not only the container image, but its per-environment configuration that is deployed alongside with the container image to the target environment. To achieve this, users can use packaging tooling such as Helm and Kustomize for Kubernetes, AWS Copilot for Amazon Elastic Container Service (Amazon ECS), Docker Swarm for Docker, and more.",
                         "url":"https://docs.aws.amazon.com/wellarchitected/latest/container-build-lens/prepare.html"
                      },
                      "improvementPlan":{
                         "displayText":"That means when building your containerized application, the target artifact will be a package that contains a reference to the container image and its common configurations across all environments. Such configurations can be environment variable, flags, ports, and other specific configurations. This package will then be deployed to different target environments with per-environment customizations. An example of this can be a Helm chart with an application that references a database endpoint. The Helm chart will contain all the common configurations for development, testing, and production environment, leaving some values to be configured per-environment such as the database endpoint. Then there will be different files such as values-dev.yaml and a values-prod.yaml that will contain different database endpoints for the development and production environments."
                      }
                   }
                ],
                "riskRules":[
                   {
                      "condition":"OPS1_1 && OPS1_2 && OPS1_3 && OPS1_4 && OPS1_5 && OPS1_6 && OPS1_7",
                      "risk":"NO_RISK"
                   },
                   {
                      "condition":"(!OPS1_1) || (!OPS1_2) || (!OPS1_4) || (!OPS1_7)",
                      "risk":"HIGH_RISK"
                   },
                   {
                      "condition":"default",
                      "risk":"MEDIUM_RISK"
                   }
                ]
             },
             {
                "id":"OPS2",
                "title":"How do you know whether your containerized workload is achieving its business goals?",
                "description":"To ensure the success of your running container, you must understand the health of your containerized workload as well as what your customers are experiencing when they interact with your application.",
                "choices":[
                   {
                      "id":"OPS2_1",
                      "title":"Implement health checks to determine container state",
                      "helpfulResource":{
                         "displayText":"Implement container health checks. Health checks are one way to determine the health of your running container. They enable your orchestration tooling to direct connection traffic to the container only when it is ready to accept connections, or stop routing connections to the container if the health checks show that the container is no longer running as expected. In the latter case, the orchestration tooling will tear down the misbehaving container and replace it with a new healthy one.For example, with Amazon ECS you can define health checks as part of the task definition, and perform load balancer health checks for your running application.  ",
                         "url":"https://docs.aws.amazon.com/wellarchitected/latest/container-build-lens/operate.html"
                      },
                      "improvementPlan":{
                         "displayText":"For Kubernetes and Amazon Elastic Kubernetes Service (Amazon EKS), you can take advantage of features such as liveness probes to detect deadlock condition, readiness probes to determine if the pod is prepared to receive requests, and startup probes to know when the application running in the container has started. Liveness probes can either be shell commands or HTTP requests of TCP probes. "
                      }
                   },
                   {
                      "id":"OPS2_2",
                      "title":"Have your logs available outside the running container",
                      "helpfulResource":{
                         "displayText":"Ensure that the logs generated by your running containers are collected and accessible externally. This will enable you to use log monitors to gain more insights into the behavior and functionality of your running container. Your application should be writing its logs to STDOUT and STDERR so that a logging agent can ship the logs to your log monitoring system. As with other application workloads, you must understand the metrics and messages that you have collected from your workload. Not only must you understand the data emitted by your containers, but you must also have a standardized log format to easily evaluate the data with your logging tools. Logging collector and forwarder tools give you the ability to standardize your log format across multiple containerized services.",
                         "url":"https://docs.aws.amazon.com/wellarchitected/latest/container-build-lens/operate.html"
                      },
                      "improvementPlan":{
                         "displayText":"To enable you and your team to pinpoint where issues may be occurring, define your log messages to be consistently structured to enable correlation of logs across multiple microservices in your central logging system.This understanding enables you to evolve your workload to respond to external pressures such as increased traffic or issues with external APIs that your workload may use in the course of accomplishing its business goals. "
                      }
                   }
                ],
                "riskRules":[
                   {
                      "condition":"OPS2_1 && OPS2_2",
                      "risk":"NO_RISK"
                   },
                   {
                      "condition":"(!OPS2_1) || (!OPS2_2)",
                      "risk":"HIGH_RISK"
                   },
                   {
                      "condition":"default",
                      "risk":"MEDIUM_RISK"
                   }
                ]
             }
          ]
       },
       {
          "id":"SEC",
          "name":"Security",
          "questions":[
             {
                "id":"SEC1",
                "title":"How do you ensure that your container images are using least privilege identity?",
                "description":"When the processes inside the container are running as the root user, not only do they have full administrative access to containers, they also have the same administrative level access to the container host. Having an application running within a container through the root user expands the attack surface of the environment.",
                "choices":[
                   {
                      "id":"SEC1_1",
                      "title":"define the USER directive in the Dockerfile used to compile the image",
                      "helpfulResource":{
                         "displayText":"By default, containers provide process isolation. This means that processes running inside of a container are isolated from processes and data that exist in other containers as well as the container host’s operating system. However, it is important to note that the default behavior is to run the container using the root user when running a container. When the processes inside the container are running as the root user, not only do they have full administrative access to containers, they also have the same administrative level access to the container host. Having an application running within a container through the root user expands the attack surface of the environment. This could provide bad actors with the ability to escalate privilege to the container host infrastructure if the application is compromised.",
                         "url":"https://docs.aws.amazon.com/wellarchitected/latest/container-build-lens/identity-and-access-management.html"
                      },
                      "improvementPlan":{
                         "displayText":"There are multiple ways to mitigate this risk. The most straightforward method is to define the USER directive in the Dockerfile used to compile the image"
                      }
                   }
                ],
                "riskRules":[
                   {
                      "condition":"SEC1_1",
                      "risk":"NO_RISK"
                   },
                   {
                      "condition":"!SEC1_1",
                      "risk":"MEDIUM_RISK"
                   },
                   {
                      "condition":"default",
                      "risk":"HIGH_RISK"
                   }
                ]
             },
             {
                "id":"SEC2",
                "title":"How do you control access to your build infrastructure?",
                "description":"To ensure the success of your running container, you must understand the health of your containerized workload as well as what your customers are experiencing when they interact with your application.",
                "choices":[
                   {
                      "id":"SEC2_1",
                      "title":"Limit administrator access to build infrastructure (CI pipeline)",
                      "helpfulResource":{
                         "displayText":"Adding continuous security validation in a build pipeline is a major focus for organizations moving to a DevSecOps strategy. This helps ensure that security is built into the application from the beginning of the application’s lifecycle as opposed to performing security testing only at the end of the development process. However, it is important to note that securing an organization’s build pipeline should be considered a high priority as well, as the pipeline typically accesses databases, proprietary code, and secrets or credentials across dev, test, and prod environments.",
                         "url":"https://docs.aws.amazon.com/wellarchitected/latest/container-build-lens/identity-and-access-management.html"
                      },
                      "improvementPlan":{
                         "displayText":"A compromised build pipeline could provide a bad actor with access to all of the preceding resources in a customer environment. As detailed in the security pillar of the AWS Well-Architected Framework, it is important to follow the best practice of granting the least privileged access to the container build infrastructure. The least privileged best practice should be applied to human identities as well as machine identities. An example might be that a human identity that has access to the container build infrastructure can reach an application’s source code, secrets, and other sensitive data."
                      }
                   }
                ],
                "riskRules":[
                   {
                      "condition":"SEC2_1",
                      "risk":"NO_RISK"
                   },
                   {
                      "condition":"!SEC2_1",
                      "risk":"MEDIUM_RISK"
                   },
                   {
                      "condition":"default",
                      "risk":"HIGH_RISK"
                   }
                ]
             },
             {
                "id":"SEC3",
                "title":"How do you detect and address vulnerabilities within your container image?",
                "description":"To ensure the success of your running container, you must understand the health of your containerized workload as well as what your customers are experiencing when they interact with your application.",
                "choices":[
                   {
                      "id":"SEC3_1",
                      "title":"Ensure that your images are scanned for vulnerabilities",
                      "helpfulResource":{
                         "displayText":"After images are built, it is important to maintain a regular cadence of scanning those images to ensure no new or existing vulnerabilities have surfaced. There are two basic categories to consider when discussing image scanning: static scanning and dynamic scanning. Static scanning is performed before the image is deployed. This is important because it allows organizations to detect vulnerabilities in a container image before a container is deployed into an environment.",
                         "url":"https://docs.aws.amazon.com/wellarchitected/latest/container-build-lens/detective-controls.html"
                      },
                      "improvementPlan":{
                         "displayText":" Many registry offerings provide native static image scanning that can scan container images for common vulnerabilities and exposures (CVEs) without having to integrate and maintain a third-party image scanning tool. The scanning process is performed by comparing parent container images, dependencies, and libraries that are used by the container image to known CVEs. Dynamic container scanning is a process that scans the underlying infrastructure where containers run. It is executed post container deployment, and identifies vulnerabilities that may have been introduced by other software installed on the infrastructure itself. These vulnerabilities can be either modifications to an existing running container, or communication with a container that is exposed externally to other processes or hosts."
                      }
                   }
                ],
                "riskRules":[
                   {
                      "condition":"SEC3_1",
                      "risk":"NO_RISK"
                   },
                   {
                      "condition":"!SEC3_1",
                      "risk":"MEDIUM_RISK"
                   },
                   {
                      "condition":"default",
                      "risk":"HIGH_RISK"
                   }
                ]
             },
             {
                "id":"SEC4",
                "title":"How do you manage your container image boundaries?",
                "description":"Managing container image boundaries",
                "choices":[
                   {
                      "id":"SEC4_1",
                      "title":"Minimize attack surface",
                      "helpfulResource":{
                         "displayText":"In the context of container workloads, infrastructure protection is often a topic with respect to the container as a vector to access the underlying compute infrastructure. In any security context, reducing attack surface is top of mind. This can be accomplished when designing and building your container in a variety of ways",
                         "url":"https://docs.aws.amazon.com/wellarchitected/latest/container-build-lens/infrastructure-protection.html"
                      },
                      "improvementPlan":{
                         "displayText":"Run distroless images without a shell or a package manager to ensure that bad actors cannot make changes to the image or easily download software packages to aid in their attack.Build open-source libraries from source or scan libraries for vulnerabilities to ensure awareness of all of the components of the container image.Remove or defang setuid and setgid bits from the container image to make sure that these permissions are not used in privilege escalation attacks.Lint your Dockerfile to help identify violations of best practices for building container images.Use a tool such as docker-slim to analyze existing images and remove unnecessary binaries not required by the application.Ensure that your container is designed to operate with a read-only root filesystem. This functionality is normally defined at runtime but it is important to consider this facet when designing the container itself."
                      }
                   },
                   {
                      "id":"SEC4_2",
                      "title":"Understand the lineage of your container image",
                      "helpfulResource":{
                         "displayText":"Aside from reducing attack surface, it is also important to understand where your container images are coming from. If not building images from scratch, you should only run images from trusted registries that have been signed with a trusted signature to ensure integrity. Regarding signing images, it is recommended to utilize signed images to ensure that the contents of the container have not been modified before they are deployed.",
                         "url":"https://docs.aws.amazon.com/wellarchitected/latest/container-build-lens/infrastructure-protection.html"
                      },
                      "improvementPlan":{
                         "displayText":"In general, don’t incorporate images directly from a public repository into your container pipeline. Private registries should be used to allow an organization to maintain complete control and visibility over their container image catalog. If using images originating from public repositories, they should be scanned, signed, and stored in a private registry to ensure that the contents of the image are known and verified against existing security standards."
                      }
                   }
                ],
                "riskRules":[
                   {
                      "condition":"SEC4_1 && SEC4_2",
                      "risk":"NO_RISK"
                   },
                   {
                      "condition":"SEC4_1 && !SEC4_2",
                      "risk":"MEDIUM_RISK"
                   },
                   {
                      "condition":"default",
                      "risk":"HIGH_RISK"
                   }
                ]
             },
             {
                "id":"SEC5",
                "title":"How do you handle data within your containerized applications?",
                "description":"Handling data within containerized applications",
                "choices":[
                   {
                      "id":"SEC5_1",
                      "title":"Do not hardcode sensitive data into your container image",
                      "helpfulResource":{
                         "displayText":"With respect to handling data in the build and design of the container, it is important that no sensitive information is stored in the container itself. For example, user credentials should never be hardcoded into your container image.",
                         "url":"https://docs.aws.amazon.com/wellarchitected/latest/container-build-lens/data-protection.html"
                      },
                      "improvementPlan":{
                         "displayText":"Instead, consider using a secret management protocol that is compatible with the container orchestration system being used to manage the container workloads."
                      }
                   },
                   {
                      "id":"SEC5_2",
                      "title":" Ensure that persistent data is stored outside of the container",
                      "helpfulResource":{
                         "displayText":"Also, if your containerized application writes or consumes persistent data, ensure that data is stored outside of the container. Since containers are intended to be ephemeral, use volumes to store persistent data that will remain intact long after a container’s lifecycle has completed. ",
                         "url":"https://docs.aws.amazon.com/wellarchitected/latest/container-build-lens/data-protection.html"
                      },
                      "improvementPlan":{
                         "displayText":"Also, if your containerized application writes or consumes persistent data, ensure that data is stored outside of the container. Since containers are intended to be ephemeral, use volumes to store persistent data that will remain intact long after a container’s lifecycle has completed."
                      }
                   }
                ],
                "riskRules":[
                   {
                      "condition":"SEC5_1 && SEC5_2",
                      "risk":"NO_RISK"
                   },
                   {
                      "condition":"SEC5_1 && !SEC5_2",
                      "risk":"MEDIUM_RISK"
                   },
                   {
                      "condition":"default",
                      "risk":"HIGH_RISK"
                   }
                ]
             }
          ]
       },
       {
          "id":"REL",
          "name":"Reliability",
          "questions":[
             {
                "id":"REL1",
                "title":"How do you limit the amount of CPU and memory a container consumes?",
                "description":"Whatever container orchestrator you are using, specifying resource requests and limits for your containerized applications is highly critical.",
                "choices":[
                   {
                      "id":"REL1_1",
                      "title":"Use RAM and CPU limits",
                      "helpfulResource":{
                         "displayText":"By default, a running container will use the full RAM and CPU of the host system. This can lead to performance bottlenecks on the host and put your workload in a degraded state. Setting RAM and CPU limits on your running container will improve the availability of the host system and the workload.",
                         "url":"https://docs.aws.amazon.com/wellarchitected/latest/container-build-lens/foundations.html"
                      },
                      "improvementPlan":{
                         "displayText":"In Amazon ECS, update the CPU and memory parameters in the task definition to limit the CPU and RAM a container will consume. If you are going to run your container workload on Amazon EKS, update the CPU and memory values in the resources section of your YAML file. The requests and limits keys are used to define how much memory and CPU a specific container will consume when running."
                      }
                   }
                ],
                "riskRules":[
                   {
                      "condition":"REL1_1",
                      "risk":"NO_RISK"
                   },
                   {
                      "condition":"!REL1_1",
                      "risk":"MEDIUM_RISK"
                   },
                   {
                      "condition":"default",
                      "risk":"HIGH_RISK"
                   }
                ]
             },
             {
                "id":"REL2",
                "title":"How do you handle persistent data in a container application?",
                "description":"Given the ephemeral nature of a container workload, data on the container will be lost once the container is restarted and longer exists. For this reason, handling persistent data properly in a container application is crucial.",
                "choices":[
                   {
                      "id":"REL2_1",
                      "title":"Use volumes to persist data",
                      "helpfulResource":{
                         "displayText":"There are times when workloads have to store data across multiple containers. For example, an image-processing application that saves images for processing. Given the ephemeral nature of a container workload, data on the container will be lost once the container is restarted and longer exists. Use mounted volumes, whether block or network file system (NFS), to persist file data for an application.",
                         "url":"https://docs.aws.amazon.com/wellarchitected/latest/container-build-lens/workload-architecture.html"
                      },
                      "improvementPlan":{
                         "displayText":"Mounted volumes allow for file data sharing among multiple running containers. In addition, mounted volumes should be used to persist logs or configuration files. For persisting data, use external database such as Amazon Relational Database Service (Amazon RDS), Amazon DynamoDB, or Amazon Aurora. Use a database system that provides performance, high-availability, and scalability to your container application when persisting data."
                      }
                   }
                ],
                "riskRules":[
                   {
                      "condition":"REL2_1",
                      "risk":"NO_RISK"
                   },
                   {
                      "condition":"!REL2_1",
                      "risk":"MEDIUM_RISK"
                   },
                   {
                      "condition":"default",
                      "risk":"HIGH_RISK"
                   }
                ]
             },
             {
                "id":"REL3",
                "title":"How do you automate building and testing of containers?",
                "description":"Being able to build and test your containerized application using automated tools can speed up the development phase and reduce the Time to Market.",
                "choices":[
                   {
                      "id":"REL3_1",
                      "title":"Create local testing processes",
                      "helpfulResource":{
                         "displayText":"When building a containerized application, you want to be able to test your application as early as possible. That means that you have to think about how developers will be able to test their containerized application locally. First you will have to decide whether the container build for local testing will run on the developer’s machine or in a remote machine, because this will have an impact on the tooling that developers use on their machines. Second, you will have to provide a local deployment mechanism. For this, you can use single containers that run as part of an automation script or deploy the containers locally using a local version of your target orchestrator.",
                         "url":"https://docs.aws.amazon.com/wellarchitected/latest/container-build-lens/workload-architecture.html"
                      },
                      "improvementPlan":{
                         "displayText":"This can be also part of the testing section of your local build-script. With this approach, you can deploy necessary infrastructure components like databases in a lightweight fashion in order to test your application with the real infrastructure instead of mocked APIs. One example might be a Docker Compose manifest to deploy multiple containers in a single command. For Kubernetes, use minikube to deploy the containerized application and all of its objects (such as Deployment, ConfigMaps, and Secrets). "
                      }	
                   },
                   {
                      "id":"REL3_2",
                      "title":"Design your testing environments to support your container build pipeline",
                      "helpfulResource":{
                         "displayText":"When building a containerized application, it can be easily deployed throughout multiple environments. In order to validate that your application is running properly, you will have to test your containerized applications. With the container’s ecosystem, you can have multiple manifests for all of the applications in an environment, and you can easily provision a ready-to-use environment with all dependent services already deployed in it. This process of temporary, or ephemeral testing environments, can be achieved in lower effort given the ease of reproducing fully configured environments that are based on containers. Whether you’re using the GitOps methodology for a Kubernetes based application, or a centralized deployment configuration, you should try to create reproducible environments to support testing of your containerized application.",
                         "url":"https://docs.aws.amazon.com/wellarchitected/latest/container-build-lens/workload-architecture.html"
                      },
                      "improvementPlan":{
                         "displayText":"When building a containerized application, it can be easily deployed throughout multiple environments. In order to validate that your application is running properly, you will have to test your containerized applications. With the container’s ecosystem, you can have multiple manifests for all of the applications in an environment, and you can easily provision a ready-to-use environment with all dependent services already deployed in it. This process of temporary, or ephemeral testing environments, can be achieved in lower effort given the ease of reproducing fully configured environments that are based on containers. Whether you’re using the GitOps methodology for a Kubernetes based application, or a centralized deployment configuration, you should try to create reproducible environments to support testing of your containerized application. "
                      }
                   }
                ],
                "riskRules":[
                   {
                      "condition":"REL3_1 && REL3_2",
                      "risk":"NO_RISK"
                   },
                   {
                      "condition":"REL3_1 && !REL3_2",
                      "risk":"MEDIUM_RISK"
                   },
                   {
                      "condition":"default",
                      "risk":"HIGH_RISK"
                   }
                ]
             },
             {
                "id":"REL4",
                "title":"How do I cascade updates to a parent or base image?",
                "description":"Managing updates in a proper way helps maintain consistent change management process and security posture.",
                "choices":[
                   {
                      "id":"REL4_1",
                      "title":"Create a standardized parent image",
                      "helpfulResource":{
                         "displayText":"Based on a lean parent image, a team- or enterprise-wide image can be created that provides optimizations to all teams. This could also be multiple parent images depending on the containerized application frameworks and languages. An organization could potentially start with a lean image containing company-specific configurations, and teams can add additional software that is necessary to run the different applications. This could be, for example, a Java Runtime Edition (JRE) or a specific Python version. One disadvantage of this solution is that if a parent image is changed, all images that use it - directly or indirectly - must also be recreated. ",
                         "url":"https://docs.aws.amazon.com/wellarchitected/latest/container-build-lens/change-management.html"
                      },
                      "improvementPlan":{
                         "displayText":"Based on a lean parent image, a team- or enterprise-wide image can be created that provides optimizations to all teams. This could also be multiple parent images depending on the containerized application frameworks and languages. An organization could potentially start with a lean image containing company-specific configurations, and teams can add additional software that is necessary to run the different applications. This could be, for example, a Java Runtime Edition (JRE) or a specific Python version. One disadvantage of this solution is that if a parent image is changed, all images that use it - directly or indirectly - must also be recreated. "
                      }
                   },
                   {
                      "id":"REL4_2",
                      "title":" Use an image hierarchy approach",
                      "helpfulResource":{
                         "displayText":"Try to maintain an image hierarchy in your container image strategy. A hierarchy or layered approach to container images helps with maintenance, cascading of updates to base images, and allows for the reuse of container images. In addition, it helps maintain the security posture of the broader organization by using the same images that have the security controls image managed by a central team. Operations like patching of a parent image should trigger a rebuild with changes to child images. As a best practice, separate images into the following categories: Intermediate base image, Application server, Application source code or binary",
                         "url":"https://docs.aws.amazon.com/wellarchitected/latest/container-build-lens/change-management.html"
                      },
                      "improvementPlan":{
                         "displayText":"The application server image is a specific image of the platform application to run the developer's code but does not contain the application's binary code itself. See the following example of an application server image, which is Docker Hub's official NGINX image. It contains the base image of alpine:1.13 and the NGINX platform application. The following Dockerfile is built using docker build -t nginx:1.20.1-alpine.  Lastly, the application binary created by the developer should reside in the container image. The container image comprises all the developer's source code to run their application. The following example uses the application server image, and copies the application code into the image."
                      }
                   },
                   {
                      "id":"REL4_3",
                      "title":"Use source control and tagging on all container images",
                      "helpfulResource":{
                         "displayText":"Maintain the Dockerfile for all container images in a source control repository in the image hierarchy and ensure proper tagging of container images. In addition, use a contentious integration process to create a direct correlation between the container's images in source control and the image tag. This best practice is critical to determine what changed in the container image from a prior release. For example, tag 1.0 indicates that this tag will always point to the latest patch release 1.0.1, 1.0.2, 1.0.3, and so on. ",
                         "url":"https://docs.aws.amazon.com/wellarchitected/latest/container-build-lens/change-management.html"
                      },
                      "improvementPlan":{
                         "displayText":"Maintain the Dockerfile for all container images in a source control repository in the image hierarchy and ensure proper tagging of container images. In addition, use a contentious integration process to create a direct correlation between the container's images in source control and the image tag. This best practice is critical to determine what changed in the container image from a prior release. For example, tag 1.0 indicates that this tag will always point to the latest patch release 1.0.1, 1.0.2, 1.0.3, and so on. "
                      }
                   }
                ],
                "riskRules":[
                   {
                      "condition":"REL4_1 && REL4_2",
                      "risk":"NO_RISK"
                   },
                   {
                      "condition":"REL4_1 && !REL4_2",
                      "risk":"MEDIUM_RISK"
                   },
                   {
                      "condition":"default",
                      "risk":"HIGH_RISK"
                   }
                ]
             },
             {
                "id":"REL5",
                "title":"How do you monitor the health of a container?",
                "description":"Monitoring the health of a container is crucial to ensure the availability of the services and business continuity.",
                "choices":[
                   {
                      "id":"REL5_1",
                      "title":"Plan for health checks in all containers builds and deployments",
                      "helpfulResource":{
                         "displayText":"It is common to initially develop container applications without thinking of the availability of the services in the container. When running container applications, there is no way of knowing whether the services running within a container are up or not. Adding a health check or probe to the container provides testing of the services in the container. Health check options are available in Docker using the HEALTHCHECK command, however, containerd does not have this option. Examine the orchestrations systems health check and probing options. This could include liveness and readiness probes within Amazon EKS or health checks within a definition file within Amazon ECS.",
                         "url":"https://docs.aws.amazon.com/wellarchitected/latest/container-build-lens/failure-management.html"
                      },
                      "improvementPlan":{
                         "displayText":"Based on a lean parent image, a team- or enterprise-wide image can be created that provides optimizations to all teams. This could also be multiple parent images depending on the containerized application frameworks and languages. An organization could potentially start with a lean image containing company-specific configurations, and teams can add additional software that is necessary to run the different applications. This could be, for example, a Java Runtime Edition (JRE) or a specific Python version. One disadvantage of this solution is that if a parent image is changed, all images that use it - directly or indirectly - must also be recreated. "
                      }
                   }
                ],
                "riskRules":[
                   {
                      "condition":"REL5_1",
                      "risk":"NO_RISK"
                   },
                   {
                      "condition":"(!REL5_1)",
                      "risk":"HIGH_RISK"
                   },
                   {
                      "condition":"default",
                      "risk":"MEDIUM_RISK"
                   }
                ]
             }
          ]
       },
       {
          "id":"PERF",
          "name":"Performance",
          "questions":[
             {
                "id":"PERF1",
                "title":"How do you reduce the size of your container image?",
                "description":"Reducing size of your container image",
                "choices":[
                   {
                      "id":"PERF1_1",
                      "title":" Use small parent images ",
                      "helpfulResource":{
                         "displayText":"The OS parent image that is used to create the target images has a huge impact on the final container image size.",
                         "url":"https://docs.aws.amazon.com/wellarchitected/latest/container-build-lens/selection.html"
                      },
                      "improvementPlan":{
                         "displayText":"We can use Alpine to build performant containers, but for certain languages there are even more optimized run environments we can leverage. When using statically linked binaries, scratch can be an alternative. In the following example, we have a multi-stage build with a builder image based on Alpine (we will discuss multi-stage builds later in the document). In the first stage, the Go programming language application is built to a statically linked binary, the second stage uses scratch as base image and run the application built in the first stage. With this combined approach of a multi-stage build and using scratch as a base image, we achieve the smallest possible target image for running our application: "
                      }
                   },
                   {
                      "id":"PERF1_2",
                      "title":" Run a single process per container",
                      "helpfulResource":{
                         "displayText":"It is highly recommended to limit the number of processes in each container to one. This approach simplifies the implementation of separations of concerns using simple services. Each container should only be responsible for a single aspect of the application that facilitates horizontal scaling of this particular aspect. If it’s necessary to run more than one process per container, use a proper process supervisor (like supervisord) and an init system (like tini). ",
                         "url":"https://docs.aws.amazon.com/wellarchitected/latest/container-build-lens/selection.html"
                      },
                      "improvementPlan":{
                         "displayText":"It is highly recommended to limit the number of processes in each container to one. This approach simplifies the implementation of separations of concerns using simple services. Each container should only be responsible for a single aspect of the application that facilitates horizontal scaling of this particular aspect. If it’s necessary to run more than one process per container, use a proper process supervisor (like supervisord) and an init system (like tini). "
                      }
                   },
                   {
                      "id":"PERF1_3",
                      "title":"Exclude files with from your build process",
                      "helpfulResource":{
                         "displayText":"The .dockerignore file is similar to .gitignore and is used to exclude files that are not necessary for the build, or are of a sensitive nature. This can be useful if it’s not possible to restructure the source code directory to limit the build context. The following example shows a typical .dockerignore file, which excludes files like the compilation target-directory, JAR-files, and subdirectories. ",
                         "url":"https://docs.aws.amazon.com/wellarchitected/latest/container-build-lens/selection.html"
                      },
                      "improvementPlan":{
                         "displayText":"The .dockerignore file is similar to .gitignore and is used to exclude files that are not necessary for the build, or are of a sensitive nature. This can be useful if it’s not possible to restructure the source code directory to limit the build context. The following example shows a typical .dockerignore file, which excludes files like the compilation target-directory, JAR-files, and subdirectories."
                      }
                   }
                ],
                "riskRules":[
                   {
                      "condition":"PERF1_1 && PERF1_2",
                      "risk":"NO_RISK"
                   },
                   {
                      "condition":"PERF1_1 && !PERF1_2",
                      "risk":"MEDIUM_RISK"
                   },
                   {
                      "condition":"default",
                      "risk":"HIGH_RISK"
                   }
                ]
             },
             {
                "id":"PERF2",
                "title":"How do you reduce the pull time of your container image?",
                "description":"Reducing pull time of your container image",
                "choices":[
                   {
                      "id":"PERF2_1",
                      "title":"Use a container registry close to your cluster",
                      "helpfulResource":{
                         "displayText":"One of the essential factors in the speed of deploying container images from a registry is locality. The registry should be as close to the cluster as possible, which means that both the cluster and the registry should be in the same AWS Region. For multi-region deployments, this means that the CI/CD chain should publish a container image to multiple Regions. An additional way to optimize the pull time of your container image is to keep the container image as small as possible. In Tradeoffs multi-stage builds are discussed in detail to reduce the image size. ",
                         "url":"https://docs.aws.amazon.com/wellarchitected/latest/container-build-lens/selection.html"
                      },
                      "improvementPlan":{
                         "displayText":"One of the essential factors in the speed of deploying container images from a registry is locality. The registry should be as close to the cluster as possible, which means that both the cluster and the registry should be in the same AWS Region. For multi-region deployments, this means that the CI/CD chain should publish a container image to multiple Regions. An additional way to optimize the pull time of your container image is to keep the container image as small as possible. In Tradeoffs multi-stage builds are discussed in detail to reduce the image size. "
                      }
                   }
                ],
                "riskRules":[
                   {
                      "condition":"PERF2_1",
                      "risk":"NO_RISK"
                   },
                   {
                      "condition":"!PERF2_1",
                      "risk":"MEDIUM_RISK"
                   },
                   {
                      "condition":"default",
                      "risk":"HIGH_RISK"
                   }
                ]
             },
             {
                "id":"PERF3",
                "title":"How do you make sure to get consistent results for your target images?",
                "description":"Consistent results for target images",
                "choices":[
                   {
                      "id":"PERF3_1",
                      "title":"Use a tag other than latest",
                      "helpfulResource":{
                         "displayText":"Using the latest tag for the parent image could potentially lead to issues because the latest version of the image might include breaking changes compared to the version that is currently used.",
                         "url":"https://docs.aws.amazon.com/wellarchitected/latest/container-build-lens/review.html"
                      },
                      "improvementPlan":{
                         "displayText":"Using the latest tag for the parent image could potentially lead to issues because the latest version of the image might include breaking changes compared to the version that is currently used."
                      }
                   }
                ],
                "riskRules":[
                   {
                      "condition":"PERF3_1",
                      "risk":"NO_RISK"
                   },
                   {
                      "condition":"!PERF3_1",
                      "risk":"MEDIUM_RISK"
                   },
                   {
                      "condition":"default",
                      "risk":"HIGH_RISK"
                   }
                ]
             },
             {
                "id":"PERF4",
                "title":"How do you make sure to use updated versions for parent images?",
                "description":"Updated versions for parent images",
                "choices":[
                   {
                      "id":"PERF4_1",
                      "title":"Implement a notification mechanism for updated parent images",
                      "helpfulResource":{
                         "displayText":"If you’re using a team- or enterprise-wide image, you should implement a notification mechanism based as part of your CI/CD chain to distribute the information about a new parent image to the teams. The teams should build target images with the new parent images and measure the performance impact of the changes by running a proper test suite.",
                         "url":"https://docs.aws.amazon.com/wellarchitected/latest/container-build-lens/review.html"
                      },
                      "improvementPlan":{
                         "displayText":"If you’re using a team- or enterprise-wide image, you should implement a notification mechanism based as part of your CI/CD chain to distribute the information about a new parent image to the teams. The teams should build target images with the new parent images and measure the performance impact of the changes by running a proper test suite."
                      }
                   }
                ],
                "riskRules":[
                   {
                      "condition":"PERF4_1",
                      "risk":"NO_RISK"
                   },
                   {
                      "condition":"!PERF4_1",
                      "risk":"MEDIUM_RISK"
                   },
                   {
                      "condition":"default",
                      "risk":"HIGH_RISK"
                   }
                ]
             },
             {
                "id":"PERF5",
                "title":"How do you make sure you get consistent performance results over time?",
                "description":"Consistent performance results",
                "choices":[
                   {
                      "id":"PERF5_1",
                      "title":"Implement an automated performance testing strategy",
                      "helpfulResource":{
                         "displayText":"System performance can degrade over time. It’s important to have an automated testing and monitoring system in place to identify degradation of performance. Every time you build target images based on new parent images, you should measure the performance impact of the changes in the parent image. This also includes the overall build process, because we have to make sure that a testing and monitoring system covers the CI/CD chain. Performance metrics and image sizes have to be collected using services like Amazon CloudWatch and teams must be alarmed if anomalies have been detected.",
                         "url":"https://docs.aws.amazon.com/wellarchitected/latest/container-build-lens/monitoring.html"
                      },
                      "improvementPlan":{
                         "displayText":"System performance can degrade over time. It’s important to have an automated testing and monitoring system in place to identify degradation of performance. Every time you build target images based on new parent images, you should measure the performance impact of the changes in the parent image. This also includes the overall build process, because we have to make sure that a testing and monitoring system covers the CI/CD chain. Performance metrics and image sizes have to be collected using services like Amazon CloudWatch and teams must be alarmed if anomalies have been detected. "
                      }
                   }
                ],
                "riskRules":[
                   {
                      "condition":"PERF5_1",
                      "risk":"NO_RISK"
                   },
                   {
                      "condition":"!PERF5_1",
                      "risk":"MEDIUM_RISK"
                   },
                   {
                      "condition":"default",
                      "risk":"HIGH_RISK"
                   }
                ]
             },
             {
                "id":"PERF6",
                "title":"How do you optimize the size of your target image?",
                "description":"Optimising size of target image",
                "choices":[
                   {
                      "id":"PERF6_1",
                      "title":" Use caching during build",
                      "helpfulResource":{
                         "displayText":"A container image is created using layers. Each statement in a Dockerfile (like RUN or COPY) creates a new layer. These layers are stored in a local image cache and can be reused in the next build. The cache can be invalidated by changing the Dockerfile, which means that all subsequent steps to build the image must be rerun. Naturally, this has a great influence on the speed the image is built. Thus, the order of the commands in your Dockerfile can have a dramatic effect on build performance.",
                         "url":"https://docs.aws.amazon.com/wellarchitected/latest/container-build-lens/tradeoffs.html"
                      },
                      "improvementPlan":{
                         "displayText":"This simple container image uses amazonlinux with tag 2 as parent image. In the second step, the Amazon Linux distribution is updated with the latest patches. After that, the Python application is copied into the container image. Next, Python, pip, wget, and additional dependencies required by the application are installed. In the final step, we start the application. The issue with this approach is that each application change results in cache invalidation for all subsequent steps. A small change in the application results in a rerun of the Python installation, which has a negative impact on build time. An optimized version of the Dockerfile looks like this. Now the COPY statement of the application is located after yum install. The effect of this small adaption is that a change of the application code results in fewer layer changes. In the previous version of the file, each application change results in an invalidation of the layer that installs Python and other dependencies. This had to be rerun after a code change. One additional aspect, which is covered in the optimized version of this Dockerfile, is the number of layers. Each RUN command creates a new layer, by combining layers it is possible to reduce the images size. "
                      }
                   },
                   {
                      "id":"PERF6_2",
                      "title":"Use the CPU architecture with best price to performance ratio",
                      "helpfulResource":{
                         "displayText":"AWS Graviton-based Amazon EC2 instances deliver up to 40% better price performance over comparable current generation x86-based instances for a broad spectrum of workloads. Instead of using one build-server for x86 and ARM in combination with QEMU for CPU emulation, it might be a more efficient architecture to use at least one build server per CPU architecture. For example, it is possible to create multi-architecture container images to support AWS Graviton-based Amazon EC2 instances and x86 using AWS CodeBuild and AWS CodePipeline. As described in the blog post Creating multi-architecture Docker images to support Graviton2 using AWS CodeBuild and AWS CodePipeline, this approach includes three CodeBuild projects to create an x86 container image, an ARM64 container image, and a manifest list. A manifest list is a list of image layers that is created by specifying one or more (ideally more than one) image names. This approach is used to create multi-architecture container images. ",
                         "url":"https://docs.aws.amazon.com/wellarchitected/latest/container-build-lens/tradeoffs.html"
                      },
                      "improvementPlan":{
                         "displayText":"AWS Graviton-based Amazon EC2 instances deliver up to 40% better price performance over comparable current generation x86-based instances for a broad spectrum of workloads. Instead of using one build-server for x86 and ARM in combination with QEMU for CPU emulation, it might be a more efficient architecture to use at least one build server per CPU architecture. For example, it is possible to create multi-architecture container images to support AWS Graviton-based Amazon EC2 instances and x86 using AWS CodeBuild and AWS CodePipeline. As described in the blog post Creating multi-architecture Docker images to support Graviton2 using AWS CodeBuild and AWS CodePipeline, this approach includes three CodeBuild projects to create an x86 container image, an ARM64 container image, and a manifest list. A manifest list is a list of image layers that is created by specifying one or more (ideally more than one) image names. This approach is used to create multi-architecture container images. "
                      }
                   }
                ],
                "riskRules":[
                   {
                      "condition":"PERF6_1 && PERF6_2",
                      "risk":"NO_RISK"
                   },
                   {
                      "condition":"PERF6_1 && !PERF6_2",
                      "risk":"MEDIUM_RISK"
                   },
                   {
                      "condition":"default",
                      "risk":"HIGH_RISK"
                   }
                ]
             }
          ]
       },
       {
          "id":"COST",
          "name":"Cost Optimization",
          "questions":[
             {
                "id":"COST1",
                "title":"How do you design your container build process to avoid unnecessary cost?",
                "description":"Avoid unnecessary costs",
                "choices":[
                   {
                      "id":"COST1_1",
                      "title":"Are you aware of the retention period of container images?",
                      "helpfulResource":{
                         "displayText":"Building a containerized application can result in multiple images for the same service. Depending on your organization policy, you might want to keep a subset of your container images to be used in a case of a rollback scenario. An example of such a policy might be that you don’t roll back more than three versions, or more than three months in time. That means, that not all container images of a specific application should be kept. Deleting old images can save costs as container registries charge by size of images stored in the registry. You can achieve this deletion policy by creating automation processes, or use service features, for example: Amazon ECR supports a lifecycle policy that can be used to expire (delete) images based on rules such as image age, count, specific tags and more (see Examples of lifecycle policies)",
                         "url":"https://docs.aws.amazon.com/wellarchitected/latest/container-build-lens/practice-cloud-financial-management.html"
                      },
                      "improvementPlan":{
                         "displayText":"Building a containerized application can result in multiple images for the same service. Depending on your organization policy, you might want to keep a subset of your container images to be used in a case of a rollback scenario. An example of such a policy might be that you don’t roll back more than three versions, or more than three months in time. That means, that not all container images of a specific application should be kept. Deleting old images can save costs as container registries charge by size of images stored in the registry. You can achieve this deletion policy by creating automation processes, or use service features, for example: Amazon ECR supports a lifecycle policy that can be used to expire (delete) images based on rules such as image age, count, specific tags and more (see Examples of lifecycle policies)"
                      }
                   }
                ],
                "riskRules":[
                   {
                      "condition":"COST1_1",
                      "risk":"NO_RISK"
                   },
                   {
                      "condition":"!COST1_1",
                      "risk":"MEDIUM_RISK"
                   },
                   {
                      "condition":"default",
                      "risk":"HIGH_RISK"
                   }
                ]
             },
             {
                "id":"COST2",
                "title":"How do you design your container build process to avoid unnecessary cost?",
                "description":"To ensure the success of your running container, you must understand the health of your containerized workload as well as what your customers are experiencing when they interact with your application.",
                "choices":[
                   {
                      "id":"COST2_1",
                      "title":"Designing efficient container build process",
                      "helpfulResource":{
                         "displayText":"Building containers is a process that consumes compute and storage resources and can lead to unnecessary costs if not using it properly. The build process consumes resources for each build, and there are some considerations that have to be taken for it to be efficient from a cost perspective.",
                         "url":"https://docs.aws.amazon.com/wellarchitected/latest/container-build-lens/expenditure-and-usage-awareness.html"
                      },
                      "improvementPlan":{
                         "displayText":"Building containers is a process that consumes compute and storage resources and can lead to unnecessary costs if not using it properly. The build process consumes resources for each build, and there are some considerations that have to be taken for it to be efficient from a cost perspective. "
                      }
                   },
                   {
                      "id":"COST2_2",
                      "title":" Application dependencies",
                      "helpfulResource":{
                         "displayText":"The container image is usually being built alongside with the application build step. During this build step, all necessary dependencies, libraries, and modules that are being used by the application code are downloaded to the container image. Using unnecessary dependencies will make the build time longer, and will result in wasting compute resources of the build system.",
                         "url":"https://docs.aws.amazon.com/wellarchitected/latest/container-build-lens/expenditure-and-usage-awareness.html"
                      },
                      "improvementPlan":{
                         "displayText":"The container image is usually being built alongside with the application build step. During this build step, all necessary dependencies, libraries, and modules that are being used by the application code are downloaded to the container image. Using unnecessary dependencies will make the build time longer, and will result in wasting compute resources of the build system."
                      }
                   },
                   {
                      "id":"COST2_3",
                      "title":"Common container image dependencies",
                      "helpfulResource":{
                         "displayText":"Some operating system packages are needed for multiple applications in the organization for a specific runtime (for example, Python and Java). Building a parent container image that preinstalls all common operating system packages and dependencies for the specific runtime will result in a more efficient build process. Without this common image, each individual container image would be installing the same packages, thus wasting compute and network resources. This practice will also shorten the time for container images built from a specific runtime, since all of its common operating system packages and dependencies are already included in the parent container image. As a result, this will reduce costs for building all other container images that use this parent image. ",
                         "url":"https://docs.aws.amazon.com/wellarchitected/latest/container-build-lens/expenditure-and-usage-awareness.html"
                      },
                      "improvementPlan":{
                         "displayText":"Some operating system packages are needed for multiple applications in the organization for a specific runtime (for example, Python and Java). Building a parent container image that preinstalls all common operating system packages and dependencies for the specific runtime will result in a more efficient build process. Without this common image, each individual container image would be installing the same packages, thus wasting compute and network resources. This practice will also shorten the time for container images built from a specific runtime, since all of its common operating system packages and dependencies are already included in the parent container image. As a result, this will reduce costs for building all other container images that use this parent image. ."
                      }
                   }
                ],
                "riskRules":[
                   {
                      "condition":"COST2_1 && COST2_2",
                      "risk":"NO_RISK"
                   },
                   {
                      "condition":"COST2_1 && !COST2_2",
                      "risk":"MEDIUM_RISK"
                   },
                   {
                      "condition":"default",
                      "risk":"HIGH_RISK"
                   }
                ]
             },
             {
                "id":"COST3",
                "title":"Ensure that your container images contain only what is relevant",
                "description":"Container images can affect the overall cost of the system and workloads. In this section, we’ll describe what has to be done in order to optimize your container images, and why it is important from cost perspective.",
                "choices":[
                   {
                      "id":"COST3_1",
                      "title":"Containerized application start-up time",
                      "helpfulResource":{
                         "displayText":"Container image size affects the time needed for an image to be pulled from a container registry. Large image sizes (hundreds, or thousands of MB), can lead to a slow startup time of the application, which can lead to wasted compute resources while waiting for images to be pulled Slow scale-out operations Container image size also affects the scaling time needed for a containerized application to become ready to receive traffic. This time can translate to a waste of resources. In small-scale replicas of your application, the waste might not be notable, but when dealing with a dynamic autoscaled environment, a 30-second delay between a triggered scale-out event and a container ready to run can result in hundreds of compute minutes wasted per month.",
                         "url":"https://docs.aws.amazon.com/wellarchitected/latest/container-build-lens/cost-effective-resources.html"
                      },
                      "improvementPlan":{
                         "displayText":"Container image size affects the time needed for an image to be pulled from a container registry. Large image sizes (hundreds, or thousands of MB), can lead to a slow startup time of the application, which can lead to wasted compute resources while waiting for images to be pulled Slow scale-out operations Container image size also affects the scaling time needed for a containerized application to become ready to receive traffic. This time can translate to a waste of resources. In small-scale replicas of your application, the waste might not be notable, but when dealing with a dynamic autoscaled environment, a 30-second delay between a triggered scale-out event and a container ready to run can result in hundreds of compute minutes wasted per month."
                      }
                   },
                   {
                      "id":"COST3_2",
                      "title":"Storage requirements for containers",
                      "helpfulResource":{
                         "displayText":"Consider your instance’s storage requirements depending on your container image size. The size of your container image has a direct effect on the instance storage size that the container will run on. This can result in the need for a larger storage size for your instances.Container image size also affects the storage requirements of the container registry, since the container image will be stored in the registry. Stored images in Amazon ECR are priced per GB-month. For current pricing, refer to the pricing page",
                         "url":"https://docs.aws.amazon.com/wellarchitected/latest/container-build-lens/cost-effective-resources.html"
                      },
                      "improvementPlan":{
                         "displayText":"Consider your instance’s storage requirements depending on your container image size. The size of your container image has a direct effect on the instance storage size that the container will run on. This can result in the need for a larger storage size for your instances.Container image size also affects the storage requirements of the container registry, since the container image will be stored in the registry. Stored images in Amazon ECR are priced per GB-month. For current pricing, refer to the pricing page"
                      }
                   }
                ],
                "riskRules":[
                   {
                      "condition":"COST3_1 && COST3_2",
                      "risk":"NO_RISK"
                   },
                   {
                      "condition":"COST3_1 && !COST3_2",
                      "risk":"MEDIUM_RISK"
                   },
                   {
                      "condition":"default",
                      "risk":"HIGH_RISK"
                   }
                ]
             },
             {
                "id":"COST4",
                "title":"How do you reduce your container images size?",
                "description":"Reducing container image size",
                "choices":[
                   {
                      "id":"COST4_1",
                      "title":"Reducing image layers",
                      "helpfulResource":{
                         "displayText":"A container image consists of read-only layers that represent a Dockerfile instruction. Each instruction creates one additional layer on top of the previous layer. Running multiple consecutive commands can result in a large container image size, even if we delete content in the container image itself. An example of that might be installing a package, and deleting the cached downloaded files that are not needed anymore after installing the package. The following example shows that we installed some-package and then delete the cached files. Even though we used the rm command to remove the cached file, the container image contains a layer representing the rm -rf ... command, and is still containing a layer with the actual cached files, resulting in a larger container image. ",
                         "url":"https://docs.aws.amazon.com/wellarchitected/latest/container-build-lens/cost-effective-resources.html"
                      },
                      "improvementPlan":{
                         "displayText":" Reducing image layers can be done with several techniques. Building container images from the scratch image - This can result in creating the minimal container image possible, especially when containerizing executable applications with minimal external dependencies from the OS (like Go, Rust, and C).Use lightweight base images - For other type of programming languages that need a runtime environment in the container image, using parent and base images of lightweight distributions like Alpine can reduce the image size significantly. For example: a Python container image based on Debian parent image is ~330MB in size whereas a Python container image based on Alpine parent image is ~17MB in size. Reducing the number of RUN instructions by chaining commands together - Installing dependencies and deleting cache in a single command as shown in the previous command. This practice should only be used when the consecutive commands relate one to another. Consider using package managers flags to reduce dependency sizes - Such as no-install-recommends with apt-get.Use multi-stage builds - Multi-stage builds let you reduce image sizes by using build cache from the previous build step and copying only needed dependencies to the final container image. For example, see docker docs. Follow Dockerfile best practices such as: Use COPY instead of ADD. Use absolute path when using WORKDIR.Exclude files from the build process using .dockerignore. Specify exclusion patterns of file, directories or both (similar to .gitignore). This makes it easy to exclude unnecessary files from COPY or ADD commands."
                      }
                   }
                ],
                "riskRules":[
                   {
                      "condition":"COST4_1",
                      "risk":"NO_RISK"
                   },
                   {
                      "condition":"!COST4_1",
                      "risk":"MEDIUM_RISK"
                   },
                   {
                      "condition":"default",
                      "risk":"HIGH_RISK"
                   }
                ]
             },
             {
                "id":"COST5",
                "title":"How do you design your containerized application to support automatic scaling and graceful termination?",
                "description":"Autoscaling and graceful termination",
                "choices":[
                   {
                      "id":"COST5_1",
                      "title":"Does your application handle signal handling?",
                      "helpfulResource":{
                         "displayText":"When designing applications that will be containerized, it is important to include signal handling within the code and/or the container itself. Handling signals is a fundamental practice for writing applications, especially when writing applications that will run inside a container. The application should handle system signals and react according to the application logic. Although this is not directly related to cost, handling signals is a key element for using cost saving practices like automatic scaling or using Amazon EC2 Spot Instances. When a scale-in event, or replacement or termination of a Spot Instance occurs, the container orchestrator system or tools will send a SIGTERM signal to the application notifying the application to shut itself down gracefully. If it fails to do so, the process may end up being terminated while performing work, which can prohibit the use of auto scaling or spot in general.",
                         "url":"https://docs.aws.amazon.com/wellarchitected/latest/container-build-lens/cost-effective-resources.html"
                      },
                      "improvementPlan":{
                         "displayText":"When designing applications that will be containerized, it is important to include signal handling within the code and/or the container itself. Handling signals is a fundamental practice for writing applications, especially when writing applications that will run inside a container. The application should handle system signals and react according to the application logic. Although this is not directly related to cost, handling signals is a key element for using cost saving practices like automatic scaling or using Amazon EC2 Spot Instances. When a scale-in event, or replacement or termination of a Spot Instance occurs, the container orchestrator system or tools will send a SIGTERM signal to the application notifying the application to shut itself down gracefully. If it fails to do so, the process may end up being terminated while performing work, which can prohibit the use of auto scaling or spot in general."
                      }
                   }
                ],
                "riskRules":[
                   {
                      "condition":"COST5_1",
                      "risk":"NO_RISK"
                   },
                   {
                      "condition":"!COST5_1",
                      "risk":"MEDIUM_RISK"
                   },
                   {
                      "condition":"default",
                      "risk":"HIGH_RISK"
                   }
                ]
             },
             {
                "id":"COST6",
                "title":"How do you design your containerized application to support multiple CPU architectures?",
                "description":"Support multiple CPU architectures",
                "choices":[
                   {
                      "id":"COST6_1",
                      "title":"Aware of different instance families and CPU architecture",
                      "helpfulResource":{
                         "displayText":"Different instance families offer different performance for the same amount of hardware (CPU and memory). An example is using a newer instead of an older generation of instances, or using instances with different CPU architecture, such as ARM. To use a different instance architecture, you have to change your build process. Since the default behavior of the build process is to create a container image that is designed to run on the architecture of the instance that it was built on, you have to create multiple images for each CPU architecture. To create multiple images, run the same build process on an x86 instance, and on an ARM-based instance. Use tagging suffixes to differentiate between the different architectures.",
                         "url":"https://docs.aws.amazon.com/wellarchitected/latest/container-build-lens/cost-effective-resources.html"
                      },
                      "improvementPlan":{
                         "displayText":"You can see an example container image tag when searching images in your registry (see aws-node-termination-handler and search for container images in the Amazon ECR public gallery under the Image tags tab) and look for the different -linux-arm64 and -linux-amd64 suffixes. Having different container image tags allows you to schedule and run the x86 version of your container image on an x86 instance, and the ARM version of your container image on an ARM instance. You have to make sure that the correct container image version will run on the correct instance. You can’t run the ARM version of your container image on an x86 instance, and vice versa. The Docker image manifest v2 schema 2, and the OCI image index specification were created to make it easier to run your container image on any architecture. This additional specification allows you to create a high-level manifest that contains a list to other already existing container images. This container manifest, contains a reference to all the different container images, specifying their operating system type, architecture, and the digest of the container image that is referenced. Using the manifest, the container runtime will know which image to pull based on what architecture the underlying instance uses. An example of different container image manifests and manifests list, is displayed in the following screenshot from the Amazon ECR public gallery"
                      }
                   }
                ],
                "riskRules":[
                   {
                      "condition":"COST6_1",
                      "risk":"NO_RISK"
                   },
                   {
                      "condition":"!COST6_1",
                      "risk":"MEDIUM_RISK"
                   },
                   {
                      "condition":"default",
                      "risk":"HIGH_RISK"
                   }
                ]
             },
             {
                "id":"COST7",
                "title":"How do you minimize cost for your containerized application during startup time?",
                "description":"Minimize cost during startup",
                "choices":[
                   {
                      "id":"COST7_1",
                      "title":"Minimise container startup time at app or container level",
                      "helpfulResource":{
                         "displayText":"Longer startup times for containerized applications can result in wasted compute resources. Shortening startup times can be done on the application-level (code optimization), or on the container level. For example, if the application needs external dependencies to be present in the container, it should be already installed during the build process, or it should be included in the parent image, and not downloaded at startup using an entrypoint script or DOCKERFILE commands.",
                         "url":"https://docs.aws.amazon.com/wellarchitected/latest/container-build-lens/manage-demand-and-supply-resources.html"
                      },
                      "improvementPlan":{
                         "displayText":"Longer startup times for containerized applications can result in wasted compute resources. Shortening startup times can be done on the application-level (code optimization), or on the container level. For example, if the application needs external dependencies to be present in the container, it should be already installed during the build process, or it should be included in the parent image, and not downloaded at startup using an entrypoint script or DOCKERFILE commands."
                      }
                   }
                ],
                "riskRules":[
                   {
                      "condition":"COST7_1",
                      "risk":"NO_RISK"
                   },
                   {
                      "condition":"!COST7_1",
                      "risk":"MEDIUM_RISK"
                   },
                   {
                      "condition":"default",
                      "risk":"HIGH_RISK"
                   }
                ]
             },
             {
                "id":"COST8",
                "title":"What systems are you using to create your container build process?",
                "description":"Creating your container build process",
                "choices":[
                   {
                      "id":"COST8_1",
                      "title":"Have a system in place for container build process",
                      "helpfulResource":{
                         "displayText":"Creating any build process requires developing, maintaining, and operating a build system. This can be done by a variety of methods, such as using OSS tooling for job automation, or using self-developed systems that are able to run build scripts for your application. However, running and maintaining this kind of system involves software development costs, operational costs, compute, and storage costs for running the system. Alternatively you can use build and pipeline services, such as Amazon EC2 Image Builder, AWS CodeBuild, and AWS CodePipeline. Using managed services removes the operational overhead and allows developers to consume pipeline runs and build jobs on a pay-as-you-go basis.",
                         "url":"https://docs.aws.amazon.com/wellarchitected/latest/container-build-lens/manage-demand-and-supply-resources.html"
                      },
                      "improvementPlan":{
                         "displayText":"Creating any build process requires developing, maintaining, and operating a build system. This can be done by a variety of methods, such as using OSS tooling for job automation, or using self-developed systems that are able to run build scripts for your application. However, running and maintaining this kind of system involves software development costs, operational costs, compute, and storage costs for running the system. Alternatively you can use build and pipeline services, such as Amazon EC2 Image Builder, AWS CodeBuild, and AWS CodePipeline. Using managed services removes the operational overhead and allows developers to consume pipeline runs and build jobs on a pay-as-you-go basis."
                      }
                   }
                ],
                "riskRules":[
                   {
                      "condition":"COST8_1",
                      "risk":"NO_RISK"
                   },
                   {
                      "condition":"!COST8_1",
                      "risk":"MEDIUM_RISK"
                   },
                   {
                      "condition":"default",
                      "risk":"HIGH_RISK"
                   }
                ]
             }
          ]
       },
       {
          "id":"SUST",
          "name":"Sustainability",
          "questions":[
             {
                "id":"SUST1",
                "title":"How do you design your containerized application to reduce resources?",
                "description":"The sustainability pillar focuses on environmental impacts, especially energy consumption and efficiency, since they are important levers for architects to inform direct action to reduce resource usage. You can find prescriptive guidance on implementation in the Sustainability Pillar whitepaper.",
                "choices":[
                   {
                      "id":"SUST1_1",
                      "title":"Design containerized applications that it reduces underlying resources",
                      "helpfulResource":{
                         "displayText":" When designing containerized application, you should keep your build manifests up-to-date and aligned with your application needs. A containerized application image starts from a Dockerfile. The Dockerfile includes all commands required to include the configuration and dependencies for the containerized application. If there are some dependencies that are no longer required, removing them from the Dockerfile canReduce the time that it takes to build the container image. This affects host resource consumption by the build process.    Reduce the container image size and therefore reduce the time it takes for this image to be pulled to an instance. This affects host resources usage for running and storing the container images.",
                         "url":"https://docs.aws.amazon.com/wellarchitected/latest/container-build-lens/software-and-architecture-patterns.html"
                      },
                      "improvementPlan":{
                         "displayText":"When designing containerized application, you should keep your build manifests up-to-date and aligned with your application needs. A containerized application image starts from a Dockerfile. The Dockerfile includes all commands required to include the configuration and dependencies for the containerized application. If there are some dependencies that are no longer required, removing them from the Dockerfile canReduce the time that it takes to build the container image. This affects host resource consumption by the build process.    Reduce the container image size and therefore reduce the time it takes for this image to be pulled to an instance. This affects host resources usage for running and storing the container images."
                      }
                   }
                ],
                "riskRules":[
                   {
                      "condition":"SUST1_1",
                      "risk":"NO_RISK"
                   },
                   {
                      "condition":"!SUST1_1",
                      "risk":"MEDIUM_RISK"
                   },
                   {
                      "condition":"default",
                      "risk":"HIGH_RISK"
                   }
                ]
             },
             {
                "id":"SUST2",
                "title":"How do you support your containerized application to run on energy-efficient hardware?",
                "description":"Supporting containerized applications to run on optimal hardware",
                "choices":[
                   {
                      "id":"SUST2_1",
                      "title":"Use instance types with least impact",
                      "helpfulResource":{
                         "displayText":"To be able to use instance types with the least environmental impact (from the Sustainability Pillar whitepaper), you have to ensure your containerized application is able to run on a variety of instance types and architectures. This can be done by creating images that support multi-architecture as described in the Cost Optimization Pillar whitepaper. For example, you can use a build service that supports multi-architecture build servers and combine them to a multi-architecture image using the CI pipeline (see Graviton workshop as an example of using AWS CodeBuild, and AWS CodePipeline alongside Graviton and Amazon EKS). You can also use tools that generate multi-architecture images from a single Dockerfile, such as Docker Buildx.",
                         "url":"https://docs.aws.amazon.com/wellarchitected/latest/container-build-lens/hardware-patterns.html"
                      },
                      "improvementPlan":{
                         "displayText":"To be able to use instance types with the least environmental impact (from the Sustainability Pillar whitepaper), you have to ensure your containerized application is able to run on a variety of instance types and architectures. This can be done by creating images that support multi-architecture as described in the Cost Optimization Pillar whitepaper. For example, you can use a build service that supports multi-architecture build servers and combine them to a multi-architecture image using the CI pipeline (see Graviton workshop as an example of using AWS CodeBuild, and AWS CodePipeline alongside Graviton and Amazon EKS). You can also use tools that generate multi-architecture images from a single Dockerfile, such as Docker Buildx."
                      }
                   }
                ],
                "riskRules":[
                   {
                      "condition":"SUST2_1",
                      "risk":"NO_RISK"
                   },
                   {
                      "condition":"!SUST2_1",
                      "risk":"MEDIUM_RISK"
                   }
                ]
             },
             {
                "id":"SUST3",
                "title":"How do you design your build tooling and services to improve efficiency?",
                "description":"Build tooling and services for improving efficiency for environmental impact",
                "choices":[
                   {
                      "id":"SUST3_1",
                      "title":"Use dynamically created build servers for building your containerized workload ",
                      "helpfulResource":{
                         "displayText":"Using dynamically created build servers (such as AWS CodeBuild), ensures that while building your containerized images, the needed infrastructure is being provisioned when the build process starts, and being terminated as soon as the build process ends. ",
                         "url":"https://docs.aws.amazon.com/wellarchitected/latest/container-build-lens/development-and-deployment-process.html"
                      },
                      "improvementPlan":{
                         "displayText":"Using dynamically created build servers (such as AWS CodeBuild), ensures that while building your containerized images, the needed infrastructure is being provisioned when the build process starts, and being terminated as soon as the build process ends. "
                      }
                   },
                   {
                      "id":"SUST3_2",
                      "title":"Use pre-defined or built runtimes to reduce your build time, and reuse needed dependencies for the build process",
                      "helpfulResource":{
                         "displayText":" When building different types of containerized applications, using common and standardized runtimes for the build process reduces the operational management of creating and maintaining custom images. Also, by using the specific type of runtime for your build server, it verifies that no common dependency is being downloaded and configured as part of the build process. All relevant dependencies are being incorporated into the different runtimes of your build servers, and are being used many times by different build processes for different applications. An example of multiple build runtimes can be found in the AWS CodeBuild documentation. ",
                         "url":"https://docs.aws.amazon.com/wellarchitected/latest/container-build-lens/development-and-deployment-process.html"
                      },
                      "improvementPlan":{
                         "displayText":"When building different types of containerized applications, using common and standardized runtimes for the build process reduces the operational management of creating and maintaining custom images. Also, by using the specific type of runtime for your build server, it verifies that no common dependency is being downloaded and configured as part of the build process. All relevant dependencies are being incorporated into the different runtimes of your build servers, and are being used many times by different build processes for different applications. An example of multiple build runtimes can be found in the AWS CodeBuild documentation."
                      }
                   },
                   {
                      "id":"SUST3_3",
                      "title":"Update your parent and base image regularly",
                      "helpfulResource":{
                         "displayText":"Update your base and parent images to the latest versions, as sometimes there is a performance improvement that is introduced in newer versions. These improvements are translated into a sustainability improvement as it affects the resource consumption of the underlying infrastructure, and as a result improves the overall efficiency. ",
                         "url":"https://docs.aws.amazon.com/wellarchitected/latest/container-build-lens/development-and-deployment-process.html"
                      },
                      "improvementPlan":{
                         "displayText":"Update your base and parent images to the latest versions, as sometimes there is a performance improvement that is introduced in newer versions. These improvements are translated into a sustainability improvement as it affects the resource consumption of the underlying infrastructure, and as a result improves the overall efficiency."
                      }
                   },
                   {
                      "id":"SUST3_4",
                      "title":"Delete unused or obsolete container images",
                      "helpfulResource":{
                         "displayText":"As described in the Cost Optimization Pillar whitepaper, create mechanisms to verify that unused or obsolete container images are deleted. This can be achieved, for example, by registry lifecycle policies, as exists in Amazon ECR.",
                         "url":"https://docs.aws.amazon.com/wellarchitected/latest/container-build-lens/development-and-deployment-process.html"
                      },
                      "improvementPlan":{
                         "displayText":"As described in the Cost Optimization Pillar whitepaper, create mechanisms to verify that unused or obsolete container images are deleted. This can be achieved, for example, by registry lifecycle policies, as exists in Amazon ECR."
                      }
                   }
                ],
                "riskRules":[
                   {
                      "condition":"SUST3_1 && SUST3_2 && SUST3_3 && SUST3_4",
                      "risk":"NO_RISK"
                   },
                   {
                      "condition":"default",
                      "risk":"MEDIUM_RISK"
                   }
                ]
             }
          ]
       }
    ]
 }